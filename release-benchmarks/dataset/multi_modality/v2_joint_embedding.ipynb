{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets=['GSE140203_BRAIN_atac2gex',\n",
    " 'GSE140203_SKIN_atac2gex',\n",
    " 'openproblems_2022_cite_gex2adt',\n",
    " 'openproblems_2022_multi_atac2gex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-01 21:08:31,307][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_BRAIN_atac2gex/GSE140203_BRAIN_atac2gex.GSE140203_dataset.output_mod1.h5ad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-01 21:08:31,804][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_BRAIN_atac2gex/GSE140203_BRAIN_atac2gex.GSE140203_dataset.output_mod2.h5ad\n",
      "[INFO][2023-10-01 21:08:31,898][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_BRAIN_atac2gex/GSE140203_BRAIN_atac2gex.GSE140203_dataset.output_train_mod1.h5ad\n",
      "[INFO][2023-10-01 21:08:32,409][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_BRAIN_atac2gex/GSE140203_BRAIN_atac2gex.GSE140203_dataset.output_train_mod2.h5ad\n",
      "[INFO][2023-10-01 21:08:32,574][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_BRAIN_atac2gex/GSE140203_BRAIN_atac2gex.GSE140203_dataset.output_solution.h5ad\n",
      "[INFO][2023-10-01 21:09:36,904][dance][_maybe_preprocess] Preprocessing done.\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/mudata/_core/mudata.py:491: UserWarning: Cannot join columns with the same name because var_names are intersecting.\n",
      "  warnings.warn(\n",
      "[INFO][2023-10-01 21:09:37,896][dance][load_data] Raw data loaded:\n",
      "Data object that wraps (.data):\n",
      "MuData object with n_obs × n_vars = 3291 × 897209\n",
      "  uns:\t'dance_config'\n",
      "  5 modalities\n",
      "    mod1:\t988 x 10000\n",
      "      var:\t'start', 'end', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm'\n",
      "      uns:\t'dataset_id', 'hvg'\n",
      "      layers:\t'counts'\n",
      "    mod2:\t988 x 10000\n",
      "      var:\t'gene', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm'\n",
      "      uns:\t'dataset_id', 'hvg'\n",
      "      layers:\t'counts'\n",
      "    meta1:\t2303 x 428041\n",
      "      var:\t'start', 'end'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "    meta2:\t2303 x 21127\n",
      "      var:\t'gene'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "    test_sol:\t988 x 428041\n",
      "      obs:\t'atac.bc', 'cell_type'\n",
      "      var:\t'start', 'end'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "[INFO][2023-10-01 21:09:37,898][dance][wrapped_func] Took 0:01:06.592260 to load and process data.\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n",
      "[INFO][2023-10-01 21:09:38,135][dance][set_config_from_dict] Setting config 'feature_mod' to ['mod1', 'mod2', 'mod1', 'mod2', 'mod1', 'mod2']\n",
      "[INFO][2023-10-01 21:09:38,136][dance][set_config_from_dict] Setting config 'label_mod' to 'mod1'\n",
      "[INFO][2023-10-01 21:09:38,137][dance][set_config_from_dict] Setting config 'feature_channel_type' to ['layers', 'layers', None, None, 'obsm', 'obsm']\n",
      "[INFO][2023-10-01 21:09:38,138][dance][set_config_from_dict] Setting config 'feature_channel' to ['counts', 'counts', None, None, 'size_factors', 'size_factors']\n",
      "[INFO][2023-10-01 21:09:38,138][dance][set_config_from_dict] Setting config 'label_channel' to 'labels'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scRNA-ARI: 0.002 NMI: 0.012 scEpigenomics-ARI: 0.019 NMI: 0.052\n",
      "Finish training, total time is: 2.5105178356170654s\n",
      "False\n",
      "train likelihood is :  100000 epoch: 0\n",
      "Finish training, total time is: 2.0973620414733887s\n",
      "False\n",
      "train likelihood is :  100000 epoch: 0\n",
      "scRNA-ARI: 0.002 NMI: 0.009 scEpigenomics-ARI: 0.014 NMI: 0.045\n",
      "Finish training, total time is: 2.1798858642578125s\n",
      "False\n",
      "train likelihood is :  100000 epoch: 0\n",
      "[[ 7.7893804e-03  8.5386321e-02 -1.9330960e-03 ...  3.4647911e+00\n",
      "   3.7470562e+00 -2.5562053e+00]\n",
      " [-1.8570170e-01 -8.3318189e-02  9.6009038e-02 ...  3.2889309e+00\n",
      "   3.5041676e+00 -2.6117847e+00]\n",
      " [-1.8328802e-01 -6.4812332e-02 -2.9120460e-01 ...  2.7171960e+00\n",
      "   2.4213703e+00 -2.0959344e+00]\n",
      " ...\n",
      " [-8.3694747e-03 -3.1025354e-02 -1.0799071e-01 ...  2.2904475e+00\n",
      "   2.4613416e+00 -1.7188892e+00]\n",
      " [ 5.6520768e-02  3.6582332e-02 -3.7959747e-02 ...  3.1053631e+00\n",
      "   3.1622539e+00 -2.2706914e+00]\n",
      " [ 3.5017252e-02 -9.9636808e-02  1.7075598e-02 ...  2.3208294e+00\n",
      "   2.4863646e+00 -1.6979831e+00]]\n",
      "scRNA-ARI: 0.002 NMI: 0.009 scEpigenomics-ARI: 0.022 NMI: 0.073\n",
      "(0.009, 0.002, 0.073, 0.022)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-01 21:09:47,570][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_SKIN_atac2gex/GSE140203_SKIN_atac2gex.GSE140203_dataset.output_mod1.h5ad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMI: 0.121 ARI: 0.036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-01 21:09:48,842][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_SKIN_atac2gex/GSE140203_SKIN_atac2gex.GSE140203_dataset.output_mod2.h5ad\n",
      "[INFO][2023-10-01 21:09:49,066][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_SKIN_atac2gex/GSE140203_SKIN_atac2gex.GSE140203_dataset.output_train_mod1.h5ad\n",
      "[INFO][2023-10-01 21:09:51,665][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_SKIN_atac2gex/GSE140203_SKIN_atac2gex.GSE140203_dataset.output_train_mod2.h5ad\n",
      "[INFO][2023-10-01 21:09:52,116][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_SKIN_atac2gex/GSE140203_SKIN_atac2gex.GSE140203_dataset.output_solution.h5ad\n",
      "[INFO][2023-10-01 21:09:58,576][dance][_maybe_preprocess] Preprocessing done.\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/mudata/_core/mudata.py:491: UserWarning: Cannot join columns with the same name because var_names are intersecting.\n",
      "  warnings.warn(\n",
      "[INFO][2023-10-01 21:09:59,582][dance][load_data] Raw data loaded:\n",
      "Data object that wraps (.data):\n",
      "MuData object with n_obs × n_vars = 34054 × 732480\n",
      "  uns:\t'dance_config'\n",
      "  5 modalities\n",
      "    mod1:\t10217 x 10000\n",
      "      var:\t'start', 'end', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm'\n",
      "      uns:\t'dataset_id', 'hvg'\n",
      "      layers:\t'counts'\n",
      "    mod2:\t10217 x 10000\n",
      "      var:\t'gene', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm'\n",
      "      uns:\t'dataset_id', 'hvg'\n",
      "      layers:\t'counts'\n",
      "    meta1:\t23837 x 344592\n",
      "      var:\t'start', 'end'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "    meta2:\t23837 x 23296\n",
      "      var:\t'gene'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "    test_sol:\t10217 x 344592\n",
      "      obs:\t'atac.bc', 'cell_type'\n",
      "      var:\t'start', 'end'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "[INFO][2023-10-01 21:09:59,583][dance][wrapped_func] Took 0:00:12.013840 to load and process data.\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n",
      "[INFO][2023-10-01 21:10:01,541][dance][set_config_from_dict] Setting config 'feature_mod' to ['mod1', 'mod2', 'mod1', 'mod2', 'mod1', 'mod2']\n",
      "[INFO][2023-10-01 21:10:01,542][dance][set_config_from_dict] Setting config 'label_mod' to 'mod1'\n",
      "[INFO][2023-10-01 21:10:01,542][dance][set_config_from_dict] Setting config 'feature_channel_type' to ['layers', 'layers', None, None, 'obsm', 'obsm']\n",
      "[INFO][2023-10-01 21:10:01,542][dance][set_config_from_dict] Setting config 'feature_channel' to ['counts', 'counts', None, None, 'size_factors', 'size_factors']\n",
      "[INFO][2023-10-01 21:10:01,543][dance][set_config_from_dict] Setting config 'label_channel' to 'labels'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scRNA-ARI: 0.121 NMI: 0.041 scEpigenomics-ARI: 0.109 NMI: 0.045\n",
      "Finish training, total time is: 25.54280972480774s\n",
      "False\n",
      "train likelihood is :  100000 epoch: 0\n",
      "Finish training, total time is: 24.399454355239868s\n",
      "False\n",
      "train likelihood is :  100000 epoch: 0\n",
      "scRNA-ARI: 0.078 NMI: 0.107 scEpigenomics-ARI: 0.128 NMI: 0.084\n",
      "Finish training, total time is: 28.645615577697754s\n",
      "False\n",
      "train likelihood is :  100000 epoch: 0\n",
      "[[-0.25106993  0.28049928 -0.55008644 ... -2.5539322  -2.9442744\n",
      "  -3.1217422 ]\n",
      " [-0.02091426 -0.07577233 -0.7010712  ... -2.6711977  -3.130181\n",
      "  -2.84519   ]\n",
      " [-0.46733496 -0.06588307  0.46740353 ... -2.7163928  -3.0954204\n",
      "  -3.0968907 ]\n",
      " ...\n",
      " [ 0.7045505   0.30586278  0.21634519 ... -1.9041781  -3.1879153\n",
      "  -2.2486959 ]\n",
      " [ 0.36578104 -0.14034665 -0.12904985 ... -2.4020846  -2.7188373\n",
      "  -2.9552426 ]\n",
      " [-0.32595018 -0.04635978  0.03599662 ... -2.8619401  -2.8932853\n",
      "  -3.3556836 ]]\n",
      "scRNA-ARI: 0.078 NMI: 0.107 scEpigenomics-ARI: 0.19 NMI: 0.109\n",
      "(0.107, 0.078, 0.109, 0.19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-01 21:11:38,498][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_cite_gex2adt/openproblems_2022_cite_gex2adt.open_dataset.output_mod1.h5ad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMI: 0.15 ARI: 0.097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-01 21:11:40,069][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_cite_gex2adt/openproblems_2022_cite_gex2adt.open_dataset.output_mod2.h5ad\n",
      "[INFO][2023-10-01 21:11:40,164][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_cite_gex2adt/openproblems_2022_cite_gex2adt.open_dataset.output_train_mod1.h5ad\n",
      "[INFO][2023-10-01 21:11:44,555][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_cite_gex2adt/openproblems_2022_cite_gex2adt.open_dataset.output_train_mod2.h5ad\n",
      "[INFO][2023-10-01 21:11:44,698][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_cite_gex2adt/openproblems_2022_cite_gex2adt.open_dataset.output_solution.h5ad\n",
      "[INFO][2023-10-01 21:11:54,893][dance][_maybe_preprocess] Preprocessing done.\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/mudata/_core/mudata.py:491: UserWarning: Cannot join columns with the same name because var_names are intersecting.\n",
      "  warnings.warn(\n",
      "[INFO][2023-10-01 21:11:55,109][dance][load_data] Raw data loaded:\n",
      "Data object that wraps (.data):\n",
      "MuData object with n_obs × n_vars = 70988 × 54450\n",
      "  uns:\t'dance_config'\n",
      "  5 modalities\n",
      "    mod1:\t21297 x 10000\n",
      "      obs:\t'batch', 'cell_type'\n",
      "      var:\t'feature_types', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm'\n",
      "      uns:\t'dataset_id', 'hvg'\n",
      "      layers:\t'counts'\n",
      "    mod2:\t21297 x 140\n",
      "      obs:\t'batch'\n",
      "      var:\t'feature_types'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "    meta1:\t49691 x 22085\n",
      "      obs:\t'batch'\n",
      "      var:\t'feature_types'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "    meta2:\t49691 x 140\n",
      "      obs:\t'batch'\n",
      "      var:\t'feature_types'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "    test_sol:\t21297 x 22085\n",
      "      obs:\t'batch', 'cell_type'\n",
      "      var:\t'feature_types'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "[INFO][2023-10-01 21:11:55,111][dance][wrapped_func] Took 0:00:16.613155 to load and process data.\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n",
      "[INFO][2023-10-01 21:11:56,432][dance][set_config_from_dict] Setting config 'feature_mod' to ['mod1', 'mod2', 'mod1', 'mod2', 'mod1', 'mod2']\n",
      "[INFO][2023-10-01 21:11:56,434][dance][set_config_from_dict] Setting config 'label_mod' to 'mod1'\n",
      "[INFO][2023-10-01 21:11:56,435][dance][set_config_from_dict] Setting config 'feature_channel_type' to ['layers', 'layers', None, None, 'obsm', 'obsm']\n",
      "[INFO][2023-10-01 21:11:56,435][dance][set_config_from_dict] Setting config 'feature_channel' to ['counts', 'counts', None, None, 'size_factors', 'size_factors']\n",
      "[INFO][2023-10-01 21:11:56,436][dance][set_config_from_dict] Setting config 'label_channel' to 'labels'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scRNA-ARI: 0.041 NMI: 0.04 scEpigenomics-ARI: 0.134 NMI: 0.15\n",
      "Finish training, total time is: 39.55171251296997s\n",
      "False\n",
      "train likelihood is :  100000 epoch: 0\n",
      "Finish training, total time is: 35.00210785865784s\n",
      "False\n",
      "train likelihood is :  100000 epoch: 0\n",
      "scRNA-ARI: 0.155 NMI: 0.185 scEpigenomics-ARI: 0.274 NMI: 0.219\n",
      "Finish training, total time is: 34.28476905822754s\n",
      "False\n",
      "train likelihood is :  100000 epoch: 0\n",
      "[[-2.168189    3.9037285   3.1827476  ...  5.3174214  -0.6608299\n",
      "   1.1123077 ]\n",
      " [-2.6857333   4.4641213   4.4365983  ...  5.106319   -0.7351744\n",
      "   1.4727234 ]\n",
      " [-2.3172736   3.2875607   2.325252   ...  4.5123677  -1.3269365\n",
      "   1.3042661 ]\n",
      " ...\n",
      " [ 0.20897624  3.4813457   0.78894746 ...  4.3303175  -1.1400051\n",
      "   1.4252745 ]\n",
      " [ 0.02423564 -2.1603315   2.4668574  ...  3.4652672  -0.8617171\n",
      "   0.8102826 ]\n",
      " [-2.5454156   4.640644    2.5733957  ...  4.25856    -1.2654804\n",
      "   1.2884603 ]]\n",
      "scRNA-ARI: 0.155 NMI: 0.185 scEpigenomics-ARI: 0.104 NMI: 0.07\n",
      "(0.185, 0.155, 0.07, 0.104)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-01 21:14:07,142][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_multi_atac2gex/openproblems_2022_multi_atac2gex.open_dataset.output_mod1.h5ad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMI: 0.166 ARI: 0.098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-01 21:14:10,178][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_multi_atac2gex/openproblems_2022_multi_atac2gex.open_dataset.output_mod2.h5ad\n",
      "[INFO][2023-10-01 21:14:11,822][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_multi_atac2gex/openproblems_2022_multi_atac2gex.open_dataset.output_train_mod1.h5ad\n",
      "[INFO][2023-10-01 21:14:17,637][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_multi_atac2gex/openproblems_2022_multi_atac2gex.open_dataset.output_train_mod2.h5ad\n",
      "[INFO][2023-10-01 21:14:21,484][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_multi_atac2gex/openproblems_2022_multi_atac2gex.open_dataset.output_solution.h5ad\n",
      "[INFO][2023-10-01 21:14:48,725][dance][_maybe_preprocess] Preprocessing done.\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/mudata/_core/mudata.py:491: UserWarning: Cannot join columns with the same name because var_names are intersecting.\n",
      "  warnings.warn(\n",
      "[INFO][2023-10-01 21:14:49,242][dance][load_data] Raw data loaded:\n",
      "Data object that wraps (.data):\n",
      "MuData object with n_obs × n_vars = 105868 × 501302\n",
      "  uns:\t'dance_config'\n",
      "  5 modalities\n",
      "    mod1:\t31761 x 10000\n",
      "      obs:\t'batch'\n",
      "      var:\t'feature_types', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm'\n",
      "      uns:\t'dataset_id', 'hvg'\n",
      "      layers:\t'counts'\n",
      "    mod2:\t31761 x 10000\n",
      "      obs:\t'batch'\n",
      "      var:\t'feature_types', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm'\n",
      "      uns:\t'dataset_id', 'hvg'\n",
      "      layers:\t'counts'\n",
      "    meta1:\t74107 x 228942\n",
      "      obs:\t'batch'\n",
      "      var:\t'feature_types'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "    meta2:\t74107 x 23418\n",
      "      obs:\t'batch'\n",
      "      var:\t'feature_types'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "    test_sol:\t31761 x 228942\n",
      "      obs:\t'batch', 'cell_type'\n",
      "      var:\t'feature_types'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "[INFO][2023-10-01 21:14:49,246][dance][wrapped_func] Took 0:00:42.104384 to load and process data.\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py:373: UserWarning: Received a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n",
      "[INFO][2023-10-01 21:14:57,147][dance][set_config_from_dict] Setting config 'feature_mod' to ['mod1', 'mod2', 'mod1', 'mod2', 'mod1', 'mod2']\n",
      "[INFO][2023-10-01 21:14:57,148][dance][set_config_from_dict] Setting config 'label_mod' to 'mod1'\n",
      "[INFO][2023-10-01 21:14:57,150][dance][set_config_from_dict] Setting config 'feature_channel_type' to ['layers', 'layers', None, None, 'obsm', 'obsm']\n",
      "[INFO][2023-10-01 21:14:57,151][dance][set_config_from_dict] Setting config 'feature_channel' to ['counts', 'counts', None, None, 'size_factors', 'size_factors']\n",
      "[INFO][2023-10-01 21:14:57,152][dance][set_config_from_dict] Setting config 'label_channel' to 'labels'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scRNA-ARI: 0.011 NMI: 0.005 scEpigenomics-ARI: 0.028 NMI: 0.025\n",
      "Finish training, total time is: 99.04896450042725s\n",
      "False\n",
      "train likelihood is :  100000 epoch: 0\n",
      "Finish training, total time is: 59.12557649612427s\n",
      "False\n",
      "train likelihood is :  100000 epoch: 0\n",
      "scRNA-ARI: 0.201 NMI: 0.225 scEpigenomics-ARI: 0.004 NMI: 0.005\n",
      "Finish training, total time is: 68.65862393379211s\n",
      "False\n",
      "train likelihood is :  100000 epoch: 0\n",
      "[[-1.8570884   0.04997385 -1.162971   ... -0.6702888   3.4764884\n",
      "   0.4755263 ]\n",
      " [-1.9770805   0.43467298 -0.6536358  ... -0.5521196   3.5503116\n",
      "   0.25821343]\n",
      " [ 1.3098079   0.8582083   1.3729968  ... -0.07480803  4.2486453\n",
      "   1.8689553 ]\n",
      " ...\n",
      " [ 1.3577638  -0.5907472   0.10596782 ... -3.8812916   1.7039121\n",
      "   4.8353686 ]\n",
      " [-1.8294289   0.07269537 -0.33176917 ... -0.9449903   3.2171643\n",
      "  -0.3425314 ]\n",
      " [ 0.8234539   0.39255467  2.4930747  ... -3.0130513   3.590608\n",
      "  -1.1587826 ]]\n",
      "scRNA-ARI: 0.201 NMI: 0.225 scEpigenomics-ARI: 0.195 NMI: 0.254\n",
      "(0.225, 0.201, 0.254, 0.195)\n",
      "NMI: 0.286 ARI: 0.228\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'To reproduce DCCA on other samples, please refer to command lines belows:\\n\\nGEX-ADT:\\npython dcca.py --subtask openproblems_bmmc_cite_phase2 --device cuda\\n\\nGEX-ATAC:\\npython dcca.py --subtask openproblems_bmmc_multiome_phase2 --device cuda\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "DCCA_scores=[]\n",
    "\n",
    "import argparse\n",
    "\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import dance.utils.metrics as metrics\n",
    "from dance.datasets.multimodality import JointEmbeddingNIPSDataset\n",
    "from dance.modules.multi_modality.joint_embedding.dcca import DCCA\n",
    "import scanpy as sc\n",
    "\n",
    "def parameter_setting():\n",
    "    parser = argparse.ArgumentParser(description=\"Single cell Multi-omics data analysis\")\n",
    "\n",
    "    parser.add_argument(\"--latent_fusion\", \"-olf1\", type=str, default=\"First_simulate_fusion.csv\",\n",
    "                        help=\"fusion latent code file\")\n",
    "    parser.add_argument(\"--latent_1\", \"-ol1\", type=str, default=\"scRNA_latent_combine.csv\",\n",
    "                        help=\"first latent code file\")\n",
    "    parser.add_argument(\"--latent_2\", \"-ol2\", type=str, default=\"scATAC_latent.csv\", help=\"seconde latent code file\")\n",
    "    parser.add_argument(\"--denoised_1\", \"-od1\", type=str, default=\"scRNA_seq_denoised.csv\",\n",
    "                        help=\"outfile for denoised file1\")\n",
    "    parser.add_argument(\"--normalized_1\", \"-on1\", type=str, default=\"scRNA_seq_normalized_combine.tsv\",\n",
    "                        help=\"outfile for normalized file1\")\n",
    "    parser.add_argument(\"--denoised_2\", \"-od2\", type=str, default=\"scATAC_seq_denoised.csv\",\n",
    "                        help=\"outfile for denoised file2\")\n",
    "\n",
    "    parser.add_argument(\"--workdir\", \"-wk\", type=str, default=\"./new_test/\", help=\"work path\")\n",
    "    parser.add_argument(\"--outdir\", \"-od\", type=str, default=\"./new_test/\", help=\"Output path\")\n",
    "\n",
    "    parser.add_argument(\"--lr\", type=float, default=1E-3, help=\"Learning rate\")\n",
    "    parser.add_argument(\"--weight_decay\", type=float, default=1e-6, help=\"weight decay\")\n",
    "    parser.add_argument(\"--eps\", type=float, default=0.01, help=\"eps\")\n",
    "\n",
    "    parser.add_argument(\"--batch_size\", \"-b\", type=int, default=64, help=\"Batch size\")\n",
    "\n",
    "    parser.add_argument(\"--seed\", type=int, default=1, help=\"Random seed for repeat results\")\n",
    "    parser.add_argument(\"--latent\", \"-l\", type=int, default=10, help=\"latent layer dim\")\n",
    "    parser.add_argument(\"--max_epoch\", \"-me\", type=int, default=10, help=\"Max epoches\")\n",
    "    parser.add_argument(\"--max_iteration\", \"-mi\", type=int, default=1500, help=\"Max iteration\")\n",
    "    parser.add_argument(\"--anneal_epoch\", \"-ae\", type=int, default=200, help=\"Anneal epoch\")\n",
    "    parser.add_argument(\"--epoch_per_test\", \"-ept\", type=int, default=5, help=\"Epoch per test\")\n",
    "    parser.add_argument(\"--max_ARI\", \"-ma\", type=int, default=-200, help=\"initial ARI\")\n",
    "    parser.add_argument(\"-t\", \"--subtask\", default=\"openproblems_bmmc_cite_phase2\")\n",
    "    parser.add_argument(\"-device\", \"--device\", default=\"cuda\")\n",
    "    parser.add_argument(\"--final_rate\", type=float, default=1e-4)\n",
    "    parser.add_argument(\"--scale_factor\", type=float, default=4)\n",
    "    parser.add_argument(\"--span\", default=0.3, type=float)\n",
    "    return parser\n",
    "\n",
    "\n",
    "parser = parameter_setting()\n",
    "for dataset in datasets:\n",
    "    args = parser.parse_args(['--subtask',dataset,'--device','cuda',\"--span\",'1.0'])\n",
    "\n",
    "    args.sf1 = 5\n",
    "    args.sf2 = 1\n",
    "    args.cluster1 = args.cluster2 = 4\n",
    "    args.lr1 = 0.0001\n",
    "    args.flr1 = 0.0001\n",
    "    args.lr2 = 0.0005\n",
    "    args.flr2 = 0.0005\n",
    "\n",
    "    dataset = JointEmbeddingNIPSDataset(args.subtask, root=\"../../../../data/joint_embedding\", preprocess=\"feature_selection\",span=args.span)\n",
    "    data = dataset.load_data()\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    labels = le.fit_transform(data.mod[\"test_sol\"].obs[\"cell_type\"])\n",
    "    \n",
    "\n",
    "    # sc.pp.filter_genes(data.mod[\"mod1\"],min_counts=3)\n",
    "    # sc.pp.filter_genes(data.mod[\"mod2\"],min_counts=3)\n",
    "\n",
    "    sc.pp.log1p(data.mod[\"mod2\"])\n",
    "    sc.pp.log1p(data.mod[\"mod1\"])\n",
    "\n",
    "    \n",
    "    data.mod[\"mod2\"].obsm[\"size_factors\"] = np.sum(data.mod[\"mod2\"].X.todense(), 1) / 100\n",
    "    # # data.mod[\"mod1\"].obsm[\"size_factors\"] = data.mod[\"mod1\"].obs[\"size_factors\"]\n",
    "    data.mod[\"mod1\"].obsm[\"size_factors\"] = np.sum(data.mod[\"mod1\"].X.todense(), 1) / 100\n",
    "\n",
    "    \n",
    "    # data.mod[\"mod1\"].obsm[\"size_factors\"] = data.mod[\"mod1\"].obs[\"size_factors\"]\n",
    "    # data.mod[\"mod2\"].obsm[\"size_factors\"] = data.mod[\"mod1\"].obs[\"size_factors\"]\n",
    "\n",
    "    data.mod[\"mod1\"].obsm[\"labels\"] = labels\n",
    "\n",
    "    data.set_config(feature_mod=[\"mod1\", \"mod2\", \"mod1\", \"mod2\", \"mod1\", \"mod2\"], label_mod=\"mod1\",\n",
    "                    feature_channel_type=[\"layers\", \"layers\", None, None, \"obsm\", \"obsm\"],\n",
    "                    feature_channel=[\"counts\", \"counts\", None, None, \"size_factors\",\n",
    "                                     \"size_factors\"], label_channel=\"labels\")\n",
    "    (x_train, y_train, x_train_raw, y_train_raw, x_train_size,\n",
    "     y_train_size), train_labels = data.get_train_data(return_type=\"torch\")\n",
    "    (x_test, y_test, x_test_raw, y_test_raw, x_test_size,\n",
    "     y_test_size), test_labels = data.get_test_data(return_type=\"torch\")\n",
    "\n",
    "    Nfeature1 = x_train.shape[1]\n",
    "    Nfeature2 = y_train.shape[1]\n",
    "\n",
    "    device = torch.device(args.device)\n",
    "\n",
    "    model = DCCA(layer_e_1=[Nfeature1, 128], hidden1_1=128, Zdim_1=4, layer_d_1=[4, 128], hidden2_1=128,\n",
    "                 layer_e_2=[Nfeature2, 1500, 128], hidden1_2=128, Zdim_2=4, layer_d_2=[4], hidden2_2=4, args=args,\n",
    "                 Type_1=\"NB\", Type_2=\"Bernoulli\", ground_truth1=torch.cat([train_labels, test_labels]), cycle=1,\n",
    "                 attention_loss=\"Eucli\",droprate=0)  # yapf: disable\n",
    "    model.to(device)\n",
    "    train = data_utils.TensorDataset(x_train.float(), x_train_raw, x_train_size.float(), y_train.float(), y_train_raw,\n",
    "                                     y_train_size.float())\n",
    "\n",
    "\n",
    "    train_loader = data_utils.DataLoader(train, batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "    test = data_utils.TensorDataset(x_test.float(), x_test_raw, x_test_size.float(), y_test.float(), y_test_raw,\n",
    "                                    y_test_size.float())\n",
    "\n",
    "    test_loader = data_utils.DataLoader(test, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "    total = data_utils.TensorDataset(\n",
    "        torch.cat([x_train, x_test]).float(), torch.cat([x_train_raw, x_test_raw]),\n",
    "        torch.cat([x_train_size, x_test_size]).float(),\n",
    "        torch.cat([y_train, y_test]).float(), torch.cat([y_train_raw, y_test_raw]),\n",
    "        torch.cat([y_train_size, y_test_size]).float())\n",
    "\n",
    "    total_loader = data_utils.DataLoader(total, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "    model.fit(train_loader, test_loader, total_loader, \"RNA\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        emb1, emb2 = model.predict(total_loader)\n",
    "\n",
    "    embeds = np.concatenate([emb1, emb2], 1)\n",
    "    print(embeds)\n",
    "    print(model.score(total_loader))\n",
    "\n",
    "    mod1_obs = data.mod[\"mod1\"].obs\n",
    "    mod1_uns = data.mod[\"mod1\"].uns\n",
    "    adata = ad.AnnData(\n",
    "        X=embeds,\n",
    "        obs=mod1_obs,\n",
    "        uns={\n",
    "            \"dataset_id\": mod1_uns[\"dataset_id\"],\n",
    "            \"method_id\": \"scmogcn\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    NMI_score, ARI_score=metrics.labeled_clustering_evaluate(adata, data.mod[\"test_sol\"])\n",
    "    DCCA_scores.append({\"NMI_score\":NMI_score,\"ARI_score\":ARI_score})\n",
    "\"\"\"To reproduce DCCA on other samples, please refer to command lines belows:\n",
    "\n",
    "GEX-ADT:\n",
    "python dcca.py --subtask openproblems_bmmc_cite_phase2 --device cuda\n",
    "\n",
    "GEX-ATAC:\n",
    "python dcca.py --subtask openproblems_bmmc_multiome_phase2 --device cuda\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'NMI_score': 0.121, 'ARI_score': 0.036},\n",
       " {'NMI_score': 0.15, 'ARI_score': 0.097},\n",
       " {'NMI_score': 0.166, 'ARI_score': 0.098},\n",
       " {'NMI_score': 0.286, 'ARI_score': 0.228}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DCCA_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-03 15:06:37,185][dance][set_seed] Setting global random seed to 1206479118\n",
      "[INFO][2023-10-03 15:06:37,186][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_BRAIN_atac2gex/GSE140203_BRAIN_atac2gex.GSE140203_dataset.output_mod1.h5ad\n",
      "[INFO][2023-10-03 15:06:37,512][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_BRAIN_atac2gex/GSE140203_BRAIN_atac2gex.GSE140203_dataset.output_mod2.h5ad\n",
      "[INFO][2023-10-03 15:06:37,631][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_BRAIN_atac2gex/GSE140203_BRAIN_atac2gex.GSE140203_dataset.output_train_mod1.h5ad\n",
      "[INFO][2023-10-03 15:06:37,932][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_BRAIN_atac2gex/GSE140203_BRAIN_atac2gex.GSE140203_dataset.output_train_mod2.h5ad\n",
      "[INFO][2023-10-03 15:06:38,019][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_BRAIN_atac2gex/GSE140203_BRAIN_atac2gex.GSE140203_dataset.output_solution.h5ad\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py:843: UserWarning: Received a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py:843: UserWarning: Received a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n",
      "[INFO][2023-10-03 15:06:52,398][dance][_maybe_preprocess] Preprocessing done.\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/mudata/_core/mudata.py:491: UserWarning: Cannot join columns with the same name because var_names are intersecting.\n",
      "  warnings.warn(\n",
      "[INFO][2023-10-03 15:06:53,115][dance][load_data] Raw data loaded:\n",
      "Data object that wraps (.data):\n",
      "MuData object with n_obs × n_vars = 3291 × 897209\n",
      "  uns:\t'dance_config'\n",
      "  5 modalities\n",
      "    mod1:\t3291 x 10000\n",
      "      var:\t'num', 'start', 'end', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm', 'mean', 'std'\n",
      "      uns:\t'dataset_id', 'hvg'\n",
      "      layers:\t'counts'\n",
      "    mod2:\t3291 x 10000\n",
      "      var:\t'gene', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm', 'mean', 'std'\n",
      "      uns:\t'dataset_id', 'hvg'\n",
      "      layers:\t'counts'\n",
      "    meta1:\t2303 x 428041\n",
      "      var:\t'num', 'start', 'end'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "    meta2:\t2303 x 21127\n",
      "      var:\t'gene'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "    test_sol:\t3291 x 428041\n",
      "      obs:\t'atac.bc', 'cell_type'\n",
      "      var:\t'num', 'start', 'end'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "[INFO][2023-10-03 15:06:53,117][dance][wrapped_func] Took 0:00:15.931433 to load and process data.\n",
      "[INFO][2023-10-03 15:06:53,119][dance][set_config_from_dict] Setting config 'feature_mod' to ['mod1', 'mod2']\n",
      "[INFO][2023-10-03 15:06:53,120][dance][set_config_from_dict] Setting config 'label_mod' to 'mod1'\n",
      "[INFO][2023-10-03 15:06:53,121][dance][set_config_from_dict] Setting config 'feature_channel' to ['counts', 'counts']\n",
      "[INFO][2023-10-03 15:06:53,122][dance][set_config_from_dict] Setting config 'feature_channel_type' to ['layers', 'layers']\n",
      "[INFO][2023-10-03 15:06:53,123][dance][set_config_from_dict] Setting config 'label_channel' to 'labels'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2303, 10000]) torch.Size([988, 10000])\n",
      "19 1 2 20000\n",
      "epoch 0\n",
      "loss1 2.973365271792692, loss2 2.7845839191885555, loss3 -1.1687184553466068e-09, loss4 0.37793319190249725, \n",
      "val-loss1 3.060255527496338 val-loss2 2.7973666191101074 val-loss3 -5.160574745310953e-10 val-loss4 0.021960800513625145\n",
      "val score 2.702750233069336\n",
      "epoch 1\n",
      "loss1 3.1081478735979866, loss2 2.2150117369259106, loss3 -1.1687184553466068e-09, loss4 0.29792946752379923, \n",
      "val-loss1 3.0539305210113525 val-loss2 2.3885557651519775 val-loss3 -5.160574745310953e-10 val-loss4 0.045025117695331573\n",
      "val score 2.617713773597306\n",
      "epoch 2\n",
      "loss1 3.062740417087779, loss2 1.9152780210270601, loss3 -1.1687184553466068e-09, loss4 0.2709759377381381, \n",
      "val-loss1 3.0444154739379883 val-loss2 2.028909683227539 val-loss3 -5.160574745310953e-10 val-loss4 0.052663687616586685\n",
      "val score 2.5395059527571258\n",
      "epoch 3\n",
      "loss1 2.9800869997809913, loss2 1.693169404478634, loss3 -1.1687184553466068e-09, loss4 0.2544134495889439, \n",
      "val-loss1 3.027827739715576 val-loss2 1.7691762447357178 val-loss3 -5.160574745310953e-10 val-loss4 0.0631512999534607\n",
      "val score 2.476472231719917\n",
      "epoch 4\n",
      "loss1 2.998134269433863, loss2 1.5148883847629322, loss3 -1.1687184553466068e-09, loss4 0.21395561887937434, \n",
      "val-loss1 3.009948968887329 val-loss2 1.5992752313613892 val-loss3 -5.160574745310953e-10 val-loss4 0.06481188535690308\n",
      "val score 2.4300599187354504\n",
      "epoch 5\n",
      "loss1 2.9166195112116196, loss2 1.375618997742148, loss3 -1.1687184553466068e-09, loss4 0.2156453342998729, \n",
      "val-loss1 2.9828011989593506 val-loss2 1.5358259677886963 val-loss3 -5.160574745310953e-10 val-loss4 0.05650978907942772\n",
      "val score 2.397951522257453\n",
      "epoch 6\n",
      "loss1 2.9603207672343537, loss2 1.255919386358822, loss3 -1.1687184553466068e-09, loss4 0.18761067881303675, \n",
      "val-loss1 2.9410741329193115 val-loss2 1.3718653917312622 val-loss3 -5.160574745310953e-10 val-loss4 0.06411519646644592\n",
      "val score 2.3363307311872896\n",
      "epoch 7\n",
      "loss1 2.7969952120500454, loss2 1.1767568167518168, loss3 -1.1687184553466068e-09, loss4 0.1765489026027567, \n",
      "val-loss1 2.860792636871338 val-loss2 1.383195400238037 val-loss3 -5.160574745310953e-10 val-loss4 0.03899463266134262\n",
      "val score 2.281143657464808\n",
      "epoch 8\n",
      "loss1 2.7847543534110573, loss2 1.0952420760603512, loss3 -1.1687184553466068e-09, loss4 0.16779108608470245, \n",
      "val-loss1 2.7466204166412354 val-loss2 1.2815505266189575 val-loss3 -5.160574745310953e-10 val-loss4 0.06324871629476547\n",
      "val score 2.1821068327615913\n",
      "epoch 9\n",
      "loss1 2.6118335443384506, loss2 1.0578356174861683, loss3 -1.1687184553466068e-09, loss4 0.1731893621823367, \n",
      "val-loss1 2.5932226181030273 val-loss2 1.259961485862732 val-loss3 -5.160574745310953e-10 val-loss4 0.04677756130695343\n",
      "val score 2.06958700788421\n",
      "epoch 10\n",
      "loss1 2.4493794826900257, loss2 0.9872951472506803, loss3 -1.1687184553466068e-09, loss4 0.166644044658717, \n",
      "val-loss1 2.4741504192352295 val-loss2 1.2914198637008667 val-loss3 -5.160574745310953e-10 val-loss4 0.03507084399461746\n",
      "val score 1.9919428083787618\n",
      "epoch 11\n",
      "loss1 2.3919027342515835, loss2 0.9590476821450626, loss3 -1.1687184553466068e-09, loss4 0.14816509274875417, \n",
      "val-loss1 2.374943256378174 val-loss2 1.3080557584762573 val-loss3 -5.160574745310953e-10 val-loss4 0.031871501356363297\n",
      "val score 1.9256650062019884\n",
      "epoch 12\n",
      "loss1 2.174081865478964, loss2 0.9891939934562234, loss3 -1.1687184553466068e-09, loss4 0.14356079303166447, \n",
      "val-loss1 2.2175064086914062 val-loss2 1.231766700744629 val-loss3 -5.160574745310953e-10 val-loss4 0.03147832304239273\n",
      "val score 1.8001817423592266\n",
      "epoch 13\n",
      "loss1 1.987701275769402, loss2 0.9378684583832236, loss3 -1.1687184553466068e-09, loss4 0.13230419728685827, \n",
      "val-loss1 2.0836334228515625 val-loss2 1.233912467956543 val-loss3 -5.160574745310953e-10 val-loss4 0.03399694710969925\n",
      "val score 1.7070257369170843\n",
      "epoch 14\n",
      "loss1 1.8733594698064469, loss2 0.9267975723042208, loss3 -1.1687184553466068e-09, loss4 0.1255076510064742, \n",
      "val-loss1 1.9371731281280518 val-loss2 1.1736595630645752 val-loss3 -5.160574745310953e-10 val-loss4 0.030205227434635162\n",
      "val score 1.59226336364848\n",
      "epoch 15\n",
      "loss1 1.719910411273732, loss2 0.8700343580806956, loss3 -1.1687184553466068e-09, loss4 0.1243455914013526, \n",
      "val-loss1 1.8089878559112549 val-loss2 1.1861066818237305 val-loss3 -5.160574745310953e-10 val-loss4 0.030114123597741127\n",
      "val score 1.5050185416567088\n",
      "epoch 16\n",
      "loss1 1.6522123953875374, loss2 0.8492318707353929, loss3 -1.1687184553466068e-09, loss4 0.11814471641007591, \n",
      "val-loss1 1.7429274320602417 val-loss2 1.1495920419692993 val-loss3 -5.160574745310953e-10 val-loss4 0.030044596642255783\n",
      "val score 1.451469840642339\n",
      "epoch 17\n",
      "loss1 1.5480369434637182, loss2 0.8319208236301646, loss3 -1.1687184553466068e-09, loss4 0.11667177037281148, \n",
      "val-loss1 1.68728506565094 val-loss2 1.1956992149353027 val-loss3 -5.160574745310953e-10 val-loss4 0.0250843595713377\n",
      "val score 1.4214936068954824\n",
      "epoch 18\n",
      "loss1 1.4835627710118013, loss2 0.7865345267688527, loss3 -1.1687184553466068e-09, loss4 0.1130142711541232, \n",
      "val-loss1 1.6713438034057617 val-loss2 1.1040061712265015 val-loss3 -5.160574745310953e-10 val-loss4 0.021482281386852264\n",
      "val score 1.3918160106728732\n",
      "epoch 19\n",
      "loss1 1.445247134741615, loss2 0.7580985111348769, loss3 -1.1687184553466068e-09, loss4 0.11107483681510477, \n",
      "val-loss1 1.6036732196807861 val-loss2 1.1152957677841187 val-loss3 -5.160574745310953e-10 val-loss4 0.028634032234549522\n",
      "val score 1.3470621089192987\n",
      "epoch 20\n",
      "loss1 1.4061928812195272, loss2 0.6973841085153467, loss3 -1.1687184553466068e-09, loss4 0.10836549147086985, \n",
      "val-loss1 1.5824618339538574 val-loss2 1.0656938552856445 val-loss3 -5.160574745310953e-10 val-loss4 0.022823411971330643\n",
      "val score 1.3220032253975924\n",
      "epoch 21\n",
      "loss1 1.374789066174451, loss2 0.6762137202655568, loss3 -1.1687184553466068e-09, loss4 0.10929234457366607, \n",
      "val-loss1 1.5131264925003052 val-loss2 1.0722993612289429 val-loss3 -5.160574745310953e-10 val-loss4 0.020054325461387634\n",
      "val score 1.2746511332432688\n",
      "epoch 22\n",
      "loss1 1.3547856176600737, loss2 0.6525001315509572, loss3 -1.1687184553466068e-09, loss4 0.098844855585519, \n",
      "val-loss1 1.5015653371810913 val-loss2 0.9962106943130493 val-loss3 -5.160574745310953e-10 val-loss4 0.021037325263023376\n",
      "val score 1.251389741126722\n",
      "epoch 23\n",
      "loss1 1.3416053968317367, loss2 0.6382206608267391, loss3 -1.1687184553466068e-09, loss4 0.1015563247834935, \n",
      "val-loss1 1.4703503847122192 val-loss2 1.0182571411132812 val-loss3 -5.160574745310953e-10 val-loss4 0.01764914207160473\n",
      "val score 1.233779154598987\n",
      "epoch 24\n",
      "loss1 1.2754738050348617, loss2 0.6072826105005601, loss3 -1.1687184553466068e-09, loss4 0.09461083394639633, \n",
      "val-loss1 1.511489987373352 val-loss2 1.0112067461013794 val-loss3 -5.160574745310953e-10 val-loss4 0.01705111376941204\n",
      "val score 1.26113689604429\n",
      "epoch 25\n",
      "loss1 1.2892149336197798, loss2 0.5506111067884109, loss3 -1.1687184553466068e-09, loss4 0.10265897652682136, \n",
      "val-loss1 1.453848123550415 val-loss2 0.9822718501091003 val-loss3 -5.160574745310953e-10 val-loss4 0.016707098111510277\n",
      "val score 1.2149834113868834\n",
      "epoch 26\n",
      "loss1 1.2833532936432783, loss2 0.578794645912507, loss3 -1.1687184553466068e-09, loss4 0.09176748947185628, \n",
      "val-loss1 1.417324185371399 val-loss2 1.049675703048706 val-loss3 -5.160574745310953e-10 val-loss4 0.017865128815174103\n",
      "val score 1.2029553267846762\n",
      "epoch 27\n",
      "loss1 1.27977174169877, loss2 0.5221886108903324, loss3 -1.1687184553466068e-09, loss4 0.08952335092951269, \n",
      "val-loss1 1.4353433847427368 val-loss2 0.9716054797172546 val-loss3 -5.160574745310953e-10 val-loss4 0.021073728799819946\n",
      "val score 1.2001151516775548\n",
      "epoch 28\n",
      "loss1 1.2223712591563953, loss2 0.5096278436043683, loss3 -1.1687184553466068e-09, loss4 0.09033938453477972, \n",
      "val-loss1 1.4534850120544434 val-loss2 0.9521641731262207 val-loss3 -5.160574745310953e-10 val-loss4 0.016953997313976288\n",
      "val score 1.2087200429032503\n",
      "epoch 29\n",
      "loss1 1.221480162704692, loss2 0.510885568226085, loss3 -1.1687184553466068e-09, loss4 0.0896477304837283, \n",
      "val-loss1 1.4081000089645386 val-loss2 0.9879249334335327 val-loss3 -5.160574745310953e-10 val-loss4 0.019619401544332504\n",
      "val score 1.1842359630132973\n",
      "epoch 30\n",
      "loss1 1.2450942151686724, loss2 0.486113495686475, loss3 -1.1687184553466068e-09, loss4 0.0822038058848942, \n",
      "val-loss1 1.402183175086975 val-loss2 1.0125348567962646 val-loss3 -5.160574745310953e-10 val-loss4 0.01802869513630867\n",
      "val score 1.184936628651148\n",
      "epoch 31\n",
      "loss1 1.2148957883610445, loss2 0.4561999597970177, loss3 -1.1687184553466068e-09, loss4 0.0805182599407785, \n",
      "val-loss1 1.4205210208892822 val-loss2 0.9145888686180115 val-loss3 -5.160574745310953e-10 val-loss4 0.014324567280709743\n",
      "val score 1.1779987166843324\n",
      "epoch 32\n",
      "loss1 1.328656420988195, loss2 0.4326033750001122, loss3 -1.1687184553466068e-09, loss4 0.07756062794257612, \n",
      "val-loss1 1.4195754528045654 val-loss2 0.9332606792449951 val-loss3 -5.160574745310953e-10 val-loss4 0.010275847278535366\n",
      "val score 1.1808687451503186\n",
      "epoch 33\n",
      "loss1 1.199654189979329, loss2 0.42498736521776986, loss3 -1.1687184553466068e-09, loss4 0.07443873365135754, \n",
      "val-loss1 1.4282820224761963 val-loss2 0.8759787678718567 val-loss3 -5.160574745310953e-10 val-loss4 0.020619474351406097\n",
      "val score 1.176024142999476\n",
      "epoch 34\n",
      "loss1 1.1968722764183493, loss2 0.3856709424187155, loss3 -1.1687184553466068e-09, loss4 0.07787076296175227, \n",
      "val-loss1 1.433719515800476 val-loss2 0.9060555100440979 val-loss3 -5.160574745310953e-10 val-loss4 0.019593501463532448\n",
      "val score 1.1857944381165264\n",
      "epoch 35\n",
      "loss1 1.3089063623372246, loss2 0.40545090682366314, loss3 -1.1687184553466068e-09, loss4 0.07002008596763891, \n",
      "val-loss1 1.405752420425415 val-loss2 0.9041056632995605 val-loss3 -5.160574745310953e-10 val-loss4 0.01195954903960228\n",
      "val score 1.1654458043838798\n",
      "epoch 36\n",
      "loss1 1.1684583951445187, loss2 0.37582440411343293, loss3 -1.1687184553466068e-09, loss4 0.07180196331704364, \n",
      "val-loss1 1.370583415031433 val-loss2 0.8513463735580444 val-loss3 -5.160574745310953e-10 val-loss4 0.011713823303580284\n",
      "val score 1.130263356372988\n",
      "epoch 37\n",
      "loss1 1.2168923581347746, loss2 0.3584785829572117, loss3 -1.1687184553466068e-09, loss4 0.07357756311402601, \n",
      "val-loss1 1.3663129806518555 val-loss2 0.9228523969650269 val-loss3 -5.160574745310953e-10 val-loss4 0.00968402624130249\n",
      "val score 1.1414737671355664\n",
      "epoch 38\n",
      "loss1 1.1964499319300932, loss2 0.3697347553337322, loss3 -1.1687184553466068e-09, loss4 0.06883281578912455, \n",
      "val-loss1 1.3800127506256104 val-loss2 0.7911868691444397 val-loss3 -5.160574745310953e-10 val-loss4 0.00944480299949646\n",
      "val score 1.124718539390987\n",
      "epoch 39\n",
      "loss1 1.220299194840824, loss2 0.3636273513821995, loss3 -1.1687184553466068e-09, loss4 0.06752738772946246, \n",
      "val-loss1 1.3727200031280518 val-loss2 0.8532991409301758 val-loss3 -5.160574745310953e-10 val-loss4 0.010940197855234146\n",
      "val score 1.13211084024263\n",
      "epoch 40\n",
      "loss1 1.1461987740853254, loss2 0.352665983578738, loss3 -1.1687184553466068e-09, loss4 0.06619277114377302, \n",
      "val-loss1 1.4191654920578003 val-loss2 0.8078623414039612 val-loss3 -5.160574745310953e-10 val-loss4 0.010243928991258144\n",
      "val score 1.1555005091450123\n",
      "epoch 41\n",
      "loss1 1.2155074547318852, loss2 0.352641282712712, loss3 -1.1687184553466068e-09, loss4 0.06678151295465581, \n",
      "val-loss1 1.363515853881836 val-loss2 0.8497504591941833 val-loss3 -5.160574745310953e-10 val-loss4 0.012218145653605461\n",
      "val score 1.1250220968129991\n",
      "epoch 42\n",
      "loss1 1.1521997872520895, loss2 0.31823649388902325, loss3 -1.1687184553466068e-09, loss4 0.059469031060443205, \n",
      "val-loss1 1.36531662940979 val-loss2 0.8118053078651428 val-loss3 -5.160574745310953e-10 val-loss4 0.013319226913154125\n",
      "val score 1.1187486634797363\n",
      "epoch 43\n",
      "loss1 1.1441918015480042, loss2 0.31720386971445647, loss3 -1.1687184553466068e-09, loss4 0.05485678858616773, \n",
      "val-loss1 1.3753098249435425 val-loss2 0.8025291562080383 val-loss3 -5.160574745310953e-10 val-loss4 0.008546954952180386\n",
      "val score 1.1236500564238936\n",
      "epoch 44\n",
      "loss1 1.1715188517290003, loss2 0.3035336724098991, loss3 -1.1687184553466068e-09, loss4 0.05669802273897564, \n",
      "val-loss1 1.371670126914978 val-loss2 0.7635849714279175 val-loss3 -5.160574745310953e-10 val-loss4 0.009439942426979542\n",
      "val score 1.113358080221614\n",
      "epoch 45\n",
      "loss1 1.1666589484495276, loss2 0.27758217909756827, loss3 -1.1687184553466068e-09, loss4 0.0558603942832526, \n",
      "val-loss1 1.3660091161727905 val-loss2 0.7727789282798767 val-loss3 -5.160574745310953e-10 val-loss4 0.009494183585047722\n",
      "val score 1.111236876130378\n",
      "epoch 46\n",
      "loss1 1.1136781748603373, loss2 0.2605605975669973, loss3 -1.1687184553466068e-09, loss4 0.05338049044503885, \n",
      "val-loss1 1.3628501892089844 val-loss2 0.7830015420913696 val-loss3 -5.160574745310953e-10 val-loss4 0.006928690709173679\n",
      "val score 1.1109418753742186\n",
      "epoch 47\n",
      "loss1 1.1155345054233776, loss2 0.2611422845545937, loss3 -1.1687184553466068e-09, loss4 0.05443949975511607, \n",
      "val-loss1 1.357003927230835 val-loss2 0.7311558723449707 val-loss3 -5.160574745310953e-10 val-loss4 0.0069904145784676075\n",
      "val score 1.0964834442336993\n",
      "epoch 48\n",
      "loss1 1.512685849386103, loss2 0.2549915304955314, loss3 -1.1687184553466068e-09, loss4 0.055310797384556604, \n",
      "val-loss1 1.496585488319397 val-loss2 0.8142663240432739 val-loss3 -5.160574745310953e-10 val-loss4 0.004863199312239885\n",
      "val score 1.2107062665720418\n",
      "epoch 49\n",
      "loss1 1.1140739041216232, loss2 0.2726966160185197, loss3 -1.1687184553466068e-09, loss4 0.05138520480078809, \n",
      "val-loss1 1.3743005990982056 val-loss2 0.8482462763786316 val-loss3 -5.160574745310953e-10 val-loss4 0.008074783720076084\n",
      "val score 1.1320634138046712\n",
      "epoch 50\n",
      "loss1 1.1829543674693388, loss2 0.2579820638193804, loss3 -1.1687184553466068e-09, loss4 0.04759999518008793, \n",
      "val-loss1 1.3798350095748901 val-loss2 0.7540189027786255 val-loss3 -5.160574745310953e-10 val-loss4 0.006357073783874512\n",
      "val score 1.1170061409215388\n",
      "epoch 51\n",
      "loss1 1.132250642075258, loss2 0.25439300431924705, loss3 -1.1687184553466068e-09, loss4 0.047168337685220385, \n",
      "val-loss1 1.3670231103897095 val-loss2 0.7827875018119812 val-loss3 -5.160574745310953e-10 val-loss4 0.004903494380414486\n",
      "val score 1.1137188523284105\n",
      "epoch 52\n",
      "loss1 1.463422617491554, loss2 0.24839504150783315, loss3 -1.1687184553466068e-09, loss4 0.04926876351237297, \n",
      "val-loss1 1.4702718257904053 val-loss2 0.849004328250885 val-loss3 -5.160574745310953e-10 val-loss4 0.0038777512963861227\n",
      "val score 1.199185031242477\n",
      "epoch 53\n",
      "loss1 1.131542675635394, loss2 0.26821670023834004, loss3 -1.1687184553466068e-09, loss4 0.04491107319207752, \n",
      "val-loss1 1.479493260383606 val-loss2 0.7780134677886963 val-loss3 -5.160574745310953e-10 val-loss4 0.005906905047595501\n",
      "val score 1.19154332105284\n",
      "epoch 54\n",
      "loss1 1.1096314857987797, loss2 0.22509512655875263, loss3 -1.1687184553466068e-09, loss4 0.04572655917967067, \n",
      "val-loss1 1.3778538703918457 val-loss2 0.7569550275802612 val-loss3 -5.160574745310953e-10 val-loss4 0.00518635381013155\n",
      "val score 1.116148032455048\n",
      "epoch 55\n",
      "loss1 1.1672090467284708, loss2 0.2186319573837168, loss3 -1.1687184553466068e-09, loss4 0.04499633478767732, \n",
      "val-loss1 1.3298732042312622 val-loss2 0.7709185481071472 val-loss3 -5.160574745310953e-10 val-loss4 0.004251175560057163\n",
      "val score 1.0853075113355128\n",
      "epoch 56\n",
      "loss1 1.1279060489991133, loss2 0.22807262136655695, loss3 -1.1687184553466068e-09, loss4 0.04197352795916445, \n",
      "val-loss1 1.3662108182907104 val-loss2 0.6866440176963806 val-loss3 -5.160574745310953e-10 val-loss4 0.005944880191236734\n",
      "val score 1.0939736203265322\n",
      "epoch 57\n",
      "loss1 1.1903956918155445, loss2 0.2023021342123256, loss3 -1.1687184553466068e-09, loss4 0.038408885764725065, \n",
      "val-loss1 1.3414487838745117 val-loss2 0.7108843922615051 val-loss3 -5.160574745310953e-10 val-loss4 0.0051894476637244225\n",
      "val score 1.0814504995218424\n",
      "epoch 58\n",
      "loss1 1.120884979472441, loss2 0.2115071547382018, loss3 -1.1687184553466068e-09, loss4 0.0399308808367042, \n",
      "val-loss1 1.344205379486084 val-loss2 0.6797035336494446 val-loss3 -5.160574745310953e-10 val-loss4 0.005490005481988192\n",
      "val score 1.077158972618444\n",
      "epoch 59\n",
      "loss1 1.1378945112228394, loss2 0.20148435585639057, loss3 -1.1687184553466068e-09, loss4 0.0375997196225559, \n",
      "val-loss1 1.3312392234802246 val-loss2 0.7214459180831909 val-loss3 -5.160574745310953e-10 val-loss4 0.004586824681609869\n",
      "val score 1.076385981261073\n",
      "[[-0.88394195  1.4053359   0.17940539 ...  0.6793143   0.3189783\n",
      "  -0.46786752]\n",
      " [-0.05898153  1.2122064  -0.03101709 ... -1.2497703  -1.3494095\n",
      "   1.334993  ]\n",
      " [-0.9895313  -2.0832038  -4.067943   ... -8.238155   -5.7161355\n",
      "   6.581509  ]\n",
      " ...\n",
      " [ 0.03690852 -2.1140878  -0.33120823 ... -1.285618   -0.13103923\n",
      "   0.5460338 ]\n",
      " [-0.14236902 -0.9810087   0.1479822  ...  0.39100814  0.20612113\n",
      "  -0.55080914]\n",
      " [-0.05380078 -1.5632367   0.4612312  ... -0.66958123  0.03814985\n",
      "   0.157733  ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-03 15:08:20,868][dance][set_seed] Setting global random seed to 1206479118\n",
      "[INFO][2023-10-03 15:08:20,869][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_SKIN_atac2gex/GSE140203_SKIN_atac2gex.GSE140203_dataset.output_mod1.h5ad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  5 18  3 18 10 10 11  6  7  3 10  8  1  4 18 17 12  9 18 10  5  5 17\n",
      "  1 10 15 12  6 13  6 13  0 16  6  4 11 18 10 10  4 10  1 10 12 10  4 11\n",
      "  2 10 10 10 12  3  3  6 14 15  1  0 17 10  9  4  6  1 15 11  2  8  2  5\n",
      " 15  5 10 13  6 11 12 16 11  1  1 10  4 10 10 16 10 15 10  6 15 11  1  9\n",
      " 17  3  3  3  3  3  3 14  2 17  5 15 15 12 17 10 14 10  0 10 10 15 15  5\n",
      " 14  1 10  1 10  3 15 10  1  1 15 16  5 10  1  5  3  1  3 10 10 10  2 15\n",
      "  1 11 10 16  5  3  2 18  5 18 11  1  3 10  5  1 11  2  2 10 11 18 18  6\n",
      "  9 10  7 10 17  1  2  5  9 10  0  3 17  2  4 15  5 10  1  3 10  7 12  3\n",
      "  7  2  1  2  6  4  6 18 10 17 10  0  1  5 17 10 15 10  0 16  0 10  5  5\n",
      " 10  1 10 10  5  2  3 12  2 18 18 16 18  7 15 17 16 16 15 15 10 15  2 14\n",
      " 10  2 11  5 12  5  5 18  2  1  1 15 18  4  6  8 11  0 17 15 13  4  1  7\n",
      "  1  1 10  4  6  1  6 12 10  2  4 10 10  3  5  2  4  0 11  0  2  9  3 12\n",
      " 10 11 10 11  1 10  8 11 10 17 10  1 10  2  7  5  7 10 12 10 15 10  6 10\n",
      " 16  8 10 14 10  5 16  2 15 15 10 10 10 10  5 10  1  2  3 10 10  9 10 15\n",
      " 10  6  5  1  1  1  1  3 10  4  7 18  4  4 13  6  3  3 13  1 12  3  2 13\n",
      "  5 15 18  2  1  4  0 10 10  4  1  4  1 10 12 10 13 10 10  4  1 10 14  5\n",
      "  2  1 10 12 15  1 10  3 10  3 13  3 10  2 10  1 12  8 18 10  3  4  9 15\n",
      "  0  1 18 10 10  7 10  3  5  7  1 10 10  2  3  9  5  3  5 13 10  1  5  4\n",
      " 16 10  2  2 10 10 10 18  6  1  2  1 10  2 15  7 10  1  5 18 10  1  5  0\n",
      " 10  7 13  5  2 10  1  5 15 10  5  0 10  5  6  2 18  5  5 11 18 18  5 12\n",
      "  0  1 10  4  7 17  8  1 17 10 15  9 10  2 10 10  2  9  1 10 15 13 18 10\n",
      "  1 18  6  0  6 15 10  5 13 15  5  2  0  8 11 11 10  4 10  3 16 10  7 11\n",
      "  5  7  4  6  1  1  4 12 14 11  1  4  7  1 16 11  2  6 18 18  5  9  1  4\n",
      " 10  3  3 10 11  0  1  3 12  0 10  1 10 15  4 10  7 10 10 18 13  2  1  3\n",
      "  2 10  3  4  1 14 14  1  4 15  5  2  9 17  7  1  3  5 15 10  8 10 10  3\n",
      " 16 14 10  6 18  2 10  2  5 16  6  3 11 16  5  2 14 11 10 16 12  0  5  1\n",
      " 11  7 12  5  1  0  1 10 18  6  2  3 11 10 11 17 10 18 14  0  6 17  4 16\n",
      "  4 10 10 11  4 10  3 17  5 17 17  6  4 18 10 18 12  5 12 12 16  5 11  2\n",
      "  3 11 10 16 11 11 16  8  5 12 10  1 18 16 17  5  3 16  3  1 15 11 15 18\n",
      " 10 15 17 15 11  2 10 17  7  5  5 11  4 10 10  0 16 10  0 15 10 10 15  0\n",
      "  4  7 10  1  1  6  0  0 15  8 10 15  1 10 16  5  7 11  3 16 11  2 10 17\n",
      " 17  2 17  6 10 12  6 16  3  2 10  7  9 18  0  1  1 18 15  6  3  6  0 10\n",
      " 10 12  4  1  7  3  5 10  8 10  2 10 16  7 17  4 18  1 12 10 17  1  0 13\n",
      " 10  5  4 17 11  0 11  7 10  2 15 17  6  4 10 13  4  1 18 16  3 10 10  6\n",
      " 10  2 10  1  6  3  3  4  3  5 10  1 13 12  6 11  2  0 13 10  1  8 15  4\n",
      "  1  1  5  1 10  0 10 11  3 12 10  9 17 17  2  0  5  2  0  3 11 14  2  1\n",
      " 10 10  7 11 15  2  4  5 17 13 11 16  6  8  4  1 14  2 16  8  0 10  4 10\n",
      " 11 15 11  8 18 13 17 11 18 10 10  4  1 10  2 12  1  4 12  4 10 17 10  6\n",
      " 17  4  5  9 15 10 11 18  5  1  1  1 14  7 18  1  0  5 10 11 11 10  7  2\n",
      "  5  1  4  4  9 10 11  7  2  1  6 12  8 16  1  4  3  6  4  6  4  3  8  6\n",
      "  4  1  2 12  1  1 10 16 14 10 11 10 14 10 14 10  6  4 15  1 14  4  9 15\n",
      "  2 10  9 10] [7 1 3 1 6 0 5 6 6 0 7 8 7 1 1 5 5 0 0 4 8 7 0 5 1 8 3 4 4 0 6 8 4 5 4 0 4\n",
      " 8 4 8 1 8 7 6 4 0 9 0 0 0 8 6 4 5 6 6 6 6 7 5 5 5 4 1 4 7 9 4 0 0 0 1 9 1\n",
      " 9 8 6 0 4 4 0 7 5 8 1 6 8 5 8 3 4 6 1 4 1 9 5 7 7 1 7 1 4 6 4 5 1 3 6 8 5\n",
      " 8 6 8 5 8 8 4 5 1 9 1 6 7 8 5 9 8 7 1 3 5 1 8 7 7 1 1 6 8 4 8 0 6 1 9 8 5\n",
      " 9 7 4 8 1 9 4 7 7 5 9 1 4 1 0 8 8 5 6 9 6 6 4 8 5 5 0 1 9 4 5 7 5 0 1 9 1\n",
      " 8 1 7 4 6 4 0 9 4 7 0 6 1 6 6 8 5 8 4 1 1 5 8 1 8 5 5 8 4 1 1 6 1 5 8 1 0\n",
      " 1 6 4 6 6 5 9 9 1 5 5 4 9 9 8 9 6 6 8 6 6 1 4 1 1 5 0 7 1 3 9 1 4 1 6 5 5\n",
      " 9 8 0 7 4 1 1 6 1 9 7 4 4 8 4 7 8 8 7 1 4 1 8 6 5 0 6 1 0 8 9 8 0 1 4 1 6\n",
      " 8 5 6 1 9 4 6 1 6 4 6 8 9 6 4 4 5 1 8 9 8 7 4 0 0 3 4 6 4 8 7 8 1 0 1 8 5\n",
      " 6 8 9 4 9 7 7 7 1 1 1 6 1 6 4 1 7 8 9 1 7 4 7 0 1 9 4 1 6 1 0 1 7 4 8 8 7\n",
      " 1 7 7 8 0 0 8 8 8 1 1 8 6 7 0 7 6 5 7 7 8 5 8 1 8 1 8 0 8 1 4 0 5 6 1 7 6\n",
      " 9 4 1 6 8 8 6 6 7 7 4 1 8 4 0 7 9 7 1 1 6 8 1 5 7 5 6 9 0 8 4 4 4 6 7 0 7\n",
      " 6 0 6 1 4 7 1 6 4 7 1 5 8 6 8 7 5 4 7 1 4 4 7 5 8 7 6 0 9 1 1 4 9 6 7 8 3\n",
      " 7 8 1 0 5 0 1 5 8 0 4 6 0 6 5 0 6 1 8 2 5 4 8 1 4 4 4 4 9 8 1 8 7 7 0 5 0\n",
      " 0 0 8 7 8 7 5 4 6 6 7 9 7 6 7 7 1 0 4 0 1 7 1 1 5 5 0 6 4 9 1 9 7 7 9 1 7\n",
      " 8 4 5 1 1 4 5 4 7 8 3 5 6 9 8 0 5 6 0 1 9 4 6 1 7 7 4 6 1 7 9 1 0 0 5 6 1\n",
      " 7 7 6 4 1 6 8 9 5 6 6 6 4 0 6 6 1 5 9 0 0 5 9 6 9 4 6 5 6 6 1 7 5 6 4 1 1\n",
      " 6 1 8 9 9 0 1 6 8 9 0 8 7 4 5 6 5 1 5 7 8 4 6 7 8 9 5 7 5 5 6 7 6 8 6 0 9\n",
      " 6 0 5 9 9 0 1 9 5 5 9 4 4 0 1 9 8 7 1 5 5 7 1 5 1 1 9 9 7 4 8 4 5 6 8 0 6\n",
      " 5 4 0 1 0 7 6 8 5 5 8 5 9 8 8 6 5 7 7 8 7 7 6 4 4 9 1 8 4 7 8 5 7 0 0 1 5\n",
      " 6 0 8 5 5 0 5 6 8 0 4 5 4 0 5 0 9 5 0 1 1 6 4 4 1 9 5 4 4 6 1 1 9 9 7 4 7\n",
      " 4 0 8 5 4 5 1 4 7 6 8 5 7 6 0 8 7 7 5 4 5 0 0 4 9 1 5 9 7 8 0 7 1 9 5 0 8\n",
      " 8 9 4 0 4 7 9 9 1 1 1 8 8 1 0 6 0 6 4 4 8 8 7 1 7 1 1 7 1 1 8 4 8 0 1 0 8\n",
      " 9 5 5 9 8 7 0 5 1 6 6 0 1 8 8 9 4 9 9 7 1 5 8 0 5 6 0 7 7 6 0 5 0 5 5 7 8\n",
      " 5 4 6 7 0 8 5 0 5 8 8 1 1 8 0 4 1 7 6 7 6 5 4 9 8 7 7 4 6 8 4 5 9 7 1 7 6\n",
      " 9 6 7 5 1 8 4 3 4 0 0 1 1 7 1 6 6 0 9 6 7 9 4 7 5 7 1 1 6 1 4 7 1 1 4 7 7\n",
      " 0 4 7 7 8 5 4 3 9 8 9 8 6 8 6 7 0 7 6 9 0 4 0 4 4 4]\n",
      "(0.333, 0.23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-03 15:08:22,912][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_SKIN_atac2gex/GSE140203_SKIN_atac2gex.GSE140203_dataset.output_mod2.h5ad\n",
      "[INFO][2023-10-03 15:08:23,230][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_SKIN_atac2gex/GSE140203_SKIN_atac2gex.GSE140203_dataset.output_train_mod1.h5ad\n",
      "[INFO][2023-10-03 15:08:24,609][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_SKIN_atac2gex/GSE140203_SKIN_atac2gex.GSE140203_dataset.output_train_mod2.h5ad\n",
      "[INFO][2023-10-03 15:08:24,849][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_SKIN_atac2gex/GSE140203_SKIN_atac2gex.GSE140203_dataset.output_solution.h5ad\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/anndata/_core/anndata.py:1838: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py:843: UserWarning: Received a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py:843: UserWarning: Received a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n",
      "[INFO][2023-10-03 15:08:40,700][dance][_maybe_preprocess] Preprocessing done.\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/mudata/_core/mudata.py:322: UserWarning: Duplicated obs_names should not be present in different modalities due to the ambiguity that leads to.\n",
      "  warnings.warn(\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/mudata/_core/mudata.py:491: UserWarning: Cannot join columns with the same name because var_names are intersecting.\n",
      "  warnings.warn(\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/mudata/_core/mudata.py:322: UserWarning: Duplicated obs_names should not be present in different modalities due to the ambiguity that leads to.\n",
      "  warnings.warn(\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/mudata/_core/mudata.py:479: UserWarning: obs_names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  warnings.warn(\n",
      "[INFO][2023-10-03 15:08:45,206][dance][load_data] Raw data loaded:\n",
      "Data object that wraps (.data):\n",
      "MuData object with n_obs × n_vars = 35494 × 732480\n",
      "  uns:\t'dance_config'\n",
      "  5 modalities\n",
      "    mod1:\t34774 x 10000\n",
      "      var:\t'num', 'start', 'end', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm', 'mean', 'std'\n",
      "      uns:\t'dataset_id', 'hvg'\n",
      "      layers:\t'counts'\n",
      "    mod2:\t34774 x 10000\n",
      "      var:\t'gene', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm', 'mean', 'std'\n",
      "      uns:\t'dataset_id', 'hvg'\n",
      "      layers:\t'counts'\n",
      "    meta1:\t24341 x 344592\n",
      "      var:\t'num', 'start', 'end'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "    meta2:\t24341 x 23296\n",
      "      var:\t'gene'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "    test_sol:\t34774 x 344592\n",
      "      obs:\t'atac.bc', 'cell_type'\n",
      "      var:\t'num', 'start', 'end'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "[INFO][2023-10-03 15:08:45,207][dance][wrapped_func] Took 0:00:24.338513 to load and process data.\n",
      "[INFO][2023-10-03 15:08:45,213][dance][set_config_from_dict] Setting config 'feature_mod' to ['mod1', 'mod2']\n",
      "[INFO][2023-10-03 15:08:45,214][dance][set_config_from_dict] Setting config 'label_mod' to 'mod1'\n",
      "[INFO][2023-10-03 15:08:45,214][dance][set_config_from_dict] Setting config 'feature_channel' to ['counts', 'counts']\n",
      "[INFO][2023-10-03 15:08:45,215][dance][set_config_from_dict] Setting config 'feature_channel_type' to ['layers', 'layers']\n",
      "[INFO][2023-10-03 15:08:45,216][dance][set_config_from_dict] Setting config 'label_channel' to 'labels'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24341, 10000]) torch.Size([10433, 10000])\n",
      "23 1 2 20000\n",
      "epoch 0\n",
      "loss1 3.1685548417789993, loss2 2.2883755114189412, loss3 -9.64412143491109e-10, loss4 0.2619856252053449, \n",
      "val-loss1 2.963571310043335 val-loss2 1.6585065126419067 val-loss3 -4.8956578374559356e-11 val-loss4 0.04858076944947243\n",
      "val score 2.408630258028741\n",
      "epoch 1\n",
      "loss1 2.5373286632604377, loss2 1.671169947746188, loss3 -9.64412143491109e-10, loss4 0.14225028810459514, \n",
      "val-loss1 1.391563892364502 val-loss2 1.7820154428482056 val-loss3 -4.8956578374559356e-11 val-loss4 0.018176157027482986\n",
      "val score 1.3314066210737188\n",
      "epoch 2\n",
      "loss1 1.055997990245043, loss2 1.6867857263531796, loss3 -9.64412143491109e-10, loss4 0.09847766945008622, \n",
      "val-loss1 0.5775074362754822 val-loss2 1.5237488746643066 val-loss3 -4.8956578374559356e-11 val-loss4 0.016961075365543365\n",
      "val score 0.7098530340915281\n",
      "epoch 3\n",
      "loss1 0.6612909089687259, loss2 1.351150124572044, loss3 -9.64412143491109e-10, loss4 0.07899486444630595, \n",
      "val-loss1 0.5258819460868835 val-loss2 1.299696922302246 val-loss3 -4.8956578374559356e-11 val-loss4 0.013591279275715351\n",
      "val score 0.6287363106826056\n",
      "epoch 4\n",
      "loss1 0.6092332932491635, loss2 1.1265646375195926, loss3 -9.64412143491109e-10, loss4 0.06720155600978192, \n",
      "val-loss1 0.46939951181411743 val-loss2 1.2028388977050781 val-loss3 -4.8956578374559356e-11 val-loss4 0.012934274971485138\n",
      "val score 0.5697941515570243\n",
      "epoch 5\n",
      "loss1 0.570879558837691, loss2 0.9737086483212405, loss3 -9.64412143491109e-10, loss4 0.0542308206041885, \n",
      "val-loss1 0.4701850116252899 val-loss2 1.141482949256897 val-loss3 -4.8956578374559356e-11 val-loss4 0.0075571187771856785\n",
      "val score 0.5578039539254939\n",
      "epoch 6\n",
      "loss1 0.5589171583915866, loss2 0.8284625736779945, loss3 -9.64412143491109e-10, loss4 0.04090517629371133, \n",
      "val-loss1 0.45534104108810425 val-loss2 1.1257798671722412 val-loss3 -4.8956578374559356e-11 val-loss4 0.005426433403044939\n",
      "val score 0.5441660238638256\n",
      "epoch 7\n",
      "loss1 0.5392303090802458, loss2 0.7333476746151614, loss3 -9.64412143491109e-10, loss4 0.03191544740395837, \n",
      "val-loss1 0.43490180373191833 val-loss2 1.1124703884124756 val-loss3 -4.8956578374559356e-11 val-loss4 0.00475050276145339\n",
      "val score 0.5271628654304628\n",
      "epoch 8\n",
      "loss1 0.5200088083050972, loss2 0.647410322933696, loss3 -9.64412143491109e-10, loss4 0.024186523739508418, \n",
      "val-loss1 0.4221358597278595 val-loss2 1.0677348375320435 val-loss3 -4.8956578374559356e-11 val-loss4 0.002755064284428954\n",
      "val score 0.509179822527684\n",
      "epoch 9\n",
      "loss1 0.525297096302343, loss2 0.5870786083992138, loss3 -9.64412143491109e-10, loss4 0.01807224695830671, \n",
      "val-loss1 0.4452936053276062 val-loss2 1.0981038808822632 val-loss3 -4.8956578374559356e-11 val-loss4 0.0030581303872168064\n",
      "val score 0.53147920642269\n",
      "epoch 10\n",
      "loss1 0.5144244370072387, loss2 0.5297658535283666, loss3 -9.64412143491109e-10, loss4 0.013288847002915518, \n",
      "val-loss1 0.41687262058258057 val-loss2 1.0638213157653809 val-loss3 -4.8956578374559356e-11 val-loss4 0.0014811137225478888\n",
      "val score 0.504649153244562\n",
      "epoch 11\n",
      "loss1 0.5115903655803481, loss2 0.4835214904227922, loss3 -9.64412143491109e-10, loss4 0.009805538989386933, \n",
      "val-loss1 0.4255771338939667 val-loss2 1.092113971710205 val-loss3 -4.8956578374559356e-11 val-loss4 0.0009942169999703765\n",
      "val score 0.5163764989153684\n",
      "epoch 12\n",
      "loss1 0.5017623074872549, loss2 0.4428502579414567, loss3 -9.64412143491109e-10, loss4 0.006728907194270124, \n",
      "val-loss1 0.4204780161380768 val-loss2 1.0984375476837158 val-loss3 -4.8956578374559356e-11 val-loss4 0.0007583126425743103\n",
      "val score 0.5140600364630779\n",
      "epoch 13\n",
      "loss1 0.4871552278136098, loss2 0.4100209566396336, loss3 -9.64412143491109e-10, loss4 0.00468804893966461, \n",
      "val-loss1 0.4059862792491913 val-loss2 1.105456829071045 val-loss3 -4.8956578374559356e-11 val-loss4 0.0005367838894017041\n",
      "val score 0.5053086004806652\n",
      "epoch 14\n",
      "loss1 0.47181631936583407, loss2 0.36520686043902884, loss3 -9.64412143491109e-10, loss4 0.0032433197430205033, \n",
      "val-loss1 0.38338083028793335 val-loss2 1.1310371160507202 val-loss3 -4.8956578374559356e-11 val-loss4 0.00033216289011761546\n",
      "val score 0.49459061255375547\n",
      "epoch 15\n",
      "loss1 0.45439279581918274, loss2 0.33564113392386324, loss3 -9.64412143491109e-10, loss4 0.0022772716041546057, \n",
      "val-loss1 0.38467031717300415 val-loss2 1.1624798774719238 val-loss3 -4.8956578374559356e-11 val-loss4 0.0002945666783489287\n",
      "val score 0.5017799258469573\n",
      "epoch 16\n",
      "loss1 0.4368281856525776, loss2 0.32631253771657165, loss3 -9.64412143491109e-10, loss4 0.0014572952174159244, \n",
      "val-loss1 0.3770911693572998 val-loss2 1.1778264045715332 val-loss3 -4.8956578374559356e-11 val-loss4 0.0001582960394443944\n",
      "val score 0.49953701426394087\n",
      "epoch 17\n",
      "loss1 0.41671448651441306, loss2 0.3199040155944436, loss3 -9.64412143491109e-10, loss4 0.0009515280691503417, \n",
      "val-loss1 0.33855754137039185 val-loss2 1.213358998298645 val-loss3 -4.8956578374559356e-11 val-loss4 0.0001434965233784169\n",
      "val score 0.4796692534427244\n",
      "epoch 18\n",
      "loss1 0.4006780363446058, loss2 0.3183322322749814, loss3 -9.64412143491109e-10, loss4 0.0006282197795117946, \n",
      "val-loss1 0.3156759738922119 val-loss2 1.2020704746246338 val-loss3 -4.8956578374559356e-11 val-loss4 0.0001037591791828163\n",
      "val score 0.46139246460598643\n",
      "epoch 19\n",
      "loss1 0.3670389276257781, loss2 0.31056947793898193, loss3 -9.64412143491109e-10, loss4 0.0003958967424486493, \n",
      "val-loss1 0.27467119693756104 val-loss2 1.2376267910003662 val-loss3 -4.8956578374559356e-11 val-loss4 7.738275598967448e-05\n",
      "val score 0.43979906519171763\n",
      "epoch 20\n",
      "loss1 0.35967950999390247, loss2 0.2950821547487447, loss3 -9.64412143491109e-10, loss4 0.0002598525494503583, \n",
      "val-loss1 0.278777539730072 val-loss2 1.2991881370544434 val-loss3 -4.8956578374559356e-11 val-loss4 5.9329784562578425e-05\n",
      "val score 0.4549848717087194\n",
      "epoch 21\n",
      "loss1 0.33384641095302825, loss2 0.2907111865663251, loss3 -9.64412143491109e-10, loss4 0.00016788309183666148, \n",
      "val-loss1 0.24304743111133575 val-loss2 1.3177553415298462 val-loss3 -4.8956578374559356e-11 val-loss4 5.0865477533079684e-05\n",
      "val score 0.4336868133553331\n",
      "epoch 22\n",
      "loss1 0.33041422181697777, loss2 0.27356375602268895, loss3 -9.64412143491109e-10, loss4 0.00012089641707059982, \n",
      "val-loss1 0.23174026608467102 val-loss2 1.288856029510498 val-loss3 -4.8956578374559356e-11 val-loss4 3.714401464094408e-05\n",
      "val score 0.41999124935965354\n",
      "epoch 23\n",
      "loss1 0.31669934102615643, loss2 0.2577779857051927, loss3 -9.64412143491109e-10, loss4 9.512219709671795e-05, \n",
      "val-loss1 0.23152625560760498 val-loss2 1.2922626733779907 val-loss3 -4.8956578374559356e-11 val-loss4 3.0146977223921567e-05\n",
      "val score 0.42052242094733494\n",
      "epoch 24\n",
      "loss1 0.3115113919037719, loss2 0.2556374719323114, loss3 -9.64412143491109e-10, loss4 8.426528364547859e-05, \n",
      "val-loss1 0.20623143017292023 val-loss2 1.3719273805618286 val-loss3 -4.8956578374559356e-11 val-loss4 4.8216919822152704e-05\n",
      "val score 0.4187498880769532\n",
      "epoch 25\n",
      "loss1 0.3072547938588054, loss2 0.22924029437261959, loss3 -9.64412143491109e-10, loss4 7.604010648339132e-05, \n",
      "val-loss1 0.24228252470493317 val-loss2 1.3921520709991455 val-loss3 -4.8956578374559356e-11 val-loss4 3.3689444535411894e-05\n",
      "val score 0.44802986596306127\n",
      "epoch 26\n",
      "loss1 0.29808393701217895, loss2 0.21622519558945366, loss3 -9.64412143491109e-10, loss4 7.641236403964454e-05, \n",
      "val-loss1 0.19962534308433533 val-loss2 1.3457965850830078 val-loss3 -4.8956578374559356e-11 val-loss4 4.07082297897432e-05\n",
      "val score 0.40889909258467794\n",
      "epoch 27\n",
      "loss1 0.2967455876601297, loss2 0.2089377016175625, loss3 -9.64412143491109e-10, loss4 7.66500624046975e-05, \n",
      "val-loss1 0.19958926737308502 val-loss2 1.3625245094299316 val-loss3 -4.8956578374559356e-11 val-loss4 4.5229640818433836e-05\n",
      "val score 0.412219650526739\n",
      "epoch 28\n",
      "loss1 0.29548798380203023, loss2 0.20755511102114999, loss3 -9.64412143491109e-10, loss4 8.174535247066118e-05, \n",
      "val-loss1 0.1963246464729309 val-loss2 1.4162943363189697 val-loss3 -4.8956578374559356e-11 val-loss4 5.433528349385597e-05\n",
      "val score 0.42068883655657247\n",
      "epoch 29\n",
      "loss1 0.2873630932597227, loss2 0.19447150830785895, loss3 -9.64412143491109e-10, loss4 7.631325399077383e-05, \n",
      "val-loss1 0.22337841987609863 val-loss2 1.4089380502700806 val-loss3 -4.8956578374559356e-11 val-loss4 7.740941509837285e-05\n",
      "val score 0.43815637443559224\n",
      "epoch 30\n",
      "loss1 0.2779932242146758, loss2 0.19025809627546128, loss3 -9.64412143491109e-10, loss4 8.074065744738111e-05, \n",
      "val-loss1 0.18942123651504517 val-loss2 1.4160350561141968 val-loss3 -4.8956578374559356e-11 val-loss4 3.449081486905925e-05\n",
      "val score 0.4158036013216666\n",
      "epoch 31\n",
      "loss1 0.2848616857514825, loss2 0.1756995166110438, loss3 -9.64412143491109e-10, loss4 8.393534492000093e-05, \n",
      "val-loss1 0.19552229344844818 val-loss2 1.456496000289917 val-loss3 -4.8956578374559356e-11 val-loss4 4.0091916162054986e-05\n",
      "val score 0.4281668100652575\n",
      "epoch 32\n",
      "loss1 0.27289322131248406, loss2 0.17352938920606015, loss3 -9.64412143491109e-10, loss4 0.00010962331776512613, \n",
      "val-loss1 0.17802757024765015 val-loss2 1.4127607345581055 val-loss3 -4.8956578374559356e-11 val-loss4 5.637930371449329e-05\n",
      "val score 0.40717426504771415\n",
      "epoch 33\n",
      "loss1 0.27365280436568484, loss2 0.16592091146510007, loss3 -9.64412143491109e-10, loss4 0.00010323486331312885, \n",
      "val-loss1 0.19117094576358795 val-loss2 1.4792845249176025 val-loss3 -4.8956578374559356e-11 val-loss4 5.4762644140282646e-05\n",
      "val score 0.4296793051477913\n",
      "epoch 34\n",
      "loss1 0.26791977587827415, loss2 0.15587526648630237, loss3 -9.64412143491109e-10, loss4 0.00011000854224115502, \n",
      "val-loss1 0.1705133020877838 val-loss2 1.4018909931182861 val-loss3 -4.8956578374559356e-11 val-loss4 0.00011877998622367159\n",
      "val score 0.3997434490819693\n",
      "epoch 35\n",
      "loss1 0.25929550332731977, loss2 0.17082803631417973, loss3 -9.64412143491109e-10, loss4 0.000115030430944983, \n",
      "val-loss1 0.18364912271499634 val-loss2 1.5247738361358643 val-loss3 -4.8956578374559356e-11 val-loss4 0.00010723221930675209\n",
      "val score 0.43351451473618774\n",
      "epoch 36\n",
      "loss1 0.2665434242334477, loss2 0.15635443286060594, loss3 -9.64412143491109e-10, loss4 0.00012349936713330545, \n",
      "val-loss1 0.16427995264530182 val-loss2 1.456212043762207 val-loss3 -4.8956578374559356e-11 val-loss4 6.654812750639394e-05\n",
      "val score 0.40624170300808016\n",
      "epoch 37\n",
      "loss1 0.26247296101132106, loss2 0.1468104953162892, loss3 -9.64412143491109e-10, loss4 0.00012437618821676614, \n",
      "val-loss1 0.17506644129753113 val-loss2 1.5302485227584839 val-loss3 -4.8956578374559356e-11 val-loss4 6.257319910218939e-05\n",
      "val score 0.42859934211747586\n",
      "epoch 38\n",
      "loss1 0.25175855577338574, loss2 0.15473636850541414, loss3 -9.64412143491109e-10, loss4 0.00013481005653163668, \n",
      "val-loss1 0.16485600173473358 val-loss2 1.3822476863861084 val-loss3 -4.8956578374559356e-11 val-loss4 0.00010759288124972954\n",
      "val score 0.3918541181331499\n",
      "epoch 39\n",
      "loss1 0.25305831770217696, loss2 0.15322853109344495, loss3 -9.64412143491109e-10, loss4 0.00016581914568696235, \n",
      "val-loss1 0.1755455881357193 val-loss2 1.5074841976165771 val-loss3 -4.8956578374559356e-11 val-loss4 7.461883797077462e-05\n",
      "val score 0.4243824821577697\n",
      "epoch 40\n",
      "loss1 0.25367086779239567, loss2 0.13725160103464543, loss3 -9.64412143491109e-10, loss4 0.00016720556798878363, \n",
      "val-loss1 0.16872018575668335 val-loss2 1.5594896078109741 val-loss3 -4.8956578374559356e-11 val-loss4 7.658769027329981e-05\n",
      "val score 0.43000588097393905\n",
      "epoch 41\n",
      "loss1 0.24406709296758786, loss2 0.1428526792848526, loss3 -9.64412143491109e-10, loss4 0.0001550443470647266, \n",
      "val-loss1 0.161496102809906 val-loss2 1.4301363229751587 val-loss3 -4.8956578374559356e-11 val-loss4 0.00010813972767209634\n",
      "val score 0.39907994354590176\n",
      "epoch 42\n",
      "loss1 0.2516430417985417, loss2 0.14616142824118913, loss3 -9.64412143491109e-10, loss4 0.00018299009456694516, \n",
      "val-loss1 0.20107416808605194 val-loss2 1.5354995727539062 val-loss3 -4.8956578374559356e-11 val-loss4 0.00016661518020555377\n",
      "val score 0.44786016296758013\n",
      "epoch 43\n",
      "loss1 0.2421577915895817, loss2 0.1392585289946129, loss3 -9.64412143491109e-10, loss4 0.00019039913807551614, \n",
      "val-loss1 0.15360528230667114 val-loss2 1.511762261390686 val-loss3 -4.8956578374559356e-11 val-loss4 0.0001102106980397366\n",
      "val score 0.4098816604252612\n",
      "epoch 44\n",
      "loss1 0.2441312525161477, loss2 0.13154479395598173, loss3 -9.64412143491109e-10, loss4 0.00020152632655375528, \n",
      "val-loss1 0.1564851999282837 val-loss2 1.5276134014129639 val-loss3 -4.8956578374559356e-11 val-loss4 0.00013259111437946558\n",
      "val score 0.4150689497856625\n",
      "epoch 45\n",
      "loss1 0.23930495310314867, loss2 0.13506794285548981, loss3 -9.64412143491109e-10, loss4 0.00022639446970695347, \n",
      "val-loss1 0.17234022915363312 val-loss2 1.5127677917480469 val-loss3 -4.8956578374559356e-11 val-loss4 0.00015248039562720805\n",
      "val score 0.4231993427744861\n",
      "epoch 46\n",
      "loss1 0.23807023231719815, loss2 0.13388679834992387, loss3 -9.64412143491109e-10, loss4 0.00021169802680243412, \n",
      "val-loss1 0.13482360541820526 val-loss2 1.5640275478363037 val-loss3 -4.8956578374559356e-11 val-loss4 0.0001485268585383892\n",
      "val score 0.4071894597004836\n",
      "epoch 47\n",
      "loss1 0.2426772742250631, loss2 0.1303692948246418, loss3 -9.64412143491109e-10, loss4 0.00025195083316946183, \n",
      "val-loss1 0.1351330429315567 val-loss2 1.5578728914260864 val-loss3 -4.8956578374559356e-11 val-loss4 0.0001658505789237097\n",
      "val score 0.40617600086380534\n",
      "epoch 48\n",
      "loss1 0.23649457417601763, loss2 0.12678913068199574, loss3 -9.64412143491109e-10, loss4 0.0002573709678599275, \n",
      "val-loss1 0.15008379518985748 val-loss2 1.505573034286499 val-loss3 -4.8956578374559356e-11 val-loss4 0.00016414211131632328\n",
      "val score 0.4061814705933181\n",
      "[[-0.12870643 -1.8584381  -0.58257645 ... -2.07621    -1.1899583\n",
      "  -1.1940455 ]\n",
      " [ 1.1018497  -3.124468   -2.4933603  ... -0.99304485 -0.06683786\n",
      "  -0.36318758]\n",
      " [ 2.91224    -2.065634   -1.6569203  ...  1.9296205   1.2566637\n",
      "   0.56459904]\n",
      " ...\n",
      " [-0.39850003 -0.9666965  -0.79045534 ...  1.8698583   1.7589046\n",
      "   2.172792  ]\n",
      " [-8.170139   -0.94093424  2.7345734  ...  1.9058559  -0.5309066\n",
      "   0.65514815]\n",
      " [-2.092719   -2.134997   -0.87643665 ...  1.4937756   1.9110008\n",
      "   2.3105898 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-03 15:22:59,893][dance][set_seed] Setting global random seed to 1206479118\n",
      "[INFO][2023-10-03 15:22:59,895][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_cite_gex2adt/openproblems_2022_cite_gex2adt.open_dataset.output_mod1.h5ad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18 18 18 ... 13 13 13] [9 5 0 ... 0 0 0]\n",
      "(0.075, 0.074)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-03 15:23:02,712][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_cite_gex2adt/openproblems_2022_cite_gex2adt.open_dataset.output_mod2.h5ad\n",
      "[INFO][2023-10-03 15:23:02,837][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_cite_gex2adt/openproblems_2022_cite_gex2adt.open_dataset.output_train_mod1.h5ad\n",
      "[INFO][2023-10-03 15:23:04,814][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_cite_gex2adt/openproblems_2022_cite_gex2adt.open_dataset.output_train_mod2.h5ad\n",
      "[INFO][2023-10-03 15:23:04,901][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_cite_gex2adt/openproblems_2022_cite_gex2adt.open_dataset.output_solution.h5ad\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py:843: UserWarning: Received a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n",
      "[INFO][2023-10-03 15:23:31,045][dance][_maybe_preprocess] Preprocessing done.\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/mudata/_core/mudata.py:491: UserWarning: Cannot join columns with the same name because var_names are intersecting.\n",
      "  warnings.warn(\n",
      "[INFO][2023-10-03 15:23:31,170][dance][load_data] Raw data loaded:\n",
      "Data object that wraps (.data):\n",
      "MuData object with n_obs × n_vars = 70988 × 54450\n",
      "  uns:\t'dance_config'\n",
      "  5 modalities\n",
      "    mod1:\t70988 x 10000\n",
      "      obs:\t'batch', 'cell_type'\n",
      "      var:\t'feature_types', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm', 'mean', 'std'\n",
      "      uns:\t'dataset_id', 'hvg'\n",
      "      layers:\t'counts'\n",
      "    mod2:\t70988 x 140\n",
      "      obs:\t'batch'\n",
      "      var:\t'feature_types', 'mean', 'std'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "    meta1:\t49691 x 22085\n",
      "      obs:\t'batch'\n",
      "      var:\t'feature_types'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "    meta2:\t49691 x 140\n",
      "      obs:\t'batch'\n",
      "      var:\t'feature_types'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "    test_sol:\t70988 x 22085\n",
      "      obs:\t'batch', 'cell_type'\n",
      "      var:\t'feature_types'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "[INFO][2023-10-03 15:23:31,170][dance][wrapped_func] Took 0:00:31.275957 to load and process data.\n",
      "[INFO][2023-10-03 15:23:31,179][dance][set_config_from_dict] Setting config 'feature_mod' to ['mod1', 'mod2']\n",
      "[INFO][2023-10-03 15:23:31,179][dance][set_config_from_dict] Setting config 'label_mod' to 'mod1'\n",
      "[INFO][2023-10-03 15:23:31,180][dance][set_config_from_dict] Setting config 'feature_channel' to ['counts', 'counts']\n",
      "[INFO][2023-10-03 15:23:31,180][dance][set_config_from_dict] Setting config 'feature_channel_type' to ['layers', 'layers']\n",
      "[INFO][2023-10-03 15:23:31,181][dance][set_config_from_dict] Setting config 'label_channel' to 'labels'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([49691, 10000]) torch.Size([21297, 10000])\n",
      "7 1 2 10140\n",
      "epoch 0\n",
      "loss1 535.3763093784877, loss2 1.3551160260609219, loss3 -9.356125764613056e-10, loss4 3.5897841104439325, \n",
      "val-loss1 460.01739501953125 val-loss2 1.9513113498687744 val-loss3 -2.3985761293809915e-11 val-loss4 9.75899887084961\n",
      "val score 322.8903887271869\n",
      "epoch 1\n",
      "loss1 330.95955448695594, loss2 2.03310606275286, loss3 -9.356125764613056e-10, loss4 7.766586474009922, \n",
      "val-loss1 228.9608612060547 val-loss2 2.846067190170288 val-loss3 -2.3985761293809915e-11 val-loss4 9.168705940246582\n",
      "val score 161.30025157928347\n",
      "epoch 2\n",
      "loss1 118.1912338256836, loss2 2.9483223257746016, loss3 -9.356125764613056e-10, loss4 7.694849019050598, \n",
      "val-loss1 56.90885543823242 val-loss2 2.9680776596069336 val-loss3 -2.3985761293809915e-11 val-loss4 4.287264823913574\n",
      "val score 40.64417757987856\n",
      "epoch 3\n",
      "loss1 65.23069524492536, loss2 2.991837411948613, loss3 -9.356125764613056e-10, loss4 1.4918665719032287, \n",
      "val-loss1 62.34651184082031 val-loss2 2.991269588470459 val-loss3 -2.3985761293809915e-11 val-loss4 0.9826624989509583\n",
      "val score 44.28994533121465\n",
      "epoch 4\n",
      "loss1 65.21640793936594, loss2 2.9528606264931816, loss3 -9.356125764613056e-10, loss4 0.6057461224283491, \n",
      "val-loss1 62.482322692871094 val-loss2 2.826472520828247 val-loss3 -2.3985761293809915e-11 val-loss4 0.4099486470222473\n",
      "val score 44.323417821525325\n",
      "epoch 5\n",
      "loss1 64.70790196010044, loss2 2.9231999932016643, loss3 -9.356125764613056e-10, loss4 0.39540822173867907, \n",
      "val-loss1 705.7109985351562 val-loss2 2.9372591972351074 val-loss3 -2.3985761293809915e-11 val-loss4 1.3502378463745117\n",
      "val score 494.6526627063739\n",
      "epoch 6\n",
      "loss1 63.760979745047436, loss2 2.947517087800162, loss3 -9.356125764613056e-10, loss4 0.2862007149202483, \n",
      "val-loss1 64.28440856933594 val-loss2 2.7925972938537598 val-loss3 -2.3985761293809915e-11 val-loss4 0.1770072877407074\n",
      "val score 45.56645582169174\n",
      "epoch 7\n",
      "loss1 62.31691654750279, loss2 2.910374541282654, loss3 -9.356125764613056e-10, loss4 0.24029475354722568, \n",
      "val-loss1 65.60151672363281 val-loss2 2.970186233520508 val-loss3 -2.3985761293809915e-11 val-loss4 0.1552809774875641\n",
      "val score 46.522863002120246\n",
      "epoch 8\n",
      "loss1 62.05304672241211, loss2 2.8742398371015274, loss3 -9.356125764613056e-10, loss4 0.20760803216270038, \n",
      "val-loss1 61.05628204345703 val-loss2 2.7579002380371094 val-loss3 -2.3985761293809915e-11 val-loss4 0.14755982160568237\n",
      "val score 43.298355469106426\n",
      "epoch 9\n",
      "loss1 63.10798577444894, loss2 2.9095474658693585, loss3 -9.356125764613056e-10, loss4 0.19013925680092403, \n",
      "val-loss1 59.1506462097168 val-loss2 2.793790578842163 val-loss3 -2.3985761293809915e-11 val-loss4 0.13640618324279785\n",
      "val score 41.97103077173112\n",
      "epoch 10\n",
      "loss1 62.953527276175365, loss2 2.8589815054621015, loss3 -9.356125764613056e-10, loss4 0.1907673629266875, \n",
      "val-loss1 60.66827392578125 val-loss2 2.7700963020324707 val-loss3 -2.3985761293809915e-11 val-loss4 0.1377849131822586\n",
      "val score 43.02870025411127\n",
      "epoch 11\n",
      "loss1 60.393390720912386, loss2 2.8239942976406645, loss3 -9.356125764613056e-10, loss4 0.19314455085567064, \n",
      "val-loss1 59.27509689331055 val-loss2 2.8092689514160156 val-loss3 -2.3985761293809915e-11 val-loss4 0.12513329088687897\n",
      "val score 42.060678280143726\n",
      "epoch 12\n",
      "loss1 60.537652675083706, loss2 2.7713062453269957, loss3 -9.356125764613056e-10, loss4 0.19972723858697075, \n",
      "val-loss1 57.68479537963867 val-loss2 2.730567693710327 val-loss3 -2.3985761293809915e-11 val-loss4 0.15198086202144623\n",
      "val score 40.933069347589004\n",
      "[[ -4.5910845  -4.946457    5.206111  ...   4.4286537  -4.760252\n",
      "    4.4362   ]\n",
      " [ -4.298845   -4.6205244   4.8334107 ...   4.0948424  -4.3714933\n",
      "    4.1444454]\n",
      " [ -5.3677425  -5.765665    6.1062956 ...   5.2424693  -5.65187\n",
      "    5.182878 ]\n",
      " ...\n",
      " [ 13.761231   14.72937   -16.570194  ... -15.148394   16.319021\n",
      "  -13.519139 ]\n",
      " [ -4.223356   -4.5015078   4.71855   ...   3.9981287  -4.2671866\n",
      "    4.056395 ]\n",
      " [ 16.901249   18.144989  -19.920773  ... -18.02934    19.348345\n",
      "  -16.738129 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-03 15:27:49,797][dance][set_seed] Setting global random seed to 1206479118\n",
      "[INFO][2023-10-03 15:27:49,799][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_multi_atac2gex/openproblems_2022_multi_atac2gex.open_dataset.output_mod1.h5ad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 ... 1 3 1] [6 6 6 ... 5 6 5]\n",
      "(0.223, 0.169)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-03 15:27:54,819][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_multi_atac2gex/openproblems_2022_multi_atac2gex.open_dataset.output_mod2.h5ad\n",
      "[INFO][2023-10-03 15:27:58,118][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_multi_atac2gex/openproblems_2022_multi_atac2gex.open_dataset.output_train_mod1.h5ad\n",
      "[INFO][2023-10-03 15:28:01,994][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_multi_atac2gex/openproblems_2022_multi_atac2gex.open_dataset.output_train_mod2.h5ad\n",
      "[INFO][2023-10-03 15:28:04,593][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_multi_atac2gex/openproblems_2022_multi_atac2gex.open_dataset.output_solution.h5ad\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py:843: UserWarning: Received a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py:843: UserWarning: Received a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n",
      "[INFO][2023-10-03 15:29:54,183][dance][_maybe_preprocess] Preprocessing done.\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/mudata/_core/mudata.py:491: UserWarning: Cannot join columns with the same name because var_names are intersecting.\n",
      "  warnings.warn(\n",
      "[INFO][2023-10-03 15:29:54,656][dance][load_data] Raw data loaded:\n",
      "Data object that wraps (.data):\n",
      "MuData object with n_obs × n_vars = 105868 × 501302\n",
      "  uns:\t'dance_config'\n",
      "  5 modalities\n",
      "    mod1:\t105868 x 10000\n",
      "      obs:\t'batch', 'cell_type'\n",
      "      var:\t'feature_types', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm', 'mean', 'std'\n",
      "      uns:\t'dataset_id', 'hvg'\n",
      "      layers:\t'counts'\n",
      "    mod2:\t105868 x 10000\n",
      "      obs:\t'batch'\n",
      "      var:\t'feature_types', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm', 'mean', 'std'\n",
      "      uns:\t'dataset_id', 'hvg'\n",
      "      layers:\t'counts'\n",
      "    meta1:\t74107 x 228942\n",
      "      obs:\t'batch'\n",
      "      var:\t'feature_types'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "    meta2:\t74107 x 23418\n",
      "      obs:\t'batch'\n",
      "      var:\t'feature_types'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "    test_sol:\t105868 x 228942\n",
      "      obs:\t'batch', 'cell_type'\n",
      "      var:\t'feature_types'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "[INFO][2023-10-03 15:29:54,658][dance][wrapped_func] Took 0:02:04.859058 to load and process data.\n",
      "[INFO][2023-10-03 15:29:54,674][dance][set_config_from_dict] Setting config 'feature_mod' to ['mod1', 'mod2']\n",
      "[INFO][2023-10-03 15:29:54,675][dance][set_config_from_dict] Setting config 'label_mod' to 'mod1'\n",
      "[INFO][2023-10-03 15:29:54,676][dance][set_config_from_dict] Setting config 'feature_channel' to ['counts', 'counts']\n",
      "[INFO][2023-10-03 15:29:54,676][dance][set_config_from_dict] Setting config 'feature_channel_type' to ['layers', 'layers']\n",
      "[INFO][2023-10-03 15:29:54,677][dance][set_config_from_dict] Setting config 'label_channel' to 'labels'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([74107, 10000]) torch.Size([31761, 10000])\n",
      "7 1 2 20000\n",
      "epoch 0\n",
      "loss1 9.854349013032584, loss2 0.8411020556628932, loss3 -9.580846604578998e-10, loss4 0.1237062658486581, \n",
      "val-loss1 3.2408111095428467 val-loss2 0.962090790271759 val-loss3 -1.6085452414493773e-11 val-loss4 0.004456561058759689\n",
      "val score 2.461208762786478\n",
      "epoch 1\n",
      "loss1 2.420678300419073, loss2 0.7737769584431959, loss3 -9.580846604578998e-10, loss4 0.04332884040329306, \n",
      "val-loss1 2.157156467437744 val-loss2 0.5962890386581421 val-loss3 -1.6085452414493773e-11 val-loss4 0.0015593749703839421\n",
      "val score 1.6293453036857644\n",
      "epoch 2\n",
      "loss1 2.2567175183716404, loss2 0.6051138292898164, loss3 -9.580846604578998e-10, loss4 0.021058024536154563, \n",
      "val-loss1 1.9873970746994019 val-loss2 0.5005156397819519 val-loss3 -1.6085452414493773e-11 val-loss4 0.0012321437243372202\n",
      "val score 1.4913426874313844\n",
      "epoch 3\n",
      "loss1 2.205635035403387, loss2 0.5261032117452201, loss3 -9.580846604578998e-10, loss4 0.00967300720637757, \n",
      "val-loss1 2.0144543647766113 val-loss2 0.4454653263092041 val-loss3 -1.6085452414493773e-11 val-loss4 0.0007651745690964162\n",
      "val score 1.4992493793331194\n",
      "epoch 4\n",
      "loss1 2.109228284422922, loss2 0.4963553436528677, loss3 -9.580846604578998e-10, loss4 0.0046995993939110605, \n",
      "val-loss1 1.8716709613800049 val-loss2 0.4414643347263336 val-loss3 -1.6085452414493773e-11 val-loss4 0.0012401879066601396\n",
      "val score 1.3985245493057987\n",
      "epoch 5\n",
      "loss1 2.0333456196090727, loss2 0.4930103995562513, loss3 -9.580846604578998e-10, loss4 0.002828014662161013, \n",
      "val-loss1 1.8222506046295166 val-loss2 0.4399257302284241 val-loss3 -1.6085452414493773e-11 val-loss4 0.0014238531002774835\n",
      "val score 1.363631761940556\n",
      "epoch 6\n",
      "loss1 1.9685953894337476, loss2 0.5064649151145727, loss3 -9.580846604578998e-10, loss4 0.0026384445535771947, \n",
      "val-loss1 1.7501490116119385 val-loss2 0.4678206741809845 val-loss3 -1.6085452414493773e-11 val-loss4 0.0032251086086034775\n",
      "val score 1.3188296983941796\n",
      "epoch 7\n",
      "loss1 1.8893657319847195, loss2 0.5130436394463553, loss3 -9.580846604578998e-10, loss4 0.003501234912640019, \n",
      "val-loss1 1.7273133993148804 val-loss2 0.4787910580635071 val-loss3 -1.6085452414493773e-11 val-loss4 0.002978516975417733\n",
      "val score 1.3050265169810842\n",
      "epoch 8\n",
      "loss1 1.8113322395017777, loss2 0.526453593424682, loss3 -9.580846604578998e-10, loss4 0.005472299011274316, \n",
      "val-loss1 1.7541272640228271 val-loss2 0.5551900863647461 val-loss3 -1.6085452414493773e-11 val-loss4 0.010729067958891392\n",
      "val score 1.3394635554860685\n",
      "epoch 9\n",
      "loss1 1.7330140711247235, loss2 0.5165165306793319, loss3 -9.580846604578998e-10, loss4 0.010454637849510744, \n",
      "val-loss1 1.5691317319869995 val-loss2 0.4295610785484314 val-loss3 -1.6085452414493773e-11 val-loss4 0.008827016688883305\n",
      "val score 1.1847457789342257\n",
      "epoch 10\n",
      "loss1 1.6410114466002161, loss2 0.4702644066678153, loss3 -9.580846604578998e-10, loss4 0.011053591872961527, \n",
      "val-loss1 1.4411243200302124 val-loss2 0.41580551862716675 val-loss3 -1.6085452414493773e-11 val-loss4 0.007948741316795349\n",
      "val score 1.0923455648116176\n",
      "epoch 11\n",
      "loss1 1.6014592558488079, loss2 0.43518346590899876, loss3 -9.580846604578998e-10, loss4 0.01070173948796259, \n",
      "val-loss1 1.4366989135742188 val-loss2 0.3997175395488739 val-loss3 -1.6085452414493773e-11 val-loss4 0.010197894647717476\n",
      "val score 1.0861426421433094\n",
      "epoch 12\n",
      "loss1 1.570970266486493, loss2 0.4099990429777752, loss3 -9.580846604578998e-10, loss4 0.011741036839133764, \n",
      "val-loss1 1.4073413610458374 val-loss2 0.39758437871932983 val-loss3 -1.6085452414493773e-11 val-loss4 0.009184005670249462\n",
      "val score 1.0651150287586602\n",
      "epoch 13\n",
      "loss1 1.5293028697200206, loss2 0.3824373048612441, loss3 -9.580846604578998e-10, loss4 0.012081824988840412, \n",
      "val-loss1 1.3741880655288696 val-loss2 0.38721731305122375 val-loss3 -1.6085452414493773e-11 val-loss4 0.010474905371665955\n",
      "val score 1.0398988537482325\n",
      "epoch 14\n",
      "loss1 1.506103835343401, loss2 0.3617488824087998, loss3 -9.580846604578998e-10, loss4 0.012612252141138489, \n",
      "val-loss1 1.3488579988479614 val-loss2 0.3830563724040985 val-loss3 -1.6085452414493773e-11 val-loss4 0.009088345803320408\n",
      "val score 1.0212662909637542\n",
      "epoch 15\n",
      "loss1 1.486345535493902, loss2 0.3450201437219806, loss3 -9.580846604578998e-10, loss4 0.012921625882087425, \n",
      "val-loss1 1.3668278455734253 val-loss2 0.3961253762245178 val-loss3 -1.6085452414493773e-11 val-loss4 0.010507190600037575\n",
      "val score 1.0365299266754988\n",
      "epoch 16\n",
      "loss1 1.4599891229607593, loss2 0.3351244697368693, loss3 -9.580846604578998e-10, loss4 0.013120259365273846, \n",
      "val-loss1 1.3298581838607788 val-loss2 0.392625629901886 val-loss3 -1.6085452414493773e-11 val-loss4 0.012423856183886528\n",
      "val score 1.0100470474913126\n",
      "epoch 17\n",
      "loss1 1.4475617369929492, loss2 0.32346842863322217, loss3 -9.580846604578998e-10, loss4 0.01446370621500858, \n",
      "val-loss1 1.3572300672531128 val-loss2 0.41871729493141174 val-loss3 -1.6085452414493773e-11 val-loss4 0.01338951475918293\n",
      "val score 1.0344739818006161\n",
      "epoch 18\n",
      "loss1 1.423135253661437, loss2 0.3044505892071687, loss3 -9.580846604578998e-10, loss4 0.014507367486184128, \n",
      "val-loss1 1.2754693031311035 val-loss2 0.41737478971481323 val-loss3 -1.6085452414493773e-11 val-loss4 0.008774781599640846\n",
      "val score 0.9767422092139129\n",
      "epoch 19\n",
      "loss1 1.400223579900018, loss2 0.29118522569194605, loss3 -9.580846604578998e-10, loss4 0.015234906986441421, \n",
      "val-loss1 1.2496988773345947 val-loss2 0.42351675033569336 val-loss3 -1.6085452414493773e-11 val-loss4 0.011511155404150486\n",
      "val score 0.9600681219707583\n",
      "epoch 20\n",
      "loss1 1.3816953682808126, loss2 0.2850290905983969, loss3 -9.580846604578998e-10, loss4 0.01574475683675101, \n",
      "val-loss1 1.1923246383666992 val-loss2 0.41805148124694824 val-loss3 -1.6085452414493773e-11 val-loss4 0.013579929247498512\n",
      "val score 0.9189165395676497\n",
      "epoch 21\n",
      "loss1 1.350311194000573, loss2 0.2755447521919948, loss3 -9.580846604578998e-10, loss4 0.01669302019130053, \n",
      "val-loss1 1.187617301940918 val-loss2 0.46112024784088135 val-loss3 -1.6085452414493773e-11 val-loss4 0.013207809068262577\n",
      "val score 0.9242165513794277\n",
      "epoch 22\n",
      "loss1 1.318520224071554, loss2 0.27531891433215233, loss3 -9.580846604578998e-10, loss4 0.019084380598831566, \n",
      "val-loss1 1.1182639598846436 val-loss2 0.4471256732940674 val-loss3 -1.6085452414493773e-11 val-loss4 0.015806332230567932\n",
      "val score 0.8730002231887881\n",
      "epoch 23\n",
      "loss1 1.2883671937774424, loss2 0.26997514033397496, loss3 -9.580846604578998e-10, loss4 0.019816518613133736, \n",
      "val-loss1 1.1348918676376343 val-loss2 0.47771498560905457 val-loss3 -1.6085452414493773e-11 val-loss4 0.01589156873524189\n",
      "val score 0.8907618829041127\n",
      "epoch 24\n",
      "loss1 1.233251859059279, loss2 0.2813109040859787, loss3 -9.580846604578998e-10, loss4 0.01951088761496875, \n",
      "val-loss1 1.0281693935394287 val-loss2 0.4537898600101471 val-loss3 -1.6085452414493773e-11 val-loss4 0.01813947595655918\n",
      "val score 0.8113835212766533\n",
      "epoch 25\n",
      "loss1 1.20271460489295, loss2 0.2646655501847751, loss3 -9.580846604578998e-10, loss4 0.016721960720945134, \n",
      "val-loss1 0.9869030117988586 val-loss2 0.43044447898864746 val-loss3 -1.6085452414493773e-11 val-loss4 0.011142805218696594\n",
      "val score 0.7774781443170611\n",
      "epoch 26\n",
      "loss1 1.1613424430633414, loss2 0.2522258733281459, loss3 -9.580846604578998e-10, loss4 0.01218107970381491, \n",
      "val-loss1 0.9490422606468201 val-loss2 0.44867587089538574 val-loss3 -1.6085452414493773e-11 val-loss4 0.009029123932123184\n",
      "val score 0.754516212827653\n",
      "epoch 27\n",
      "loss1 1.1507951654922004, loss2 0.24406095442872394, loss3 -9.580846604578998e-10, loss4 0.009822791514532834, \n",
      "val-loss1 0.9996321201324463 val-loss2 0.42977771162986755 val-loss3 -1.6085452414493773e-11 val-loss4 0.0067922454327344894\n",
      "val score 0.7860376386895184\n",
      "epoch 28\n",
      "loss1 1.1224075572929164, loss2 0.23622688652512214, loss3 -9.580846604578998e-10, loss4 0.008168585758149566, \n",
      "val-loss1 0.9325447082519531 val-loss2 0.4636204242706299 val-loss3 -1.6085452414493773e-11 val-loss4 0.005142119247466326\n",
      "val score 0.7457624865920621\n",
      "epoch 29\n",
      "loss1 1.1104014068271009, loss2 0.22068143785856237, loss3 -9.580846604578998e-10, loss4 0.006996636014874182, \n",
      "val-loss1 0.892501711845398 val-loss2 0.4481888711452484 val-loss3 -1.6085452414493773e-11 val-loss4 0.00420480128377676\n",
      "val score 0.7145992125842128\n",
      "epoch 30\n",
      "loss1 1.1019809683392332, loss2 0.21777711346231657, loss3 -9.580846604578998e-10, loss4 0.006460784221696043, \n",
      "val-loss1 0.8999390006065369 val-loss2 0.4743947982788086 val-loss3 -1.6085452414493773e-11 val-loss4 0.00407022051513195\n",
      "val score 0.7250397711052898\n",
      "epoch 31\n",
      "loss1 1.0950184505561302, loss2 0.21310495736498486, loss3 -9.580846604578998e-10, loss4 0.0064743219132595824, \n",
      "val-loss1 0.8644120097160339 val-loss2 0.47310328483581543 val-loss3 -1.6085452414493773e-11 val-loss4 0.004218875430524349\n",
      "val score 0.6999200075391087\n",
      "epoch 32\n",
      "loss1 1.087911574091491, loss2 0.21618753977091376, loss3 -9.580846604578998e-10, loss4 0.005804275251725168, \n",
      "val-loss1 0.8705671429634094 val-loss2 0.4459587633609772 val-loss3 -1.6085452414493773e-11 val-loss4 0.003609689651057124\n",
      "val score 0.6987692372283306\n",
      "epoch 33\n",
      "loss1 1.073700344197138, loss2 0.2089831463821318, loss3 -9.580846604578998e-10, loss4 0.005526581289821172, \n",
      "val-loss1 1.1185288429260254 val-loss2 0.6179542541503906 val-loss3 -1.6085452414493773e-11 val-loss4 0.004791175946593285\n",
      "val score 0.9068005996748213\n",
      "epoch 34\n",
      "loss1 1.0635426743277188, loss2 0.2054138373569282, loss3 -9.580846604578998e-10, loss4 0.005400779300237296, \n",
      "val-loss1 0.8525877594947815 val-loss2 0.49182671308517456 val-loss3 -1.6085452414493773e-11 val-loss4 0.003057039575651288\n",
      "val score 0.6953296262413602\n",
      "epoch 35\n",
      "loss1 1.0611733404841004, loss2 0.19852399513467975, loss3 -9.580846604578998e-10, loss4 0.005221263937281009, \n",
      "val-loss1 0.8841831088066101 val-loss2 0.513925313949585 val-loss3 -1.6085452414493773e-11 val-loss4 0.004198282491415739\n",
      "val score 0.7219231530783106\n",
      "epoch 36\n",
      "loss1 1.0532849903764396, loss2 0.18875234948749514, loss3 -9.580846604578998e-10, loss4 0.004955699185169948, \n",
      "val-loss1 0.8600995540618896 val-loss2 0.4851146638393402 val-loss3 -1.6085452414493773e-11 val-loss4 0.0030779922381043434\n",
      "val score 0.6992465202222917\n",
      "epoch 37\n",
      "loss1 1.0379951888574037, loss2 0.18390798036337355, loss3 -9.580846604578998e-10, loss4 0.004826458310173161, \n",
      "val-loss1 0.8461309671401978 val-loss2 0.4875825345516205 val-loss3 -1.6085452414493773e-11 val-loss4 0.0027270845603197813\n",
      "val score 0.6899445381356741\n",
      "epoch 38\n",
      "loss1 1.0340969216549534, loss2 0.1820245046967862, loss3 -9.580846604578998e-10, loss4 0.004724843291944014, \n",
      "val-loss1 0.8389584422111511 val-loss2 0.4767025411128998 val-loss3 -1.6085452414493773e-11 val-loss4 0.002665643347427249\n",
      "val score 0.6827446999369529\n",
      "epoch 39\n",
      "loss1 1.0357819355995719, loss2 0.18220048843101525, loss3 -9.580846604578998e-10, loss4 0.004813957324704705, \n",
      "val-loss1 0.8174371719360352 val-loss2 0.5284568667411804 val-loss3 -1.6085452414493773e-11 val-loss4 0.0031365202739834785\n",
      "val score 0.6780542197163556\n",
      "epoch 40\n",
      "loss1 1.0311773162463616, loss2 0.1871676119080106, loss3 -9.580846604578998e-10, loss4 0.004836823819365738, \n",
      "val-loss1 0.8229196071624756 val-loss2 0.491506427526474 val-loss3 -1.6085452414493773e-11 val-loss4 0.002992051187902689\n",
      "val score 0.6744946130776186\n",
      "epoch 41\n",
      "loss1 1.014967212845996, loss2 0.17028349443870486, loss3 -9.580846604578998e-10, loss4 0.004871306086308769, \n",
      "val-loss1 0.817317008972168 val-loss2 0.46238264441490173 val-loss3 -1.6085452414493773e-11 val-loss4 0.003105866489931941\n",
      "val score 0.6647537284871903\n",
      "epoch 42\n",
      "loss1 1.014443970160466, loss2 0.17212443740260555, loss3 -9.580846604578998e-10, loss4 0.004885411506850572, \n",
      "val-loss1 0.8064027428627014 val-loss2 0.49523165822029114 val-loss3 -1.6085452414493773e-11 val-loss4 0.002736833179369569\n",
      "val score 0.6636650933061135\n",
      "epoch 43\n",
      "loss1 1.0069935962386516, loss2 0.17691122323731354, loss3 -9.580846604578998e-10, loss4 0.005027978710020211, \n",
      "val-loss1 0.8200256824493408 val-loss2 0.5382044911384583 val-loss3 -1.6085452414493773e-11 val-loss4 0.002810070523992181\n",
      "val score 0.6817993794676256\n",
      "epoch 44\n",
      "loss1 1.012173553307851, loss2 0.18570122983435106, loss3 -9.580846604578998e-10, loss4 0.005161721414129938, \n",
      "val-loss1 0.8423835635185242 val-loss2 0.5175564289093018 val-loss3 -1.6085452414493773e-11 val-loss4 0.002831017132848501\n",
      "val score 0.6933213311006654\n",
      "epoch 45\n",
      "loss1 1.0019040629553155, loss2 0.16940011198264884, loss3 -9.580846604578998e-10, loss4 0.00524406722466679, \n",
      "val-loss1 0.8213784098625183 val-loss2 0.47408920526504517 val-loss3 -1.6085452414493773e-11 val-loss4 0.0031244545243680477\n",
      "val score 0.669938950682186\n",
      "epoch 46\n",
      "loss1 0.9993343658145817, loss2 0.16042873309746783, loss3 -9.580846604578998e-10, loss4 0.005365150957457521, \n",
      "val-loss1 0.8024278283119202 val-loss2 0.6072447896003723 val-loss3 -1.6085452414493773e-11 val-loss4 0.0030838660895824432\n",
      "val score 0.6833026310420934\n",
      "epoch 47\n",
      "loss1 0.9928952876863808, loss2 0.15763669482421602, loss3 -9.580846604578998e-10, loss4 0.005525980885604475, \n",
      "val-loss1 0.7999256253242493 val-loss2 0.5552212595939636 val-loss3 -1.6085452414493773e-11 val-loss4 0.0034892328549176455\n",
      "val score 0.6711666512877089\n",
      "epoch 48\n",
      "loss1 0.986479139305166, loss2 0.1607249560926495, loss3 -9.580846604578998e-10, loss4 0.005601684894712492, \n",
      "val-loss1 0.7881861329078674 val-loss2 0.6169434785842896 val-loss3 -1.6085452414493773e-11 val-loss4 0.003235956421121955\n",
      "val score 0.6752807865726169\n",
      "epoch 49\n",
      "loss1 0.9868820681882544, loss2 0.146728221509049, loss3 -9.580846604578998e-10, loss4 0.005743815244257564, \n",
      "val-loss1 0.828298032283783 val-loss2 0.503627359867096 val-loss3 -1.6085452414493773e-11 val-loss4 0.0034187082201242447\n",
      "val score 0.6807050299822692\n",
      "epoch 50\n",
      "loss1 0.9741396531748132, loss2 0.13722394699394933, loss3 -9.580846604578998e-10, loss4 0.005831152216756138, \n",
      "val-loss1 0.7818552255630493 val-loss2 0.5144768357276917 val-loss3 -1.6085452414493773e-11 val-loss4 0.003778316080570221\n",
      "val score 0.650382940842897\n",
      "epoch 51\n",
      "loss1 0.9775516474155631, loss2 0.1351867201684535, loss3 -9.580846604578998e-10, loss4 0.005786244356041324, \n",
      "val-loss1 0.7823020815849304 val-loss2 0.5274020433425903 val-loss3 -1.6085452414493773e-11 val-loss4 0.003705780953168869\n",
      "val score 0.6532771548248235\n",
      "epoch 52\n",
      "loss1 0.9718790673204766, loss2 0.13300474985035216, loss3 -9.580846604578998e-10, loss4 0.005966483908830303, \n",
      "val-loss1 0.7900522947311401 val-loss2 0.5999450087547302 val-loss3 -1.6085452414493773e-11 val-loss4 0.0037980363704264164\n",
      "val score 0.6732155098804612\n",
      "epoch 53\n",
      "loss1 0.9695226253220861, loss2 0.131703766478561, loss3 -9.580846604578998e-10, loss4 0.0060671191551933115, \n",
      "val-loss1 0.8043907880783081 val-loss2 0.5612335801124573 val-loss3 -1.6085452414493773e-11 val-loss4 0.003650137223303318\n",
      "val score 0.675502774537668\n",
      "epoch 54\n",
      "loss1 0.9611226214074541, loss2 0.12902524540293606, loss3 -9.580846604578998e-10, loss4 0.006183563156001683, \n",
      "val-loss1 0.7756714820861816 val-loss2 0.5374332070350647 val-loss3 -1.6085452414493773e-11 val-loss4 0.0035814307630062103\n",
      "val score 0.6506357504046861\n",
      "epoch 55\n",
      "loss1 0.9598795102473876, loss2 0.12552114600365646, loss3 -9.580846604578998e-10, loss4 0.006247109051979364, \n",
      "val-loss1 0.756986141204834 val-loss2 0.5595665574073792 val-loss3 -1.6085452414493773e-11 val-loss4 0.004065400920808315\n",
      "val score 0.6420068803700958\n",
      "epoch 56\n",
      "loss1 0.9590136059399309, loss2 0.12921253095784177, loss3 -9.580846604578998e-10, loss4 0.006326294120515329, \n",
      "val-loss1 0.7666208744049072 val-loss2 0.5818459391593933 val-loss3 -1.6085452414493773e-11 val-loss4 0.0038723733741790056\n",
      "val score 0.6531974185832183\n",
      "epoch 57\n",
      "loss1 0.9520661805781369, loss2 0.12793960564652052, loss3 -9.580846604578998e-10, loss4 0.006347299136856564, \n",
      "val-loss1 0.746116042137146 val-loss2 0.518638014793396 val-loss3 -1.6085452414493773e-11 val-loss4 0.004071379080414772\n",
      "val score 0.6262124014078979\n",
      "epoch 58\n",
      "loss1 0.9530372210846093, loss2 0.12531094839332546, loss3 -9.580846604578998e-10, loss4 0.006589338218193801, \n",
      "val-loss1 0.7519847750663757 val-loss2 0.5511696934700012 val-loss3 -1.6085452414493773e-11 val-loss4 0.003779183840379119\n",
      "val score 0.636812240431678\n",
      "epoch 59\n",
      "loss1 0.9455079561905843, loss2 0.11509454112243035, loss3 -9.580846604578998e-10, loss4 0.0067638311993644725, \n",
      "val-loss1 0.7531550526618958 val-loss2 0.5643173456192017 val-loss3 -1.6085452414493773e-11 val-loss4 0.004566212184727192\n",
      "val score 0.6403003165955995\n",
      "[[-2.4015737e+00 -1.0893321e-01 -2.6115665e+00 ... -3.7106230e+00\n",
      "  -2.7381977e-01 -8.7959796e-02]\n",
      " [-2.0095134e+00  6.1033096e+00 -5.3994107e+00 ... -1.9656918e+00\n",
      "  -7.0053846e-02  1.4424967e+00]\n",
      " [-2.8672552e+00 -6.2142229e+00  7.2074418e+00 ...  5.9440136e-03\n",
      "   4.4756193e+00  3.5842414e+00]\n",
      " ...\n",
      " [ 1.0890455e+00 -1.7924463e+00  5.4937685e-01 ...  1.2881304e+01\n",
      "   3.4910972e+00  4.1542506e+00]\n",
      " [ 2.4145155e+00  1.2101829e+01 -1.0362788e+00 ... -2.7802045e+00\n",
      "  -8.0940371e+00 -6.0472341e+00]\n",
      " [ 3.4617229e+00  5.3478327e+00 -1.9510510e+00 ... -2.5423026e+00\n",
      "  -7.9322934e+00 -5.3806605e+00]]\n",
      "[4 1 2 ... 6 1 3] [8 8 0 ... 2 9 7]\n",
      "(0.25, 0.18)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'To reproduce JAE on other samples, please refer to command lines belows:\\n\\nGEX-ADT:\\npython jae.py --subtask openproblems_bmmc_cite_phase2 --device cuda\\n\\nGEX-ATAC:\\npython jae.py --subtask openproblems_bmmc_multiome_phase2 --device cuda\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JAE_scores=[]\n",
    "import argparse\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from dance.datasets.multimodality import JointEmbeddingNIPSDataset\n",
    "from dance.modules.multi_modality.joint_embedding.jae import JAEWrapper\n",
    "from dance.utils import set_seed\n",
    "\n",
    "rndseed = random.randint(0, 2147483647)\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-t\", \"--subtask\", default=datasets[0],\n",
    "                    choices=datasets)\n",
    "parser.add_argument(\"-d\", \"--data_folder\", default=\"../../../../data/joint_embedding\")\n",
    "parser.add_argument(\"-pre\", \"--pretrained_folder\", default=\"./data/joint_embedding/pretrained\")\n",
    "parser.add_argument(\"-csv\", \"--csv_path\", default=\"decoupled_lsi.csv\")\n",
    "parser.add_argument(\"-seed\", \"--rnd_seed\", default=rndseed, type=int)\n",
    "parser.add_argument(\"-cpu\", \"--cpus\", default=1, type=int)\n",
    "parser.add_argument(\"-device\", \"--device\", default=\"cpu\")\n",
    "parser.add_argument(\"-bs\", \"--batch_size\", default=128, type=int)\n",
    "parser.add_argument(\"-nm\", \"--normalize\", default=1, type=int, choices=[0, 1])\n",
    "parser.add_argument(\"--span\", default=0.3, type=float)\n",
    "\n",
    "for dataset in datasets:\n",
    "    args = parser.parse_args(['--subtask',dataset,'--device','cpu','--span','1.0'])\n",
    "\n",
    "    device = args.device\n",
    "    pre_normalize = bool(args.normalize)\n",
    "    torch.set_num_threads(args.cpus)\n",
    "    rndseed = args.rnd_seed\n",
    "    set_seed(rndseed)\n",
    "\n",
    "    dataset = JointEmbeddingNIPSDataset(args.subtask, root=args.data_folder, preprocess=\"feature_selection\", normalize=True,span=args.span)\n",
    "    data = dataset.load_data()\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    labels = le.fit_transform(data.mod[\"test_sol\"].obs[\"cell_type\"])\n",
    "    data.mod[\"mod1\"].obsm[\"labels\"] = labels\n",
    "    data.set_config(\n",
    "        feature_mod=[\"mod1\", \"mod2\"],\n",
    "        label_mod=\"mod1\",\n",
    "        feature_channel=[\"counts\", \"counts\"],\n",
    "        feature_channel_type=[\"layers\", \"layers\"],\n",
    "        label_channel=\"labels\",\n",
    "    )\n",
    "    (X_mod1_train, X_mod2_train), (cell_type) = data.get_train_data(return_type=\"torch\")\n",
    "    (X_mod1_test, X_mod2_test), (cell_type_test) = data.get_test_data(return_type=\"torch\")\n",
    "    print(X_mod1_train.shape,X_mod1_test.shape)\n",
    "    X_train = torch.cat([X_mod1_train, X_mod2_train], dim=1)\n",
    "    phase_score =torch.transpose(torch.tensor([[0.0]*(X_train.shape[0]),[0]*X_train.shape[0]]),0,1)\n",
    "    batch_label=torch.tensor([0.0]*(X_train.shape[0]))\n",
    "    # data.set_config(\n",
    "    #     feature_mod=[\"mod1\", \"mod2\"],\n",
    "    #     label_mod=[\"mod1\", \"mod1\", \"mod1\", \"mod1\", \"mod1\"],\n",
    "    #     feature_channel=[\"X_pca\", \"X_pca\"],\n",
    "    #     label_channel=[\"cell_type\", \"batch_label\", \"phase_labels\", \"S_scores\", \"G2M_scores\"],\n",
    "    # )\n",
    "    # (X_mod1_train, X_mod2_train), (cell_type, batch_label, phase_label, S_score,\n",
    "    #                                G2M_score) = data.get_train_data(return_type=\"torch\")\n",
    "    # (X_mod1_test, X_mod2_test), (cell_type_test, _, _, _, _) = data.get_test_data(return_type=\"torch\")\n",
    "    # X_train = torch.cat([X_mod1_train, X_mod2_train], dim=1)\n",
    "    # phase_score = torch.cat([S_score[:, None], G2M_score[:, None]], 1)\n",
    "    model = JAEWrapper(args, num_celL_types=int(cell_type.max() + 1), num_batches=int(batch_label.max() + 1),#这里记得从data里的config里的batch_label里取\n",
    "                       num_phases=phase_score.shape[1], num_features=X_train.shape[1])\n",
    "    model.fit(X_train, cell_type, batch_label, phase_score)\n",
    "    model.load(f\"models/model_joint_embedding_{rndseed}.pth\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        X_test = torch.cat([X_mod1_test, X_mod2_test], dim=1).float().to(device)\n",
    "        test_id = np.arange(X_test.shape[0])\n",
    "        labels = cell_type_test.numpy()\n",
    "        embeds = model.predict(X_test, test_id).cpu().numpy()\n",
    "        print(embeds)\n",
    "        score=model.score(X_test, test_id, labels, metric=\"clustering\")\n",
    "        print(score)\n",
    "        JAE_scores.append(score)\n",
    "\"\"\"To reproduce JAE on other samples, please refer to command lines belows:\n",
    "\n",
    "GEX-ADT:\n",
    "python jae.py --subtask openproblems_bmmc_cite_phase2 --device cuda\n",
    "\n",
    "GEX-ATAC:\n",
    "python jae.py --subtask openproblems_bmmc_multiome_phase2 --device cuda\n",
    "\n",
    "\"\"\"\n",
    "# TODO\n",
    "# 把所有preprocess修为feature_selection,可以尝试以下\n",
    "#最好将output涵盖住train,然后sol说明output的细胞类型\n",
    "#phase可以改没或者修改为同一时期的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.333, 0.23), (0.075, 0.074), (0.223, 0.169), (0.25, 0.18)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JAE_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-03 17:38:14,049][dance][set_seed] Setting global random seed to 1247938998\n",
      "[INFO][2023-10-03 17:38:14,051][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_BRAIN_atac2gex/GSE140203_BRAIN_atac2gex.GSE140203_dataset.output_mod1.h5ad\n",
      "[INFO][2023-10-03 17:38:14,458][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_BRAIN_atac2gex/GSE140203_BRAIN_atac2gex.GSE140203_dataset.output_mod2.h5ad\n",
      "[INFO][2023-10-03 17:38:14,562][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_BRAIN_atac2gex/GSE140203_BRAIN_atac2gex.GSE140203_dataset.output_train_mod1.h5ad\n",
      "[INFO][2023-10-03 17:38:14,850][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_BRAIN_atac2gex/GSE140203_BRAIN_atac2gex.GSE140203_dataset.output_train_mod2.h5ad\n",
      "[INFO][2023-10-03 17:38:14,946][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_BRAIN_atac2gex/GSE140203_BRAIN_atac2gex.GSE140203_dataset.output_solution.h5ad\n",
      "/home/zyxing/dance/dance/transforms/preprocess.py:147: RuntimeWarning: divide by zero encountered in divide\n",
      "  self.idf = X.shape[0] / X.sum(axis=0)\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py:843: UserWarning: Received a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py:843: UserWarning: Received a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n",
      "[INFO][2023-10-03 17:38:47,178][dance][_maybe_preprocess] Preprocessing done.\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/mudata/_core/mudata.py:491: UserWarning: Cannot join columns with the same name because var_names are intersecting.\n",
      "  warnings.warn(\n",
      "[INFO][2023-10-03 17:38:47,934][dance][load_data] Raw data loaded:\n",
      "Data object that wraps (.data):\n",
      "MuData object with n_obs × n_vars = 3291 × 897209\n",
      "  uns:\t'dance_config'\n",
      "  5 modalities\n",
      "    mod1:\t3291 x 10000\n",
      "      var:\t'num', 'start', 'end', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm', 'mean', 'std'\n",
      "      uns:\t'dataset_id', 'hvg'\n",
      "      obsm:\t'X_pca'\n",
      "      layers:\t'counts'\n",
      "    mod2:\t3291 x 10000\n",
      "      var:\t'gene', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm', 'mean', 'std'\n",
      "      uns:\t'dataset_id', 'hvg'\n",
      "      obsm:\t'X_pca'\n",
      "      layers:\t'counts'\n",
      "    meta1:\t2303 x 428041\n",
      "      var:\t'num', 'start', 'end'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "    meta2:\t2303 x 21127\n",
      "      var:\t'gene'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "    test_sol:\t3291 x 428041\n",
      "      obs:\t'atac.bc', 'cell_type'\n",
      "      var:\t'num', 'start', 'end'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "[INFO][2023-10-03 17:38:47,936][dance][wrapped_func] Took 0:00:33.885453 to load and process data.\n",
      "[INFO][2023-10-03 17:38:47,995][dance][set_config_from_dict] Setting config 'feature_mod' to ['mod1', 'mod2']\n",
      "[INFO][2023-10-03 17:38:47,997][dance][set_config_from_dict] Setting config 'label_mod' to ['mod1']\n",
      "[INFO][2023-10-03 17:38:47,998][dance][set_config_from_dict] Setting config 'feature_channel' to ['X_pca', 'X_pca']\n",
      "[INFO][2023-10-03 17:38:47,998][dance][set_config_from_dict] Setting config 'label_channel' to ['labels']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "loss1 1.0276559326383803, loss2 3.099752320183648, loss3 0.9825230439503988, loss4 0.442961464325587, \n",
      "val-loss1 1.0264090299606323 val-loss2 2.92504620552063 val-loss3 0.07733790576457977 val-loss4 0.011519686318933964\n",
      "val score 1.3079384416807445\n",
      "epoch 1\n",
      "loss1 1.0256121224827237, loss2 3.003436221016778, loss3 1.0041138264867995, loss4 0.413780798514684, \n",
      "val-loss1 1.0257552862167358 val-loss2 2.8912832736968994 val-loss3 0.15937145054340363 val-loss4 0.02396094612777233\n",
      "val score 1.3054519749246536\n",
      "epoch 2\n",
      "loss1 1.023488528198666, loss2 2.9367370075649686, loss3 0.9532757931285434, loss4 0.3987369305557675, \n",
      "val-loss1 1.0250908136367798 val-loss2 2.816216230392456 val-loss3 0.2464807778596878 val-loss4 0.04908547177910805\n",
      "val score 1.295585128106177\n",
      "epoch 3\n",
      "loss1 1.0213981072107952, loss2 2.858206960890028, loss3 0.8819088008668687, loss4 0.37190412481625873, \n",
      "val-loss1 1.0244345664978027 val-loss2 2.7212274074554443 val-loss3 0.3116030991077423 val-loss4 0.07549013942480087\n",
      "val score 1.280704339966178\n",
      "epoch 4\n",
      "loss1 1.0205433037545946, loss2 2.771186590194702, loss3 0.8967805835935805, loss4 0.3820776641368866, \n",
      "val-loss1 1.023459553718567 val-loss2 2.6278672218322754 val-loss3 0.3365861475467682 val-loss4 0.08738882094621658\n",
      "val score 1.2631938803941012\n",
      "epoch 5\n",
      "loss1 1.0179867678218417, loss2 2.691572586695353, loss3 0.911052299870385, loss4 0.35866812202665543, \n",
      "val-loss1 1.0223374366760254 val-loss2 2.54195499420166 val-loss3 0.35018405318260193 val-loss4 0.0896177589893341\n",
      "val score 1.2460172951221464\n",
      "epoch 6\n",
      "loss1 1.0166435241699219, loss2 2.620869663026598, loss3 0.8339679506089952, loss4 0.3465929991669125, \n",
      "val-loss1 1.021144986152649 val-loss2 2.463348865509033 val-loss3 0.3474802076816559 val-loss4 0.08736450970172882\n",
      "val score 1.22921349927783\n",
      "epoch 7\n",
      "loss1 1.0149336391025119, loss2 2.5523137516445584, loss3 0.8754713336626688, loss4 0.3253641658359104, \n",
      "val-loss1 1.019498348236084 val-loss2 2.3870160579681396 val-loss3 0.3490005135536194 val-loss4 0.08497093617916107\n",
      "val score 1.212750627845526\n",
      "epoch 8\n",
      "loss1 1.013113194041782, loss2 2.4653649595048694, loss3 0.8272943562931485, loss4 0.3375326792399089, \n",
      "val-loss1 1.0177396535873413 val-loss2 2.3154356479644775 val-loss3 0.3468901216983795 val-loss4 0.08085624128580093\n",
      "val score 1.1968922052532434\n",
      "epoch 9\n",
      "loss1 1.0104555553860135, loss2 2.379504919052124, loss3 0.8082652158207364, loss4 0.32063574923409355, \n",
      "val-loss1 1.0159187316894531 val-loss2 2.2479934692382812 val-loss3 0.33973807096481323 val-loss4 0.07521732896566391\n",
      "val score 1.1814895760267972\n",
      "epoch 10\n",
      "loss1 1.009091231558058, loss2 2.316186401579115, loss3 0.8219237393803067, loss4 0.2997712327374352, \n",
      "val-loss1 1.0138360261917114 val-loss2 2.1825850009918213 val-loss3 0.3329751789569855 val-loss4 0.071120485663414\n",
      "val score 1.1664070017635821\n",
      "epoch 11\n",
      "loss1 1.0065678026941087, loss2 2.274712774488661, loss3 0.7703900933265686, loss4 0.285877267519633, \n",
      "val-loss1 1.011688470840454 val-loss2 2.1201889514923096 val-loss3 0.320917546749115 val-loss4 0.0667763501405716\n",
      "val score 1.151604414731264\n",
      "epoch 12\n",
      "loss1 1.004300958580441, loss2 2.1909759839375815, loss3 0.7633445395363702, loss4 0.26552577647897935, \n",
      "val-loss1 1.0092740058898926 val-loss2 2.0606532096862793 val-loss3 0.3122917115688324 val-loss4 0.06080454960465431\n",
      "val score 1.137277259118855\n",
      "epoch 13\n",
      "loss1 1.0013323028882344, loss2 2.1170896424187555, loss3 0.7687253289752536, loss4 0.268560023771392, \n",
      "val-loss1 1.006468415260315 val-loss2 2.0002992153167725 val-loss3 0.3036195933818817 val-loss4 0.05925315245985985\n",
      "val score 1.122731371037662\n",
      "epoch 14\n",
      "loss1 0.9989205400149027, loss2 2.058842102686564, loss3 0.7379123767217001, loss4 0.2661707103252411, \n",
      "val-loss1 1.0037217140197754 val-loss2 1.94758141040802 val-loss3 0.2944580018520355 val-loss4 0.05606404319405556\n",
      "val score 1.1096475841477513\n",
      "epoch 15\n",
      "loss1 0.9958328803380331, loss2 2.002531501981947, loss3 0.7521300580766466, loss4 0.24399388664298588, \n",
      "val-loss1 1.000399112701416 val-loss2 1.895562767982483 val-loss3 0.2900833487510681 val-loss4 0.05319664254784584\n",
      "val score 1.0965559320524334\n",
      "epoch 16\n",
      "loss1 0.9933959113226997, loss2 1.9371473789215088, loss3 0.7276133563783433, loss4 0.2477603256702423, \n",
      "val-loss1 0.997044563293457 val-loss2 1.845897912979126 val-loss3 0.280565470457077 val-loss4 0.051864705979824066\n",
      "val score 1.0837322857230902\n",
      "epoch 17\n",
      "loss1 0.9899601936340332, loss2 1.8897519244088068, loss3 0.709415508641137, loss4 0.23296638164255354, \n",
      "val-loss1 0.9933062195777893 val-loss2 1.8003419637680054 val-loss3 0.2768373489379883 val-loss4 0.05000050738453865\n",
      "val score 1.07172463927418\n",
      "epoch 18\n",
      "loss1 0.9877695772382948, loss2 1.8305628034803603, loss3 0.6881470415327284, loss4 0.2257998784383138, \n",
      "val-loss1 0.989753246307373 val-loss2 1.759499430656433 val-loss3 0.26869675517082214 val-loss4 0.04748573154211044\n",
      "val score 1.0605362828820943\n",
      "epoch 19\n",
      "loss1 0.9831792248619927, loss2 1.7921068668365479, loss3 0.64246090915468, loss4 0.23574854599104988, \n",
      "val-loss1 0.9861079454421997 val-loss2 1.7183825969696045 val-loss3 0.26633280515670776 val-loss4 0.04487547278404236\n",
      "val score 1.049512495100498\n",
      "epoch 20\n",
      "loss1 0.9806099798944261, loss2 1.7495376269022624, loss3 0.6704739067289565, loss4 0.22011366817686293, \n",
      "val-loss1 0.9820652604103088 val-loss2 1.6760425567626953 val-loss3 0.26039743423461914 val-loss4 0.042798962444067\n",
      "val score 1.0378140134736895\n",
      "epoch 21\n",
      "loss1 0.977994852595859, loss2 1.7240646150377061, loss3 0.661722355418735, loss4 0.19889294273323482, \n",
      "val-loss1 0.9778538942337036 val-loss2 1.6376712322235107 val-loss3 0.2583222985267639 val-loss4 0.041740287095308304\n",
      "val score 1.0270351016893982\n",
      "epoch 22\n",
      "loss1 0.9744955698649088, loss2 1.6959672768910725, loss3 0.6468362808227539, loss4 0.20750009682443407, \n",
      "val-loss1 0.9737807512283325 val-loss2 1.6037352085113525 val-loss3 0.25041988492012024 val-loss4 0.04010811820626259\n",
      "val score 1.0169199677184224\n",
      "epoch 23\n",
      "loss1 0.9716476731830173, loss2 1.6249638928307428, loss3 0.6529815991719564, loss4 0.20193556944529215, \n",
      "val-loss1 0.9698587656021118 val-loss2 1.5671799182891846 val-loss3 0.2419077455997467 val-loss4 0.03919173777103424\n",
      "val score 1.0063920937478543\n",
      "epoch 24\n",
      "loss1 0.9667612314224243, loss2 1.5845013591978285, loss3 0.6138721704483032, loss4 0.194720553027259, \n",
      "val-loss1 0.9661475419998169 val-loss2 1.5368226766586304 val-loss3 0.2316957414150238 val-loss4 0.03784462437033653\n",
      "val score 0.9971448330208658\n",
      "epoch 25\n",
      "loss1 0.9640490412712097, loss2 1.562069919374254, loss3 0.6276401546266344, loss4 0.18466241492165458, \n",
      "val-loss1 0.9628285765647888 val-loss2 1.506800889968872 val-loss3 0.2238788902759552 val-loss4 0.036366984248161316\n",
      "val score 0.9883524753153324\n",
      "epoch 26\n",
      "loss1 0.9621081683370802, loss2 1.5217567947175767, loss3 0.6224950419531928, loss4 0.18010381526417202, \n",
      "val-loss1 0.9593446254730225 val-loss2 1.480899691581726 val-loss3 0.2182973474264145 val-loss4 0.03607765585184097\n",
      "val score 0.9804399263113737\n",
      "epoch 27\n",
      "loss1 0.9596915178828769, loss2 1.4921022918489244, loss3 0.6138781242900424, loss4 0.18442267179489136, \n",
      "val-loss1 0.9562658667564392 val-loss2 1.4496231079101562 val-loss3 0.2130003571510315 val-loss4 0.034960661083459854\n",
      "val score 0.9717087792232633\n",
      "epoch 28\n",
      "loss1 0.9569401144981384, loss2 1.4720407062106662, loss3 0.590299149354299, loss4 0.17282332645522225, \n",
      "val-loss1 0.953231930732727 val-loss2 1.419265866279602 val-loss3 0.20797140896320343 val-loss4 0.03349921107292175\n",
      "val score 0.9631890557706356\n",
      "epoch 29\n",
      "loss1 0.9540920257568359, loss2 1.4119348128636677, loss3 0.5943487948841519, loss4 0.17365900344318813, \n",
      "val-loss1 0.9505398273468018 val-loss2 1.3982124328613281 val-loss3 0.20211873948574066 val-loss4 0.03304889053106308\n",
      "val score 0.956778747215867\n",
      "epoch 30\n",
      "loss1 0.9521810743543837, loss2 1.3927968078189426, loss3 0.576650963889228, loss4 0.16605164441797468, \n",
      "val-loss1 0.9479377865791321 val-loss2 1.3695443868637085 val-loss3 0.19565631449222565 val-loss4 0.032396476715803146\n",
      "val score 0.9488679675385355\n",
      "epoch 31\n",
      "loss1 0.9510118100378249, loss2 1.3860246472888522, loss3 0.5867282681994967, loss4 0.15980880128012764, \n",
      "val-loss1 0.9452459216117859 val-loss2 1.3446437120437622 val-loss3 0.19147981703281403 val-loss4 0.030800538137555122\n",
      "val score 0.941714905295521\n",
      "epoch 32\n",
      "loss1 0.9471479455629984, loss2 1.3468687534332275, loss3 0.5660044550895691, loss4 0.15491411089897156, \n",
      "val-loss1 0.942878782749176 val-loss2 1.3196550607681274 val-loss3 0.18571117520332336 val-loss4 0.030814357101917267\n",
      "val score 0.9347724366933108\n",
      "epoch 33\n",
      "loss1 0.9469696879386902, loss2 1.3364994128545125, loss3 0.5482533574104309, loss4 0.15878524548477596, \n",
      "val-loss1 0.9406958222389221 val-loss2 1.2993757724761963 val-loss3 0.18080241978168488 val-loss4 0.029650257900357246\n",
      "val score 0.9288848639465869\n",
      "epoch 34\n",
      "loss1 0.9441752235094706, loss2 1.2916981379191081, loss3 0.5522063540087806, loss4 0.14738703270753226, \n",
      "val-loss1 0.9385645389556885 val-loss2 1.2775672674179077 val-loss3 0.17284569144248962 val-loss4 0.028578773140907288\n",
      "val score 0.9225798539817334\n",
      "epoch 35\n",
      "loss1 0.9417296780480279, loss2 1.2629093594021268, loss3 0.5359990331861708, loss4 0.1418430788649453, \n",
      "val-loss1 0.9365036487579346 val-loss2 1.255042314529419 val-loss3 0.16862204670906067 val-loss4 0.028639698401093483\n",
      "val score 0.9164241042919458\n",
      "epoch 36\n",
      "loss1 0.939787381225162, loss2 1.2341826756795247, loss3 0.5444197555383047, loss4 0.14271253016259935, \n",
      "val-loss1 0.9347374439239502 val-loss2 1.238040804862976 val-loss3 0.1640491634607315 val-loss4 0.027576107531785965\n",
      "val score 0.9115056352689861\n",
      "epoch 37\n",
      "loss1 0.9385769963264465, loss2 1.234674546453688, loss3 0.5148165822029114, loss4 0.14668270448843637, \n",
      "val-loss1 0.932470440864563 val-loss2 1.2140244245529175 val-loss3 0.16372492909431458 val-loss4 0.02688198909163475\n",
      "val score 0.905064539425075\n",
      "epoch 38\n",
      "loss1 0.9354950785636902, loss2 1.2137905094358656, loss3 0.5154627164204916, loss4 0.14534414807955423, \n",
      "val-loss1 0.9303572773933411 val-loss2 1.1927803754806519 val-loss3 0.15933971107006073 val-loss4 0.026416344568133354\n",
      "val score 0.8990939720533789\n",
      "epoch 39\n",
      "loss1 0.9347521265347799, loss2 1.1804317633310955, loss3 0.5225292874707116, loss4 0.13801971740192837, \n",
      "val-loss1 0.9285205602645874 val-loss2 1.1755154132843018 val-loss3 0.15504784882068634 val-loss4 0.025062305852770805\n",
      "val score 0.8940729825757443\n",
      "epoch 40\n",
      "loss1 0.9313542909092374, loss2 1.1520886818567913, loss3 0.513474702835083, loss4 0.12859715521335602, \n",
      "val-loss1 0.9263666272163391 val-loss2 1.155827283859253 val-loss3 0.1531289666891098 val-loss4 0.024563249200582504\n",
      "val score 0.8885067066177725\n",
      "epoch 41\n",
      "loss1 0.9288495712810092, loss2 1.1263818078570895, loss3 0.5025584267245399, loss4 0.13171466853883532, \n",
      "val-loss1 0.9245189428329468 val-loss2 1.137158751487732 val-loss3 0.1499263346195221 val-loss4 0.024283137172460556\n",
      "val score 0.8833054838702081\n",
      "epoch 42\n",
      "loss1 0.9283295737372504, loss2 1.1117119590441387, loss3 0.4910251531336043, loss4 0.12332132624255286, \n",
      "val-loss1 0.9227920174598694 val-loss2 1.1223682165145874 val-loss3 0.14400658011436462 val-loss4 0.023536410182714462\n",
      "val score 0.87880520503968\n",
      "epoch 43\n",
      "loss1 0.9253365132543776, loss2 1.1017827060487535, loss3 0.47794626156489056, loss4 0.13068416549099815, \n",
      "val-loss1 0.9208672642707825 val-loss2 1.1084105968475342 val-loss3 0.13953718543052673 val-loss4 0.022712288424372673\n",
      "val score 0.8744016780517996\n",
      "epoch 44\n",
      "loss1 0.9248882068528069, loss2 1.074567715326945, loss3 0.46994273530112374, loss4 0.1226198747754097, \n",
      "val-loss1 0.9190701842308044 val-loss2 1.0914181470870972 val-loss3 0.13674408197402954 val-loss4 0.02272586151957512\n",
      "val score 0.8696062555536627\n",
      "epoch 45\n",
      "loss1 0.9237819777594672, loss2 1.0746515459484525, loss3 0.47223957710795933, loss4 0.11558295041322708, \n",
      "val-loss1 0.9169159531593323 val-loss2 1.0706772804260254 val-loss3 0.13662002980709076 val-loss4 0.02233687788248062\n",
      "val score 0.8639244686812162\n",
      "epoch 46\n",
      "loss1 0.920982645617591, loss2 1.034580065144433, loss3 0.458704862329695, loss4 0.1168057844042778, \n",
      "val-loss1 0.9153432250022888 val-loss2 1.0575368404388428 val-loss3 0.1336897760629654 val-loss4 0.021589370444417\n",
      "val score 0.8600115829147399\n",
      "epoch 47\n",
      "loss1 0.9198958542611864, loss2 1.0176701479487948, loss3 0.4569455186525981, loss4 0.11432874451080959, \n",
      "val-loss1 0.9140593409538269 val-loss2 1.0440093278884888 val-loss3 0.13047024607658386 val-loss4 0.020928600803017616\n",
      "val score 0.8562133465893567\n",
      "epoch 48\n",
      "loss1 0.9174974030918546, loss2 1.0092839731110468, loss3 0.4573819372389052, loss4 0.11448585076464547, \n",
      "val-loss1 0.912013590335846 val-loss2 1.0255253314971924 val-loss3 0.12996311485767365 val-loss4 0.02087392471730709\n",
      "val score 0.8510564315132796\n",
      "epoch 49\n",
      "loss1 0.9145262307590909, loss2 0.9846001929706998, loss3 0.4495177235868242, loss4 0.11035703536536959, \n",
      "val-loss1 0.9106380343437195 val-loss2 1.0117839574813843 val-loss3 0.12587065994739532 val-loss4 0.02000374160706997\n",
      "val score 0.8470971356146038\n",
      "epoch 50\n",
      "loss1 0.914226598209805, loss2 0.9769963754547967, loss3 0.44227765997250873, loss4 0.10490577833520041, \n",
      "val-loss1 0.9093000292778015 val-loss2 0.9982509613037109 val-loss3 0.12412939965724945 val-loss4 0.019382748752832413\n",
      "val score 0.8433358201757073\n",
      "epoch 51\n",
      "loss1 0.9131423632303873, loss2 0.9642663333151076, loss3 0.4145491189426846, loss4 0.1052625063392851, \n",
      "val-loss1 0.9078568816184998 val-loss2 0.9872564077377319 val-loss3 0.11610094457864761 val-loss4 0.019461337476968765\n",
      "val score 0.8397292127832771\n",
      "epoch 52\n",
      "loss1 0.9123321837849088, loss2 0.948413974708981, loss3 0.4237745437357161, loss4 0.1070110880666309, \n",
      "val-loss1 0.9069983959197998 val-loss2 0.977044403553009 val-loss3 0.1153470128774643 val-loss4 0.01885087788105011\n",
      "val score 0.8370176523923873\n",
      "epoch 53\n",
      "loss1 0.9090596106317308, loss2 0.9293711450364854, loss3 0.41690514816178215, loss4 0.10075254903899299, \n",
      "val-loss1 0.906083345413208 val-loss2 0.9644749760627747 val-loss3 0.11306735873222351 val-loss4 0.018213612958788872\n",
      "val score 0.8337173855863511\n",
      "epoch 54\n",
      "loss1 0.9113166795836555, loss2 0.9294874005847507, loss3 0.41143656770388287, loss4 0.10170928388834, \n",
      "val-loss1 0.9046097993850708 val-loss2 0.9477915167808533 val-loss3 0.11154952645301819 val-loss4 0.017868569120764732\n",
      "val score 0.8292560677044093\n",
      "epoch 55\n",
      "loss1 0.9075346721543206, loss2 0.9019195901023017, loss3 0.4089369773864746, loss4 0.09545331448316574, \n",
      "val-loss1 0.903562605381012 val-loss2 0.9359095096588135 val-loss3 0.10914279520511627 val-loss4 0.017336048185825348\n",
      "val score 0.8259996678680182\n",
      "epoch 56\n",
      "loss1 0.9059397843148973, loss2 0.8840552899572585, loss3 0.40218616856469047, loss4 0.09406854377852546, \n",
      "val-loss1 0.9024589657783508 val-loss2 0.9239636063575745 val-loss3 0.10839644074440002 val-loss4 0.017100026831030846\n",
      "val score 0.822788820695132\n",
      "epoch 57\n",
      "loss1 0.9055406384997897, loss2 0.8688020639949374, loss3 0.3984813888867696, loss4 0.09494192981057697, \n",
      "val-loss1 0.9014363884925842 val-loss2 0.9169821739196777 val-loss3 0.10551654547452927 val-loss4 0.01582481525838375\n",
      "val score 0.82046897476539\n",
      "epoch 58\n",
      "loss1 0.9042349126603868, loss2 0.8389624953269958, loss3 0.37824591332011753, loss4 0.09351387371619542, \n",
      "val-loss1 0.9002825617790222 val-loss2 0.9033185243606567 val-loss3 0.10200141370296478 val-loss4 0.015597638674080372\n",
      "val score 0.8167414507362992\n",
      "epoch 59\n",
      "loss1 0.9040247201919556, loss2 0.8380028009414673, loss3 0.37488362524244523, loss4 0.08587714367442661, \n",
      "val-loss1 0.8992724418640137 val-loss2 0.8933555483818054 val-loss3 0.09956773370504379 val-loss4 0.015404689125716686\n",
      "val score 0.8139104401227087\n",
      "[[-0.6771123   0.95773536  1.064546   ...  0.19232957  1.075316\n",
      "   0.09179482]\n",
      " [-0.77288973  1.4251505  -0.37561384 ...  0.03850992  0.97796595\n",
      "  -0.2812837 ]\n",
      " [ 5.9964933  -1.5276927  -1.9631349  ... -2.6197536  -3.4391513\n",
      "  -0.13043329]\n",
      " ...\n",
      " [ 0.4377606  -1.358833   -1.2189798  ... -0.14868902 -0.02810606\n",
      "   0.5059295 ]\n",
      " [-0.2432389  -1.3482286  -0.15343095 ...  0.11644661  0.5728477\n",
      "   0.6256022 ]\n",
      " [ 0.35242432 -2.4322162   0.68237376 ...  0.97463924  0.01772492\n",
      "  -0.1630483 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-03 17:39:01,966][dance][set_seed] Setting global random seed to 1247938998\n",
      "[INFO][2023-10-03 17:39:01,968][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_SKIN_atac2gex/GSE140203_SKIN_atac2gex.GSE140203_dataset.output_mod1.h5ad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.536, 0.464)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-03 17:39:04,152][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_SKIN_atac2gex/GSE140203_SKIN_atac2gex.GSE140203_dataset.output_mod2.h5ad\n",
      "[INFO][2023-10-03 17:39:04,497][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_SKIN_atac2gex/GSE140203_SKIN_atac2gex.GSE140203_dataset.output_train_mod1.h5ad\n",
      "[INFO][2023-10-03 17:39:06,023][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_SKIN_atac2gex/GSE140203_SKIN_atac2gex.GSE140203_dataset.output_train_mod2.h5ad\n",
      "[INFO][2023-10-03 17:39:06,285][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_SKIN_atac2gex/GSE140203_SKIN_atac2gex.GSE140203_dataset.output_solution.h5ad\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/anndata/_core/anndata.py:1838: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/home/zyxing/dance/dance/transforms/preprocess.py:147: RuntimeWarning: divide by zero encountered in divide\n",
      "  self.idf = X.shape[0] / X.sum(axis=0)\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py:843: UserWarning: Received a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py:843: UserWarning: Received a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n",
      "[INFO][2023-10-03 17:42:47,861][dance][_maybe_preprocess] Preprocessing done.\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/mudata/_core/mudata.py:322: UserWarning: Duplicated obs_names should not be present in different modalities due to the ambiguity that leads to.\n",
      "  warnings.warn(\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/mudata/_core/mudata.py:491: UserWarning: Cannot join columns with the same name because var_names are intersecting.\n",
      "  warnings.warn(\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/mudata/_core/mudata.py:322: UserWarning: Duplicated obs_names should not be present in different modalities due to the ambiguity that leads to.\n",
      "  warnings.warn(\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/mudata/_core/mudata.py:479: UserWarning: obs_names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  warnings.warn(\n",
      "[INFO][2023-10-03 17:42:52,782][dance][load_data] Raw data loaded:\n",
      "Data object that wraps (.data):\n",
      "MuData object with n_obs × n_vars = 35494 × 732480\n",
      "  uns:\t'dance_config'\n",
      "  5 modalities\n",
      "    mod1:\t34774 x 10000\n",
      "      var:\t'num', 'start', 'end', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm', 'mean', 'std'\n",
      "      uns:\t'dataset_id', 'hvg'\n",
      "      obsm:\t'X_pca'\n",
      "      layers:\t'counts'\n",
      "    mod2:\t34774 x 10000\n",
      "      var:\t'gene', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm', 'mean', 'std'\n",
      "      uns:\t'dataset_id', 'hvg'\n",
      "      obsm:\t'X_pca'\n",
      "      layers:\t'counts'\n",
      "    meta1:\t24341 x 344592\n",
      "      var:\t'num', 'start', 'end'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "    meta2:\t24341 x 23296\n",
      "      var:\t'gene'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "    test_sol:\t34774 x 344592\n",
      "      obs:\t'atac.bc', 'cell_type'\n",
      "      var:\t'num', 'start', 'end'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "[INFO][2023-10-03 17:42:52,783][dance][wrapped_func] Took 0:03:50.815776 to load and process data.\n",
      "[INFO][2023-10-03 17:42:52,956][dance][set_config_from_dict] Setting config 'feature_mod' to ['mod1', 'mod2']\n",
      "[INFO][2023-10-03 17:42:52,956][dance][set_config_from_dict] Setting config 'label_mod' to ['mod1']\n",
      "[INFO][2023-10-03 17:42:52,957][dance][set_config_from_dict] Setting config 'feature_channel' to ['X_pca', 'X_pca']\n",
      "[INFO][2023-10-03 17:42:52,958][dance][set_config_from_dict] Setting config 'label_channel' to ['labels']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "loss1 0.9766389089961385, loss2 3.0757083504699, loss3 2.1226531877074133, loss4 0.3670721026354058, \n",
      "val-loss1 0.9533858895301819 val-loss2 2.577671766281128 val-loss3 3.2521517276763916 val-loss4 0.06938908249139786\n",
      "val score 1.3489815164357424\n",
      "epoch 1\n",
      "loss1 0.9563381505566974, loss2 2.4858868510224097, loss3 1.7462219138478123, loss4 0.29313984513282776, \n",
      "val-loss1 0.92420494556427 val-loss2 2.057708501815796 val-loss3 2.827094554901123 val-loss4 0.05714154243469238\n",
      "val score 1.202696967124939\n",
      "epoch 2\n",
      "loss1 0.9108819615009219, loss2 2.083017193993857, loss3 1.5208737378896668, loss4 0.23084795509659967, \n",
      "val-loss1 0.861436665058136 val-loss2 1.7471261024475098 val-loss3 2.184696674346924 val-loss4 0.04255502671003342\n",
      "val score 1.0637934710830448\n",
      "epoch 3\n",
      "loss1 0.8361747625262238, loss2 1.8321943726650505, loss3 1.3425771219785823, loss4 0.1941535119400468, \n",
      "val-loss1 0.774044930934906 val-loss2 1.5737709999084473 val-loss3 1.7143093347549438 val-loss4 0.030860282480716705\n",
      "val score 0.9438441324979067\n",
      "epoch 4\n",
      "loss1 0.7649328306663868, loss2 1.6824710175048474, loss3 1.2098090413004854, loss4 0.16363454558128535, \n",
      "val-loss1 0.7204331159591675 val-loss2 1.4590383768081665 val-loss3 1.3593697547912598 val-loss4 0.02162751741707325\n",
      "val score 0.8651607201434672\n",
      "epoch 5\n",
      "loss1 0.7290321519208509, loss2 1.5569724676220915, loss3 1.1241206790125646, loss4 0.14059325394242309, \n",
      "val-loss1 0.6969668865203857 val-loss2 1.3625164031982422 val-loss3 1.1024038791656494 val-loss4 0.016729475930333138\n",
      "val score 0.8163367689587175\n",
      "epoch 6\n",
      "loss1 0.7121619817822479, loss2 1.4646044609158537, loss3 1.0499744872714198, loss4 0.12330708652734756, \n",
      "val-loss1 0.680387020111084 val-loss2 1.2793525457382202 val-loss3 1.0236927270889282 val-loss4 0.014064192771911621\n",
      "val score 0.7840292692184447\n",
      "epoch 7\n",
      "loss1 0.6983035678087279, loss2 1.387268864831259, loss3 0.9623074212739634, loss4 0.1106504137779391, \n",
      "val-loss1 0.6677228212356567 val-loss2 1.2106853723526 val-loss3 0.8748033046722412 val-loss4 0.01208831649273634\n",
      "val score 0.7538876303937285\n",
      "epoch 8\n",
      "loss1 0.6876462947490604, loss2 1.330355730167655, loss3 0.8911713528078656, loss4 0.0996585167771162, \n",
      "val-loss1 0.6564351320266724 val-loss2 1.1572457551956177 val-loss3 0.756871223449707 val-loss4 0.010210780426859856\n",
      "val score 0.7293078436516225\n",
      "epoch 9\n",
      "loss1 0.6778175858564155, loss2 1.274678726528966, loss3 0.8230921459752459, loss4 0.08739792486262876, \n",
      "val-loss1 0.6484581232070923 val-loss2 1.113464593887329 val-loss3 0.6896291971206665 val-loss4 0.008980734273791313\n",
      "val score 0.7115441015921533\n",
      "epoch 10\n",
      "loss1 0.670818593612937, loss2 1.2303253911262335, loss3 0.7762092698452084, loss4 0.07914152186970379, \n",
      "val-loss1 0.641806423664093 val-loss2 1.0771198272705078 val-loss3 0.6169672012329102 val-loss4 0.007407373283058405\n",
      "val score 0.695907190744765\n",
      "epoch 11\n",
      "loss1 0.6654118147007254, loss2 1.1992457716964011, loss3 0.7025816038597462, loss4 0.07222419318764708, \n",
      "val-loss1 0.6373032331466675 val-loss2 1.0485128164291382 val-loss3 0.5276463627815247 val-loss4 0.00642959913238883\n",
      "val score 0.6825186245841905\n",
      "epoch 12\n",
      "loss1 0.6607380523238071, loss2 1.171175945636838, loss3 0.6437440195748972, loss4 0.06375927608027014, \n",
      "val-loss1 0.6329768300056458 val-loss2 1.0233509540557861 val-loss3 0.4578116536140442 val-loss4 0.005428867414593697\n",
      "val score 0.6709159978665412\n",
      "epoch 13\n",
      "loss1 0.656704209571661, loss2 1.1392236698505491, loss3 0.5870484183000964, loss4 0.05728103696953419, \n",
      "val-loss1 0.6294004917144775 val-loss2 1.0007740259170532 val-loss3 0.4200059473514557 val-loss4 0.004934688564389944\n",
      "val score 0.6619821811793373\n",
      "epoch 14\n",
      "loss1 0.652705920297046, loss2 1.116881224998208, loss3 0.5264616019504015, loss4 0.05228138047941895, \n",
      "val-loss1 0.6265241503715515 val-loss2 0.9843413829803467 val-loss3 0.36460092663764954 val-loss4 0.00428285077214241\n",
      "val score 0.6538793707266449\n",
      "epoch 15\n",
      "loss1 0.651190766068392, loss2 1.095600031143011, loss3 0.47052835863690046, loss4 0.046697983994733454, \n",
      "val-loss1 0.6242141723632812 val-loss2 0.9683402180671692 val-loss3 0.306078165769577 val-loss4 0.0037384985480457544\n",
      "val score 0.6461087974836117\n",
      "epoch 16\n",
      "loss1 0.6483866891195608, loss2 1.0864224087360292, loss3 0.4185682895571686, loss4 0.04142350790112517, \n",
      "val-loss1 0.6214977502822876 val-loss2 0.9531880617141724 val-loss3 0.2762150466442108 val-loss4 0.003283488331362605\n",
      "val score 0.6396609642892145\n",
      "epoch 17\n",
      "loss1 0.6461281027904776, loss2 1.0731975574826085, loss3 0.3589413311592368, loss4 0.0371508943133576, \n",
      "val-loss1 0.6196515560150146 val-loss2 0.9427099823951721 val-loss3 0.2348509132862091 val-loss4 0.00293059553951025\n",
      "val score 0.6341871611308306\n",
      "epoch 18\n",
      "loss1 0.6429730930993723, loss2 1.0558345622794574, loss3 0.30722677569056667, loss4 0.033797264835515685, \n",
      "val-loss1 0.6168769598007202 val-loss2 0.9323571920394897 val-loss3 0.19385449588298798 val-loss4 0.002710795495659113\n",
      "val score 0.6281135748373344\n",
      "epoch 19\n",
      "loss1 0.6410725477129914, loss2 1.0432110789210298, loss3 0.2577881844237793, loss4 0.030196957896615185, \n",
      "val-loss1 0.6138623952865601 val-loss2 0.922536313533783 val-loss3 0.16637836396694183 val-loss4 0.0022352596279233694\n",
      "val score 0.6226416205870918\n",
      "epoch 20\n",
      "loss1 0.6385482050651727, loss2 1.0298219794450805, loss3 0.20505014096581659, loss4 0.02671138344462528, \n",
      "val-loss1 0.6115246415138245 val-loss2 0.9134373664855957 val-loss3 0.13068054616451263 val-loss4 0.0020226442720741034\n",
      "val score 0.6173898818786255\n",
      "epoch 21\n",
      "loss1 0.6363378305767857, loss2 1.0250994978949082, loss3 0.1573008978089621, loss4 0.02395265874301278, \n",
      "val-loss1 0.6093405485153198 val-loss2 0.9091094136238098 val-loss3 0.111396923661232 val-loss4 0.0017705592326819897\n",
      "val score 0.6140186408301814\n",
      "epoch 22\n",
      "loss1 0.6340063810348511, loss2 1.0166558845098628, loss3 0.10954459739285846, loss4 0.02118709830697193, \n",
      "val-loss1 0.6072399020195007 val-loss2 0.9015827775001526 val-loss3 0.06599696725606918 val-loss4 0.0015991015825420618\n",
      "val score 0.6087642903556116\n",
      "epoch 23\n",
      "loss1 0.6323330485543539, loss2 1.0075829930083697, loss3 0.06634649660351664, loss4 0.018587125162052555, \n",
      "val-loss1 0.6058948040008545 val-loss2 0.8949395418167114 val-loss3 0.04249654337763786 val-loss4 0.0013983029639348388\n",
      "val score 0.6053090134810191\n",
      "epoch 24\n",
      "loss1 0.6311521183612735, loss2 0.9927337211231853, loss3 0.026513567497563915, loss4 0.016481628100019553, \n",
      "val-loss1 0.6041556000709534 val-loss2 0.8890982866287231 val-loss3 0.014428428374230862 val-loss4 0.001189756323583424\n",
      "val score 0.6015094866103027\n",
      "epoch 25\n",
      "loss1 0.6297658931377322, loss2 0.9890141916829486, loss3 0.004216337768729169, loss4 0.014736678407982338, \n",
      "val-loss1 0.6028481721878052 val-loss2 0.8840537667274475 val-loss3 0.013401241041719913 val-loss4 0.0010314908577129245\n",
      "val score 0.5995261104719247\n",
      "epoch 26\n",
      "loss1 0.6283519628436066, loss2 0.9810339947079503, loss3 0.002466469523930099, loss4 0.01258405921764152, \n",
      "val-loss1 0.6012542843818665 val-loss2 0.879366934299469 val-loss3 0.009927709586918354 val-loss4 0.0009513722034171224\n",
      "val score 0.5972953400167171\n",
      "epoch 27\n",
      "loss1 0.6273287798083106, loss2 0.9845283322556074, loss3 0.0017981642970901935, loss4 0.011235139809202316, \n",
      "val-loss1 0.6001484990119934 val-loss2 0.8767592906951904 val-loss3 0.00737058324739337 val-loss4 0.0008376528858207166\n",
      "val score 0.5958662192540941\n",
      "epoch 28\n",
      "loss1 0.6259674651678219, loss2 0.9712086832800577, loss3 0.001745313181281956, loss4 0.00990404647796653, \n",
      "val-loss1 0.5993679761886597 val-loss2 0.8717179894447327 val-loss3 0.012567778117954731 val-loss4 0.0007062475779093802\n",
      "val score 0.5945648825058014\n",
      "epoch 29\n",
      "loss1 0.6246539894924608, loss2 0.9611857270085534, loss3 0.0019744151342270333, loss4 0.008514899164871421, \n",
      "val-loss1 0.598051130771637 val-loss2 0.8677538633346558 val-loss3 0.007649719715118408 val-loss4 0.0006326211732812226\n",
      "val score 0.5926006812514971\n",
      "epoch 30\n",
      "loss1 0.623450564783673, loss2 0.9642870564793431, loss3 0.001321382941082553, loss4 0.007391258576061837, \n",
      "val-loss1 0.5970214009284973 val-loss2 0.8650288581848145 val-loss3 0.0073873973451554775 val-loss4 0.0005512170610018075\n",
      "val score 0.5913176830072189\n",
      "epoch 31\n",
      "loss1 0.6231163961942806, loss2 0.9556579575982205, loss3 0.0016405787359554927, loss4 0.006505035459562097, \n",
      "val-loss1 0.596301794052124 val-loss2 0.8626811504364014 val-loss3 0.010698888450860977 val-loss4 0.00046038892469368875\n",
      "val score 0.5905054497925449\n",
      "epoch 32\n",
      "loss1 0.6214685176694116, loss2 0.9537193844484728, loss3 0.0015234118219205114, loss4 0.0055505259850517265, \n",
      "val-loss1 0.5952348709106445 val-loss2 0.8605145812034607 val-loss3 0.003435838967561722 val-loss4 0.00039676178130321205\n",
      "val score 0.5889589559155866\n",
      "epoch 33\n",
      "loss1 0.620821494002675, loss2 0.9484417757322622, loss3 0.001101221820220438, loss4 0.004793439082108265, \n",
      "val-loss1 0.5940933227539062 val-loss2 0.8573723435401917 val-loss3 0.0018027201294898987 val-loss4 0.00034386609331704676\n",
      "val score 0.587447123946913\n",
      "epoch 34\n",
      "loss1 0.6199460930602495, loss2 0.944523696289506, loss3 0.0012805528957721625, loss4 0.004114066927455539, \n",
      "val-loss1 0.5933550000190735 val-loss2 0.8543165326118469 val-loss3 0.013784336857497692 val-loss4 0.0002924907603301108\n",
      "val score 0.5869156479166122\n",
      "epoch 35\n",
      "loss1 0.6188477693602096, loss2 0.9410543788311093, loss3 0.001617896863324351, loss4 0.003526633870679625, \n",
      "val-loss1 0.592391312122345 val-loss2 0.8514638543128967 val-loss3 0.005123106297105551 val-loss4 0.00025000376626849174\n",
      "val score 0.5852353448513895\n",
      "epoch 36\n",
      "loss1 0.6185234701910685, loss2 0.9363920078721157, loss3 0.0012284356120670604, loss4 0.0029617266859426057, \n",
      "val-loss1 0.5918394327163696 val-loss2 0.849219560623169 val-loss3 0.0037137973122298717 val-loss4 0.00020782013598363847\n",
      "val score 0.5843275958985032\n",
      "epoch 37\n",
      "loss1 0.6164629833642826, loss2 0.9334574147712352, loss3 0.0011215688170713568, loss4 0.002532774382162579, \n",
      "val-loss1 0.5894548296928406 val-loss2 0.8482688665390015 val-loss3 0.003693097038194537 val-loss4 0.00017889549781102687\n",
      "val score 0.582465753719589\n",
      "epoch 38\n",
      "loss1 0.6156186433725579, loss2 0.9277166738066562, loss3 0.001207085579449614, loss4 0.002132524029611675, \n",
      "val-loss1 0.5877781510353088 val-loss2 0.845379650592804 val-loss3 0.005241089966148138 val-loss4 0.00015005523164290935\n",
      "val score 0.5807901931031665\n",
      "epoch 39\n",
      "loss1 0.6143247138622195, loss2 0.9262465765309889, loss3 0.0011197991173736057, loss4 0.001836528508858972, \n",
      "val-loss1 0.5867979526519775 val-loss2 0.8450701832771301 val-loss3 0.007312788628041744 val-loss4 0.0001277468545595184\n",
      "val score 0.5801446302859403\n",
      "epoch 40\n",
      "loss1 0.6133957297302955, loss2 0.9251116611236749, loss3 0.001013898606098062, loss4 0.0015261350876413459, \n",
      "val-loss1 0.5859566330909729 val-loss2 0.8427721261978149 val-loss3 0.0034687663428485394 val-loss4 0.00010731058864621446\n",
      "val score 0.5789028722498187\n",
      "epoch 41\n",
      "loss1 0.6123560043268426, loss2 0.9165503216344256, loss3 0.0013588323653134149, loss4 0.0012673707218667448, \n",
      "val-loss1 0.5851929783821106 val-loss2 0.8418274521827698 val-loss3 0.004873442463576794 val-loss4 9.045405022334307e-05\n",
      "val score 0.5782487701297214\n",
      "epoch 42\n",
      "loss1 0.6117277062216471, loss2 0.9223378855128621, loss3 0.0011493109185573493, loss4 0.0010693404338929023, \n",
      "val-loss1 0.584402859210968 val-loss2 0.8369225263595581 val-loss3 0.005291604902595282 val-loss4 7.332834502449259e-05\n",
      "val score 0.5767347533819702\n",
      "epoch 43\n",
      "loss1 0.6116046545117401, loss2 0.9122725129127502, loss3 0.0009413320194864862, loss4 0.0008764870540607114, \n",
      "val-loss1 0.5837121605873108 val-loss2 0.8374438285827637 val-loss3 0.0025622535031288862 val-loss4 6.23512823949568e-05\n",
      "val score 0.5762185083669464\n",
      "epoch 44\n",
      "loss1 0.6102485005245653, loss2 0.912635302820871, loss3 0.0010192293922828381, loss4 0.0007369493440248419, \n",
      "val-loss1 0.5831300616264343 val-loss2 0.8381202220916748 val-loss3 0.006082641892135143 val-loss4 5.348333070287481e-05\n",
      "val score 0.5761218938179808\n",
      "epoch 45\n",
      "loss1 0.6096865812013316, loss2 0.9033728144889654, loss3 0.0009920866395141063, loss4 0.0006239500700842676, \n",
      "val-loss1 0.582407534122467 val-loss2 0.8333775997161865 val-loss3 0.0027471885550767183 val-loss4 4.425113002071157e-05\n",
      "val score 0.5745003658132191\n",
      "epoch 46\n",
      "loss1 0.6085950579754141, loss2 0.9110147246094638, loss3 0.0010767878969958008, loss4 0.0005073873048680726, \n",
      "val-loss1 0.5817268490791321 val-loss2 0.8318491578102112 val-loss3 0.00735542643815279 val-loss4 3.5199733247281983e-05\n",
      "val score 0.5739481572260048\n",
      "epoch 47\n",
      "loss1 0.6079208171644876, loss2 0.90246614467266, loss3 0.001041719041558979, loss4 0.0004165611313764266, \n",
      "val-loss1 0.5809911489486694 val-loss2 0.8320364356040955 val-loss3 0.0025464051868766546 val-loss4 3.0970924854045734e-05\n",
      "val score 0.5732299601904742\n",
      "epoch 48\n",
      "loss1 0.6077642842780712, loss2 0.8950690294420997, loss3 0.0011139021046611285, loss4 0.0003485751045911118, \n",
      "val-loss1 0.5806922316551208 val-loss2 0.8310302495956421 val-loss3 0.00498155364766717 val-loss4 2.6249666916555725e-05\n",
      "val score 0.5729410022434421\n",
      "epoch 49\n",
      "loss1 0.6069438194119653, loss2 0.9024692468864973, loss3 0.0011784646492234844, loss4 0.0002765941303656545, \n",
      "val-loss1 0.5799893736839294 val-loss2 0.828323483467102 val-loss3 0.004392347764223814 val-loss4 2.0031493477290496e-05\n",
      "val score 0.5718778772350561\n",
      "epoch 50\n",
      "loss1 0.6064575397691061, loss2 0.8969252968943396, loss3 0.0009250491708625367, loss4 0.00023051691823638976, \n",
      "val-loss1 0.579474687576294 val-loss2 0.8278030753135681 val-loss3 0.0043128724209964275 val-loss4 1.8313688997295685e-05\n",
      "val score 0.571409455671619\n",
      "epoch 51\n",
      "loss1 0.606127776378809, loss2 0.8887277841567993, loss3 0.0010346056796003912, loss4 0.00018651945669431413, \n",
      "val-loss1 0.5788930058479309 val-loss2 0.8276252746582031 val-loss3 0.0037504928186535835 val-loss4 1.472090389142977e-05\n",
      "val score 0.5709384197113194\n",
      "epoch 52\n",
      "loss1 0.6048025960145995, loss2 0.895693160766779, loss3 0.0009016675189635608, loss4 0.0001533542036181749, \n",
      "val-loss1 0.5785841345787048 val-loss2 0.8267102241516113 val-loss3 0.004427710548043251 val-loss4 1.2891013284388464e-05\n",
      "val score 0.5705729691134819\n",
      "epoch 53\n",
      "loss1 0.6045327449953833, loss2 0.8873877178790958, loss3 0.001068164077370839, loss4 0.00012477867029130806, \n",
      "val-loss1 0.5778908729553223 val-loss2 0.8258022665977478 val-loss3 0.006322290748357773 val-loss4 1.0742216545622796e-05\n",
      "val score 0.5700007160365202\n",
      "epoch 54\n",
      "loss1 0.6044478139211965, loss2 0.8865868532380392, loss3 0.0009712641720313492, loss4 0.00010275662599840786, \n",
      "val-loss1 0.5773900151252747 val-loss2 0.8232844471931458 val-loss3 0.003990161698311567 val-loss4 8.116226126730908e-06\n",
      "val score 0.5690298139225433\n",
      "epoch 55\n",
      "loss1 0.6039380680683047, loss2 0.8846475551294726, loss3 0.000994655504676535, loss4 8.372238601644545e-05, \n",
      "val-loss1 0.5767236351966858 val-loss2 0.8239279985427856 val-loss3 0.005284405313432217 val-loss4 8.072322088992223e-06\n",
      "val score 0.5687567682280132\n",
      "epoch 56\n",
      "loss1 0.6029326929602512, loss2 0.8838981154353119, loss3 0.0010477075702510774, loss4 6.997253800617791e-05, \n",
      "val-loss1 0.5750877261161804 val-loss2 0.8224072456359863 val-loss3 0.00409228028729558 val-loss4 1.173728651338024e-05\n",
      "val score 0.567248058287214\n",
      "epoch 57\n",
      "loss1 0.6012984264728635, loss2 0.8843526895656142, loss3 0.0009513249902357889, loss4 5.9088706367156404e-05, \n",
      "val-loss1 0.573959469795227 val-loss2 0.8206028342247009 val-loss3 0.0043960073962807655 val-loss4 6.892143574077636e-06\n",
      "val score 0.5661123406785918\n",
      "epoch 58\n",
      "loss1 0.600956398387288, loss2 0.8826022300609323, loss3 0.0009623046214475708, loss4 4.783717871083185e-05, \n",
      "val-loss1 0.5736399292945862 val-loss2 0.8191929459571838 val-loss3 0.005669684149324894 val-loss4 6.131738700787537e-06\n",
      "val score 0.5656703304920484\n",
      "epoch 59\n",
      "loss1 0.6000867818677148, loss2 0.8740475787672886, loss3 0.0009466059164815518, loss4 3.840731462628884e-05, \n",
      "val-loss1 0.5730766654014587 val-loss2 0.8173542618751526 val-loss3 0.004826687276363373 val-loss4 3.843852482532384e-06\n",
      "val score 0.5648660447124939\n",
      "[[ 1.3582287  -0.5638684  -0.04159795 ... -1.3280287   0.21237834\n",
      "  -0.44218785]\n",
      " [ 1.4795483  -1.0180756  -0.863828   ... -1.2036122   0.4435527\n",
      "  -0.31286293]\n",
      " [ 1.8619499  -1.722857   -1.2314284  ... -1.9521475   0.87841946\n",
      "  -0.2512198 ]\n",
      " ...\n",
      " [ 0.17129889 -1.3952309   0.4596069  ... -0.17086472  0.9844754\n",
      "  -0.15113902]\n",
      " [ 0.19328305 -0.21672292 -0.56147015 ...  0.06194831  0.04584648\n",
      "  -0.32498768]\n",
      " [ 0.78659236 -1.5747293  -1.1765622  ... -0.17695689  0.91641253\n",
      "   0.6816834 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-03 17:43:35,850][dance][set_seed] Setting global random seed to 1247938998\n",
      "[INFO][2023-10-03 17:43:35,852][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_cite_gex2adt/openproblems_2022_cite_gex2adt.open_dataset.output_mod1.h5ad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.388, 0.275)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-03 17:43:38,863][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_cite_gex2adt/openproblems_2022_cite_gex2adt.open_dataset.output_mod2.h5ad\n",
      "[INFO][2023-10-03 17:43:39,007][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_cite_gex2adt/openproblems_2022_cite_gex2adt.open_dataset.output_train_mod1.h5ad\n",
      "[INFO][2023-10-03 17:43:41,169][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_cite_gex2adt/openproblems_2022_cite_gex2adt.open_dataset.output_train_mod2.h5ad\n",
      "[INFO][2023-10-03 17:43:41,266][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_cite_gex2adt/openproblems_2022_cite_gex2adt.open_dataset.output_solution.h5ad\n",
      "/home/zyxing/dance/dance/transforms/preprocess.py:147: RuntimeWarning: divide by zero encountered in divide\n",
      "  self.idf = X.shape[0] / X.sum(axis=0)\n",
      "/home/zyxing/dance/dance/transforms/preprocess.py:154: RuntimeWarning: divide by zero encountered in divide\n",
      "  tf = X.multiply(1 / X.sum(axis=1))\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py:843: UserWarning: Received a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n",
      "[INFO][2023-10-03 17:47:48,205][dance][_maybe_preprocess] Preprocessing done.\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/mudata/_core/mudata.py:491: UserWarning: Cannot join columns with the same name because var_names are intersecting.\n",
      "  warnings.warn(\n",
      "[INFO][2023-10-03 17:47:48,351][dance][load_data] Raw data loaded:\n",
      "Data object that wraps (.data):\n",
      "MuData object with n_obs × n_vars = 70988 × 54450\n",
      "  uns:\t'dance_config'\n",
      "  5 modalities\n",
      "    mod1:\t70988 x 10000\n",
      "      obs:\t'batch', 'cell_type'\n",
      "      var:\t'feature_types', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm', 'mean', 'std'\n",
      "      uns:\t'dataset_id', 'hvg'\n",
      "      obsm:\t'X_pca'\n",
      "      layers:\t'counts'\n",
      "    mod2:\t70988 x 140\n",
      "      obs:\t'batch'\n",
      "      var:\t'feature_types', 'mean', 'std'\n",
      "      uns:\t'dataset_id'\n",
      "      obsm:\t'X_pca'\n",
      "      layers:\t'counts'\n",
      "    meta1:\t49691 x 22085\n",
      "      obs:\t'batch'\n",
      "      var:\t'feature_types'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "    meta2:\t49691 x 140\n",
      "      obs:\t'batch'\n",
      "      var:\t'feature_types'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "    test_sol:\t70988 x 22085\n",
      "      obs:\t'batch', 'cell_type'\n",
      "      var:\t'feature_types'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "[INFO][2023-10-03 17:47:48,353][dance][wrapped_func] Took 0:04:12.501775 to load and process data.\n",
      "[INFO][2023-10-03 17:47:48,736][dance][set_config_from_dict] Setting config 'feature_mod' to ['mod1', 'mod2']\n",
      "[INFO][2023-10-03 17:47:48,738][dance][set_config_from_dict] Setting config 'label_mod' to ['mod1']\n",
      "[INFO][2023-10-03 17:47:48,738][dance][set_config_from_dict] Setting config 'feature_channel' to ['X_pca', 'X_pca']\n",
      "[INFO][2023-10-03 17:47:48,739][dance][set_config_from_dict] Setting config 'label_channel' to ['labels']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "loss1 0.9636432907798074, loss2 1.560280141505328, loss3 2.078423125500029, loss4 0.3786299215121703, \n",
      "val-loss1 0.9325199723243713 val-loss2 0.9174661040306091 val-loss3 6.0477118492126465 val-loss4 0.08128175884485245\n",
      "val score 1.1427068818360568\n",
      "epoch 1\n",
      "loss1 0.8868953856554899, loss2 0.8454443663358688, loss3 1.5039144872941754, loss4 0.2443485569886186, \n",
      "val-loss1 0.8494113683700562 val-loss2 0.572718620300293 val-loss3 3.828327178955078 val-loss4 0.03873004764318466\n",
      "val score 0.9024845432490111\n",
      "epoch 2\n",
      "loss1 0.8406203050505031, loss2 0.6014278862964023, loss3 1.2224178290502592, loss4 0.16939426721497017, \n",
      "val-loss1 0.82344651222229 val-loss2 0.4538191556930542 val-loss3 2.7190845012664795 val-loss4 0.021746991202235222\n",
      "val score 0.8042179643176497\n",
      "epoch 3\n",
      "loss1 0.8203147094358098, loss2 0.49676038121635263, loss3 1.028939708728682, loss4 0.12810799725015054, \n",
      "val-loss1 0.8044955134391785 val-loss2 0.38955509662628174 val-loss3 1.9769529104232788 val-loss4 0.014214176684617996\n",
      "val score 0.7406162330880761\n",
      "epoch 4\n",
      "loss1 0.8070681237361648, loss2 0.4344679665836421, loss3 0.8634825745089487, loss4 0.09969870288940993, \n",
      "val-loss1 0.7935646176338196 val-loss2 0.34915030002593994 val-loss3 1.544884443283081 val-loss4 0.00987987220287323\n",
      "val score 0.7030635081231594\n",
      "epoch 5\n",
      "loss1 0.7984331446615133, loss2 0.39498656683347444, loss3 0.7268164689567956, loss4 0.07993591102686795, \n",
      "val-loss1 0.7852590084075928 val-loss2 0.32051515579223633 val-loss3 1.2146975994110107 val-loss4 0.007030840031802654\n",
      "val score 0.6748707590159029\n",
      "epoch 6\n",
      "loss1 0.7922053133899515, loss2 0.3673560324717652, loss3 0.5974440513686701, loss4 0.06423240281980146, \n",
      "val-loss1 0.7792125344276428 val-loss2 0.3001457750797272 val-loss3 0.930810272693634 val-loss4 0.0054084789007902145\n",
      "val score 0.6522888666950165\n",
      "epoch 7\n",
      "loss1 0.7874646721915766, loss2 0.3434097228402441, loss3 0.4772553090006113, loss4 0.05189179959283634, \n",
      "val-loss1 0.7744694352149963 val-loss2 0.2846934199333191 val-loss3 0.6743788719177246 val-loss4 0.004199122078716755\n",
      "val score 0.6329961883369832\n",
      "epoch 8\n",
      "loss1 0.783619383519346, loss2 0.3279606916687705, loss3 0.35913778900761495, loss4 0.04145195360549472, \n",
      "val-loss1 0.7697625160217285 val-loss2 0.2717854380607605 val-loss3 0.5266675353050232 val-loss4 0.0034201983362436295\n",
      "val score 0.6196952355094253\n",
      "epoch 9\n",
      "loss1 0.7794352133165706, loss2 0.3169508877802979, loss3 0.2510189739987254, loss4 0.03376522255976769, \n",
      "val-loss1 0.765502393245697 val-loss2 0.2615368068218231 val-loss3 0.31649506092071533 val-loss4 0.0025727886240929365\n",
      "val score 0.604112429113593\n",
      "epoch 10\n",
      "loss1 0.7762472419576212, loss2 0.30721606415781105, loss3 0.14467627898027952, loss4 0.02660551144402813, \n",
      "val-loss1 0.7617913484573364 val-loss2 0.2533154785633087 val-loss3 0.16386236250400543 val-loss4 0.001999487401917577\n",
      "val score 0.5922101321280934\n",
      "epoch 11\n",
      "loss1 0.7730551524595781, loss2 0.29415861754254863, loss3 0.05140301542335444, loss4 0.021145683141763915, \n",
      "val-loss1 0.7583571672439575 val-loss2 0.24686916172504425 val-loss3 0.026219597086310387 val-loss4 0.0015454230597242713\n",
      "val score 0.5816121004230806\n",
      "epoch 12\n",
      "loss1 0.7700315822254528, loss2 0.2891697055575522, loss3 0.004908643720475745, loss4 0.01653111542956057, \n",
      "val-loss1 0.7554107308387756 val-loss2 0.24145954847335815 val-loss3 0.013341492973268032 val-loss4 0.0012028755154460669\n",
      "val score 0.5778066397062503\n",
      "epoch 13\n",
      "loss1 0.7675934786146338, loss2 0.2858519464392554, loss3 0.0029422591416567393, loss4 0.012827416215176609, \n",
      "val-loss1 0.7525519132614136 val-loss2 0.2364273965358734 val-loss3 0.03544428572058678 val-loss4 0.0009343933779746294\n",
      "val score 0.5758907525450921\n",
      "epoch 14\n",
      "loss1 0.7653476683930918, loss2 0.27840750596740027, loss3 0.002713898949547332, loss4 0.0099078103561293, \n",
      "val-loss1 0.749993622303009 val-loss2 0.23176603019237518 val-loss3 0.05791550502181053 val-loss4 0.0007031579152680933\n",
      "val score 0.5742796747974352\n",
      "epoch 15\n",
      "loss1 0.7634826356714423, loss2 0.2751766246828166, loss3 0.004185955022959123, loss4 0.007533947635569017, \n",
      "val-loss1 0.7479937076568604 val-loss2 0.22804273664951324 val-loss3 0.050962503999471664 val-loss4 0.0005200130399316549\n",
      "val score 0.571778268541675\n",
      "epoch 16\n",
      "loss1 0.7612195150418715, loss2 0.2710586567832665, loss3 0.0030749025000576776, loss4 0.005637072365392338, \n",
      "val-loss1 0.7460846304893494 val-loss2 0.22521722316741943 val-loss3 0.016765955835580826 val-loss4 0.0003894400433637202\n",
      "val score 0.5681604557699756\n",
      "epoch 17\n",
      "loss1 0.7594739503481172, loss2 0.26627025329931214, loss3 0.001658046993807974, loss4 0.004185207092880525, \n",
      "val-loss1 0.7439333200454712 val-loss2 0.22288712859153748 val-loss3 0.02877793088555336 val-loss4 0.0002742260112427175\n",
      "val score 0.5667833575949771\n",
      "epoch 18\n",
      "loss1 0.7575139098546722, loss2 0.2674479523504322, loss3 0.0021825463700224645, loss4 0.0030823299153284593, \n",
      "val-loss1 0.742324709892273 val-loss2 0.22099167108535767 val-loss3 0.07529323548078537 val-loss4 0.0002057813253486529\n",
      "val score 0.5676005819819693\n",
      "epoch 19\n",
      "loss1 0.7560277059674263, loss2 0.26255056871609256, loss3 0.003361930063957433, loss4 0.002230015693137168, \n",
      "val-loss1 0.740548312664032 val-loss2 0.21821630001068115 val-loss3 0.013269435614347458 val-loss4 0.00014368639676831663\n",
      "val score 0.5626977349675143\n",
      "epoch 20\n",
      "loss1 0.7547563883391294, loss2 0.2641322280872952, loss3 0.001524124692712741, loss4 0.0015719357020729644, \n",
      "val-loss1 0.7391823530197144 val-loss2 0.21663658320903778 val-loss3 0.005433829501271248 val-loss4 0.00010283453593729064\n",
      "val score 0.5610317969574681\n",
      "epoch 21\n",
      "loss1 0.7529953799464486, loss2 0.25814586759290914, loss3 0.0014476144047379917, loss4 0.0011135829422114925, \n",
      "val-loss1 0.7374815344810486 val-loss2 0.21567635238170624 val-loss3 0.03575803339481354 val-loss4 6.917604332556948e-05\n",
      "val score 0.5611637050849821\n",
      "epoch 22\n",
      "loss1 0.7513704638589512, loss2 0.2554362318055196, loss3 0.0014745790692607195, loss4 0.000771345588542648, \n",
      "val-loss1 0.736059844493866 val-loss2 0.21301542222499847 val-loss3 0.010156248696148396 val-loss4 5.116518877912313e-05\n",
      "val score 0.5583553462849523\n",
      "epoch 23\n",
      "loss1 0.7503195005384359, loss2 0.2529122783717784, loss3 0.0013093227197797123, loss4 0.0005265337504996834, \n",
      "val-loss1 0.734773576259613 val-loss2 0.2135079801082611 val-loss3 0.013403790071606636 val-loss4 3.380657290108502e-05\n",
      "val score 0.5577149792356068\n",
      "epoch 24\n",
      "loss1 0.748544963246042, loss2 0.2530105796388604, loss3 0.0013753986859228462, loss4 0.0003565066895548212, \n",
      "val-loss1 0.7332721948623657 val-loss2 0.2113053798675537 val-loss3 0.004469112493097782 val-loss4 2.3870368750067428e-05\n",
      "val score 0.555776261520259\n",
      "epoch 25\n",
      "loss1 0.7474798898805272, loss2 0.24912706728685985, loss3 0.0017409548464374066, loss4 0.0002361990338448033, \n",
      "val-loss1 0.7323161363601685 val-loss2 0.2119845747947693 val-loss3 0.003175645135343075 val-loss4 1.5072723726916593e-05\n",
      "val score 0.5551777463040252\n",
      "epoch 26\n",
      "loss1 0.7463537413965572, loss2 0.24892605671828444, loss3 0.0013341857957129832, loss4 0.00015476893515204375, \n",
      "val-loss1 0.7310201525688171 val-loss2 0.2098952829837799 val-loss3 0.005014890339225531 val-loss4 9.411905921297148e-06\n",
      "val score 0.5539443785071853\n",
      "epoch 27\n",
      "loss1 0.745356710119681, loss2 0.25094602460210974, loss3 0.001452665617266162, loss4 0.00010198982264145425, \n",
      "val-loss1 0.730047345161438 val-loss2 0.20911924540996552 val-loss3 0.02355843409895897 val-loss4 7.986581294971984e-06\n",
      "val score 0.5540353117290123\n",
      "epoch 28\n",
      "loss1 0.7443587617440657, loss2 0.2469008598815311, loss3 0.0014786196430081459, loss4 6.760809314569501e-05, \n",
      "val-loss1 0.7288749814033508 val-loss2 0.20853397250175476 val-loss3 0.012337090447545052 val-loss4 5.8371247178001795e-06\n",
      "val score 0.5525364278613096\n",
      "epoch 29\n",
      "loss1 0.7432904216376218, loss2 0.2427537129683928, loss3 0.0012666462984766854, loss4 4.316849838852993e-05, \n",
      "val-loss1 0.7277123332023621 val-loss2 0.2075578272342682 val-loss3 0.009031274355947971 val-loss4 3.5704326819541166e-06\n",
      "val score 0.5513619409279387\n",
      "epoch 30\n",
      "loss1 0.7424128536473621, loss2 0.24316118437458167, loss3 0.0008034742029187989, loss4 3.060232438656385e-05, \n",
      "val-loss1 0.7265650033950806 val-loss2 0.20705662667751312 val-loss3 0.021433347836136818 val-loss4 3.4758629681164166e-06\n",
      "val score 0.5510786688970143\n",
      "epoch 31\n",
      "loss1 0.7412997992201285, loss2 0.2426651082932949, loss3 0.0010965048234290655, loss4 1.8958878709699174e-05, \n",
      "val-loss1 0.7255463600158691 val-loss2 0.2060992419719696 val-loss3 0.009004480205476284 val-loss4 2.6603372589306673e-06\n",
      "val score 0.5495526574326391\n",
      "epoch 32\n",
      "loss1 0.7400052046233957, loss2 0.24198490821502425, loss3 0.0014116572314047846, loss4 1.3272879651925574e-05, \n",
      "val-loss1 0.7244381308555603 val-loss2 0.20628151297569275 val-loss3 0.03216521069407463 val-loss4 3.6635062770074e-06\n",
      "val score 0.5499714379040483\n",
      "epoch 33\n",
      "loss1 0.7392839396541769, loss2 0.23923429287970066, loss3 0.0017138601159041916, loss4 1.0832565056840725e-05, \n",
      "val-loss1 0.7239663600921631 val-loss2 0.20474158227443695 val-loss3 0.026374632492661476 val-loss4 3.5046289212914417e-06\n",
      "val score 0.5490436753754806\n",
      "epoch 34\n",
      "loss1 0.7386144162579016, loss2 0.24063715457238935, loss3 0.0015415405072086617, loss4 1.1173357217392715e-05, \n",
      "val-loss1 0.7227810025215149 val-loss2 0.20405299961566925 val-loss3 0.02614210546016693 val-loss4 3.867193754558684e-06\n",
      "val score 0.5480646003208903\n",
      "epoch 35\n",
      "loss1 0.7372978322885253, loss2 0.23786304687911813, loss3 0.0016412121202103497, loss4 7.484635153270409e-06, \n",
      "val-loss1 0.7217584848403931 val-loss2 0.20355381071567535 val-loss3 0.008613458834588528 val-loss4 3.890051630150992e-06\n",
      "val score 0.5463725689757211\n",
      "epoch 36\n",
      "loss1 0.7364428700371222, loss2 0.23620706881311807, loss3 0.0011770204232148403, loss4 6.158385722508021e-06, \n",
      "val-loss1 0.720963716506958 val-loss2 0.20433203876018524 val-loss3 0.012541468255221844 val-loss4 1.7514099681648077e-06\n",
      "val score 0.5461681702901672\n",
      "epoch 37\n",
      "loss1 0.7359561432491649, loss2 0.23554862273687666, loss3 0.0013557240652682428, loss4 5.516366415618408e-06, \n",
      "val-loss1 0.7203060984611511 val-loss2 0.20365048944950104 val-loss3 0.02570042386651039 val-loss4 1.2596464102898608e-06\n",
      "val score 0.546229450988352\n",
      "epoch 38\n",
      "loss1 0.7351635884154927, loss2 0.23065767318687655, loss3 0.0022792526612068864, loss4 5.666702223420956e-06, \n",
      "val-loss1 0.7193319797515869 val-loss2 0.20254825055599213 val-loss3 0.010019759647548199 val-loss4 1.070738449016062e-06\n",
      "val score 0.5445430774566091\n",
      "epoch 39\n",
      "loss1 0.7345207380977544, loss2 0.2338456448844888, loss3 0.0012986099887215955, loss4 6.019201226660119e-06, \n",
      "val-loss1 0.7184222340583801 val-loss2 0.20296742022037506 val-loss3 0.030658716335892677 val-loss4 4.717295269074384e-06\n",
      "val score 0.5450222195664992\n",
      "epoch 40\n",
      "loss1 0.7329750433564186, loss2 0.23305839638818393, loss3 0.0018915609808490526, loss4 6.2404531475253444e-06, \n",
      "val-loss1 0.716710090637207 val-loss2 0.20212070643901825 val-loss3 0.007666049059480429 val-loss4 2.9354064281506e-06\n",
      "val score 0.5425046539571441\n",
      "epoch 41\n",
      "loss1 0.7318043512376872, loss2 0.23153935440561987, loss3 0.001266184917436807, loss4 7.774616821362459e-06, \n",
      "val-loss1 0.7157342433929443 val-loss2 0.20115794241428375 val-loss3 0.022296959534287453 val-loss4 2.73603041023307e-06\n",
      "val score 0.5423605436361527\n",
      "epoch 42\n",
      "loss1 0.7312065227465196, loss2 0.2302723488008434, loss3 0.0012735869257250504, loss4 6.564152608296519e-06, \n",
      "val-loss1 0.7150987386703491 val-loss2 0.200487419962883 val-loss3 0.003416539868339896 val-loss4 5.688859346264508e-06\n",
      "val score 0.5408377124982052\n",
      "epoch 43\n",
      "loss1 0.7304566685448993, loss2 0.23198324577374893, loss3 0.0009038878336220725, loss4 5.527332151897016e-06, \n",
      "val-loss1 0.7142524123191833 val-loss2 0.1997642070055008 val-loss3 0.026882214471697807 val-loss4 1.5993176702977507e-06\n",
      "val score 0.5412737207139968\n",
      "epoch 44\n",
      "loss1 0.7297573577273976, loss2 0.23059612868184393, loss3 0.000874068795052484, loss4 5.874495126466751e-06, \n",
      "val-loss1 0.7136834859848022 val-loss2 0.19992244243621826 val-loss3 0.010667609982192516 val-loss4 2.9939794785605045e-06\n",
      "val score 0.5400964588746887\n",
      "epoch 45\n",
      "loss1 0.7289267873222177, loss2 0.22863219678401947, loss3 0.0012519739592045714, loss4 6.693467252138031e-06, \n",
      "val-loss1 0.7124161124229431 val-loss2 0.19915196299552917 val-loss3 0.028679680079221725 val-loss4 4.518572950473754e-06\n",
      "val score 0.5399558812277747\n",
      "epoch 46\n",
      "loss1 0.728399093855511, loss2 0.2284197820858522, loss3 0.001360562634627885, loss4 7.156255481855954e-06, \n",
      "val-loss1 0.7118173837661743 val-loss2 0.19908344745635986 val-loss3 0.009626072831451893 val-loss4 3.666507836896926e-06\n",
      "val score 0.5385703450945585\n",
      "epoch 47\n",
      "loss1 0.7277176508849318, loss2 0.22929692945697092, loss3 0.001285743235216201, loss4 7.432014347779676e-06, \n",
      "val-loss1 0.7109889388084412 val-loss2 0.19908754527568817 val-loss3 0.007726680487394333 val-loss4 2.280085254824371e-06\n",
      "val score 0.5378962142496788\n",
      "epoch 48\n",
      "loss1 0.7269747772000053, loss2 0.227470156990669, loss3 0.0008782721240343315, loss4 7.609648295411634e-06, \n",
      "val-loss1 0.7102452516555786 val-loss2 0.1982652246952057 val-loss3 0.018868865445256233 val-loss4 3.7636509659932926e-06\n",
      "val score 0.5377683525527572\n",
      "epoch 49\n",
      "loss1 0.7260630543936383, loss2 0.2251955159008503, loss3 0.0008400029142979871, loss4 7.176265104259404e-06, \n",
      "val-loss1 0.7094112038612366 val-loss2 0.19864565134048462 val-loss3 0.006442104931920767 val-loss4 4.8143610911211e-06\n",
      "val score 0.5366393189356131\n",
      "epoch 50\n",
      "loss1 0.7258148687806997, loss2 0.2269682384688746, loss3 0.0011647830489726568, loss4 8.466502275826894e-06, \n",
      "val-loss1 0.7089089751243591 val-loss2 0.19823238253593445 val-loss3 0.006384663283824921 val-loss4 3.4999375202460214e-06\n",
      "val score 0.5362021672553056\n",
      "epoch 51\n",
      "loss1 0.7249603576280854, loss2 0.2244196432557973, loss3 0.000974562011006955, loss4 6.662544163563408e-06, \n",
      "val-loss1 0.7081437706947327 val-loss2 0.19786065816879272 val-loss3 0.006373264826834202 val-loss4 2.6463856102054706e-06\n",
      "val score 0.5355915666806935\n",
      "epoch 52\n",
      "loss1 0.7246422171592712, loss2 0.22701657478782264, loss3 0.0007994800061252053, loss4 9.435225908046876e-06, \n",
      "val-loss1 0.7075418829917908 val-loss2 0.19776715338230133 val-loss3 0.0098233912140131 val-loss4 7.57423276809277e-06\n",
      "val score 0.5353242970430527\n",
      "epoch 53\n",
      "loss1 0.7236682528799231, loss2 0.22290141440250658, loss3 0.001150138077553658, loss4 8.895359857516185e-06, \n",
      "val-loss1 0.7068926692008972 val-loss2 0.19786801934242249 val-loss3 0.008056278340518475 val-loss4 4.7521921260340605e-06\n",
      "val score 0.5348015238357448\n",
      "epoch 54\n",
      "loss1 0.7234689491716298, loss2 0.22593255374919285, loss3 0.0011949293508554217, loss4 8.842106152232274e-06, \n",
      "val-loss1 0.7061795592308044 val-loss2 0.19881145656108856 val-loss3 0.010420856066048145 val-loss4 2.3280058485397603e-06\n",
      "val score 0.5346091419773756\n",
      "epoch 55\n",
      "loss1 0.7223710404200987, loss2 0.22448350506072695, loss3 0.0011832624904028225, loss4 9.293640056801616e-06, \n",
      "val-loss1 0.7055887579917908 val-loss2 0.1987186223268509 val-loss3 0.018209517002105713 val-loss4 5.275669082038803e-06\n",
      "val score 0.534566594693183\n",
      "epoch 56\n",
      "loss1 0.7222366231408986, loss2 0.22291932407427917, loss3 0.0012409980051663958, loss4 9.533093733890299e-06, \n",
      "val-loss1 0.7050290703773499 val-loss2 0.1982848346233368 val-loss3 0.023507921025156975 val-loss4 6.10519327892689e-06\n",
      "val score 0.5343530174997341\n",
      "epoch 57\n",
      "loss1 0.7215098860588941, loss2 0.22113658690994437, loss3 0.001986841946332292, loss4 7.928840892129136e-06, \n",
      "val-loss1 0.704035758972168 val-loss2 0.19800718128681183 val-loss3 0.03355422988533974 val-loss4 6.113353265391197e-06\n",
      "val score 0.5341044846998102\n",
      "epoch 58\n",
      "loss1 0.7209091078151356, loss2 0.22030008397996426, loss3 0.0023497922110519457, loss4 8.829447655113075e-06, \n",
      "val-loss1 0.7034836411476135 val-loss2 0.1979873925447464 val-loss3 0.022165635600686073 val-loss4 9.685550139693078e-06\n",
      "val score 0.53314479336982\n",
      "epoch 59\n",
      "loss1 0.7205565585331484, loss2 0.22389555333012884, loss3 0.0010409819495345635, loss4 8.756260859337834e-06, \n",
      "val-loss1 0.7031465172767639 val-loss2 0.19679315388202667 val-loss3 0.027653783559799194 val-loss4 4.237399480189197e-06\n",
      "val score 0.532944093918104\n",
      "[[-0.08826777 -3.798853    7.2712283  ...  0.10568003 -0.13245238\n",
      "   2.112794  ]\n",
      " [-0.9239605  -3.4351869   7.142234   ...  1.0217288   0.12609495\n",
      "   0.5117292 ]\n",
      " [-0.89505804 -2.912077    5.4494357  ...  0.17211142  0.05205516\n",
      "   1.019518  ]\n",
      " ...\n",
      " [ 1.0496302   9.960913   -6.5502     ... -0.48232487 -1.1722448\n",
      "  -1.2914467 ]\n",
      " [-0.07561678 -1.0034658  -5.8866425  ... -1.1360108   0.9818847\n",
      "   0.07673251]\n",
      " [ 0.12621887  8.096723   -3.8777716  ... -0.49613136 -1.5797157\n",
      "  -1.1602592 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-03 17:49:16,628][dance][set_seed] Setting global random seed to 1247938998\n",
      "[INFO][2023-10-03 17:49:16,630][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_multi_atac2gex/openproblems_2022_multi_atac2gex.open_dataset.output_mod1.h5ad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.533, 0.507)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-03 17:49:22,237][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_multi_atac2gex/openproblems_2022_multi_atac2gex.open_dataset.output_mod2.h5ad\n",
      "[INFO][2023-10-03 17:49:25,826][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_multi_atac2gex/openproblems_2022_multi_atac2gex.open_dataset.output_train_mod1.h5ad\n",
      "[INFO][2023-10-03 17:49:29,592][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_multi_atac2gex/openproblems_2022_multi_atac2gex.open_dataset.output_train_mod2.h5ad\n",
      "[INFO][2023-10-03 17:49:32,168][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_multi_atac2gex/openproblems_2022_multi_atac2gex.open_dataset.output_solution.h5ad\n",
      "/home/zyxing/dance/dance/transforms/preprocess.py:147: RuntimeWarning: divide by zero encountered in divide\n",
      "  self.idf = X.shape[0] / X.sum(axis=0)\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py:843: UserWarning: Received a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py:843: UserWarning: Received a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n",
      "[INFO][2023-10-03 18:08:52,652][dance][_maybe_preprocess] Preprocessing done.\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/mudata/_core/mudata.py:491: UserWarning: Cannot join columns with the same name because var_names are intersecting.\n",
      "  warnings.warn(\n",
      "[INFO][2023-10-03 18:08:53,100][dance][load_data] Raw data loaded:\n",
      "Data object that wraps (.data):\n",
      "MuData object with n_obs × n_vars = 105868 × 501302\n",
      "  uns:\t'dance_config'\n",
      "  5 modalities\n",
      "    mod1:\t105868 x 10000\n",
      "      obs:\t'batch', 'cell_type'\n",
      "      var:\t'feature_types', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm', 'mean', 'std'\n",
      "      uns:\t'dataset_id', 'hvg'\n",
      "      obsm:\t'X_pca'\n",
      "      layers:\t'counts'\n",
      "    mod2:\t105868 x 10000\n",
      "      obs:\t'batch'\n",
      "      var:\t'feature_types', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm', 'mean', 'std'\n",
      "      uns:\t'dataset_id', 'hvg'\n",
      "      obsm:\t'X_pca'\n",
      "      layers:\t'counts'\n",
      "    meta1:\t74107 x 228942\n",
      "      obs:\t'batch'\n",
      "      var:\t'feature_types'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "    meta2:\t74107 x 23418\n",
      "      obs:\t'batch'\n",
      "      var:\t'feature_types'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "    test_sol:\t105868 x 228942\n",
      "      obs:\t'batch', 'cell_type'\n",
      "      var:\t'feature_types'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "[INFO][2023-10-03 18:08:53,100][dance][wrapped_func] Took 0:19:36.470557 to load and process data.\n",
      "[INFO][2023-10-03 18:08:53,711][dance][set_config_from_dict] Setting config 'feature_mod' to ['mod1', 'mod2']\n",
      "[INFO][2023-10-03 18:08:53,712][dance][set_config_from_dict] Setting config 'label_mod' to ['mod1']\n",
      "[INFO][2023-10-03 18:08:53,713][dance][set_config_from_dict] Setting config 'feature_channel' to ['X_pca', 'X_pca']\n",
      "[INFO][2023-10-03 18:08:53,713][dance][set_config_from_dict] Setting config 'label_channel' to ['labels']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "loss1 0.9126302859255375, loss2 1.1689277182098563, loss3 1.877712727048015, loss4 0.3264447872647802, \n",
      "val-loss1 0.7879327535629272 val-loss2 0.6117417812347412 val-loss3 6.011832237243652 val-loss4 0.03547019511461258\n",
      "val score 0.9762664053589106\n",
      "epoch 1\n",
      "loss1 0.7167177186667464, loss2 0.5916646989702269, loss3 1.256161720925615, loss4 0.17249394447066402, \n",
      "val-loss1 0.6336088180541992 val-loss2 0.45634716749191284 val-loss3 3.370448112487793 val-loss4 0.014594639651477337\n",
      "val score 0.7040477437432855\n",
      "epoch 2\n",
      "loss1 0.6437534466954588, loss2 0.4780203813814935, loss3 0.9741421021122969, loss4 0.11781825278779022, \n",
      "val-loss1 0.5955461859703064 val-loss2 0.39776623249053955 val-loss3 2.1228954792022705 val-loss4 0.008486340753734112\n",
      "val score 0.6030046676751226\n",
      "epoch 3\n",
      "loss1 0.618204427584437, loss2 0.4292549636527782, loss3 0.7548332770589654, loss4 0.0847671890759286, \n",
      "val-loss1 0.5808871984481812 val-loss2 0.3675185739994049 val-loss3 1.2701523303985596 val-loss4 0.004936907906085253\n",
      "val score 0.54387921562884\n",
      "epoch 4\n",
      "loss1 0.606211559008096, loss2 0.4012795286324188, loss3 0.5671285669539721, loss4 0.061156677295460954, \n",
      "val-loss1 0.5712849497795105 val-loss2 0.3476996421813965 val-loss3 0.9014329314231873 val-loss4 0.003546350635588169\n",
      "val score 0.5146883573848754\n",
      "epoch 5\n",
      "loss1 0.5981671023004838, loss2 0.38283766931249896, loss3 0.3943832867018139, loss4 0.044602680055580976, \n",
      "val-loss1 0.5648564696311951 val-loss2 0.3353229761123657 val-loss3 0.592260479927063 val-loss4 0.0024358106311410666\n",
      "val score 0.49219893849221985\n",
      "epoch 6\n",
      "loss1 0.5921089267002717, loss2 0.3682741217940818, loss3 0.23326945356057802, loss4 0.032614316947701325, \n",
      "val-loss1 0.5597678422927856 val-loss2 0.32696616649627686 val-loss3 0.3232547640800476 val-loss4 0.0017514239298179746\n",
      "val score 0.47348103230469857\n",
      "epoch 7\n",
      "loss1 0.5870943911202992, loss2 0.3625529237830912, loss3 0.09111540887561691, loss4 0.023016110048380518, \n",
      "val-loss1 0.555587112903595 val-loss2 0.32096460461616516 val-loss3 0.12394984811544418 val-loss4 0.0012011928483843803\n",
      "val score 0.45936145200394096\n",
      "epoch 8\n",
      "loss1 0.5828398875607789, loss2 0.35363456902613166, loss3 0.005474617032028507, loss4 0.016237669105406936, \n",
      "val-loss1 0.5512532591819763 val-loss2 0.31564855575561523 val-loss3 0.057373445481061935 val-loss4 0.0007926799007691443\n",
      "val score 0.451915298847598\n",
      "epoch 9\n",
      "loss1 0.5788316858633784, loss2 0.34937416301428814, loss3 0.002612911592653547, loss4 0.011040720427479908, \n",
      "val-loss1 0.547498881816864 val-loss2 0.3118354082107544 val-loss3 0.018092241138219833 val-loss4 0.0005435641505755484\n",
      "val score 0.44654808917839545\n",
      "epoch 10\n",
      "loss1 0.5752091380476042, loss2 0.3432294266824504, loss3 0.0020702891016222595, loss4 0.007447517676037231, \n",
      "val-loss1 0.5441722869873047 val-loss2 0.30835628509521484 val-loss3 0.052412595599889755 val-loss4 0.00036569504300132394\n",
      "val score 0.44523077244230075\n",
      "epoch 11\n",
      "loss1 0.5718959051234122, loss2 0.3414214561686261, loss3 0.001842310698791798, loss4 0.004850263735777094, \n",
      "val-loss1 0.5410292148590088 val-loss2 0.30431652069091797 val-loss3 0.025045031681656837 val-loss4 0.0002339075435884297\n",
      "val score 0.440847701500752\n",
      "epoch 12\n",
      "loss1 0.5687918913273411, loss2 0.33956056287270464, loss3 0.0015653963069669646, loss4 0.003086486907732737, \n",
      "val-loss1 0.5385579466819763 val-loss2 0.30284368991851807 val-loss3 0.007807465735822916 val-loss4 0.0001514101168140769\n",
      "val score 0.43795724445371886\n",
      "epoch 13\n",
      "loss1 0.5665661428720896, loss2 0.3370881510599879, loss3 0.0013949245521940917, loss4 0.0018978112400331684, \n",
      "val-loss1 0.5357675552368164 val-loss2 0.30029886960983276 val-loss3 0.03303646668791771 val-loss4 9.102449985221028e-05\n",
      "val score 0.4367534371471265\n",
      "epoch 14\n",
      "loss1 0.5637178257221483, loss2 0.3346853033276915, loss3 0.0011568436452866538, loss4 0.0011489730513164105, \n",
      "val-loss1 0.533030092716217 val-loss2 0.29857802391052246 val-loss3 0.02053539641201496 val-loss4 5.477233207784593e-05\n",
      "val score 0.433866178120661\n",
      "epoch 15\n",
      "loss1 0.5610465148023067, loss2 0.33014116305431335, loss3 0.001333588146638367, loss4 0.0006646839144216665, \n",
      "val-loss1 0.5303866267204285 val-loss2 0.2968355417251587 val-loss3 0.021271929144859314 val-loss4 3.540542093105614e-05\n",
      "val score 0.4317031137776211\n",
      "epoch 16\n",
      "loss1 0.5584691794774005, loss2 0.32957144889212747, loss3 0.0012184190863782525, loss4 0.00037531691331430585, \n",
      "val-loss1 0.5278127193450928 val-loss2 0.2947574555873871 val-loss3 0.023401159793138504 val-loss4 2.2870923203299753e-05\n",
      "val score 0.4295915961948594\n",
      "epoch 17\n",
      "loss1 0.5562621518855787, loss2 0.3278073315857021, loss3 0.001080490650634907, loss4 0.0002055305345312742, \n",
      "val-loss1 0.5251510143280029 val-loss2 0.2938506007194519 val-loss3 0.008951421827077866 val-loss4 1.2106821486668196e-05\n",
      "val score 0.4268240066059206\n",
      "epoch 18\n",
      "loss1 0.5524448483954859, loss2 0.32788949078730956, loss3 0.0011287283448712148, loss4 0.00010972604144876467, \n",
      "val-loss1 0.5203216671943665 val-loss2 0.29209187626838684 val-loss3 0.013729438185691833 val-loss4 8.234560482378583e-06\n",
      "val score 0.4233304259270426\n",
      "epoch 19\n",
      "loss1 0.5488860370548627, loss2 0.3227304158774951, loss3 0.0013259777195844089, loss4 5.960421188368341e-05, \n",
      "val-loss1 0.5182406902313232 val-loss2 0.29140737652778625 val-loss3 0.020429061725735664 val-loss4 5.575113391387276e-06\n",
      "val score 0.4220716903094398\n",
      "epoch 20\n",
      "loss1 0.5465751809018259, loss2 0.32439506850169814, loss3 0.0012545690792683825, loss4 3.229518003487615e-05, \n",
      "val-loss1 0.5163072347640991 val-loss2 0.2891906201839447 val-loss3 0.03356136381626129 val-loss4 4.1768039409362245e-06\n",
      "val score 0.4209314654026684\n",
      "epoch 21\n",
      "loss1 0.544957806135862, loss2 0.3209662233827678, loss3 0.0011818528630573458, loss4 1.9716294265460163e-05, \n",
      "val-loss1 0.5143322348594666 val-loss2 0.28965267539024353 val-loss3 0.023383978754281998 val-loss4 4.380753125587944e-06\n",
      "val score 0.41913251745504565\n",
      "epoch 22\n",
      "loss1 0.5427381077795538, loss2 0.3222421213188244, loss3 0.0011813802836118054, loss4 1.4111717536328769e-05, \n",
      "val-loss1 0.5125664472579956 val-loss2 0.2875913083553314 val-loss3 0.015173236839473248 val-loss4 3.7278082345437724e-06\n",
      "val score 0.41707362298404854\n",
      "epoch 23\n",
      "loss1 0.5412990300709964, loss2 0.31958910003873225, loss3 0.00108947008643797, loss4 1.1022006643223771e-05, \n",
      "val-loss1 0.5111551284790039 val-loss2 0.286548376083374 val-loss3 0.04081002250313759 val-loss4 2.1757002741651377e-06\n",
      "val score 0.4171588750621481\n",
      "epoch 24\n",
      "loss1 0.5395191780483449, loss2 0.31913597222047907, loss3 0.0010541406457218207, loss4 9.387910899619318e-06, \n",
      "val-loss1 0.5094746947288513 val-loss2 0.28582462668418884 val-loss3 0.021331876516342163 val-loss4 4.317133971198928e-06\n",
      "val score 0.4148640213295493\n",
      "epoch 25\n",
      "loss1 0.5383829237850568, loss2 0.31611477157086815, loss3 0.0010520799913290775, loss4 8.425519979048568e-06, \n",
      "val-loss1 0.5081292986869812 val-loss2 0.28491178154945374 val-loss3 0.02846602536737919 val-loss4 4.7190483201120514e-06\n",
      "val score 0.41409640261156255\n",
      "epoch 26\n",
      "loss1 0.5366356336433469, loss2 0.31678507346233337, loss3 0.0011992463402144384, loss4 8.931459457669513e-06, \n",
      "val-loss1 0.5069057941436768 val-loss2 0.2843703329563141 val-loss3 0.025723500177264214 val-loss4 4.366689609014429e-06\n",
      "val score 0.41299451583518015\n",
      "epoch 27\n",
      "loss1 0.5354358330937742, loss2 0.31471125258289223, loss3 0.0010947767629124621, loss4 8.599536863411378e-06, \n",
      "val-loss1 0.5056232213973999 val-loss2 0.2829967439174652 val-loss3 0.020246148109436035 val-loss4 5.279701781546464e-06\n",
      "val score 0.41154817515223385\n",
      "epoch 28\n",
      "loss1 0.5348020132261379, loss2 0.3137247886594015, loss3 0.0009494110009231327, loss4 8.087123275195952e-06, \n",
      "val-loss1 0.5044329762458801 val-loss2 0.2855534255504608 val-loss3 0.031875308603048325 val-loss4 2.5272183847846463e-06\n",
      "val score 0.41180766027327986\n",
      "epoch 29\n",
      "loss1 0.532733853991705, loss2 0.3138250399181861, loss3 0.001020694129748398, loss4 7.70514059987009e-06, \n",
      "val-loss1 0.5031681656837463 val-loss2 0.28223270177841187 val-loss3 0.023149704560637474 val-loss4 2.0228624180163024e-06\n",
      "val score 0.4098218427054575\n",
      "epoch 30\n",
      "loss1 0.5318066414075954, loss2 0.3127362423270713, loss3 0.0008602736428698155, loss4 8.404549002954657e-06, \n",
      "val-loss1 0.5021151900291443 val-loss2 0.2815400958061218 val-loss3 0.018276294693350792 val-loss4 5.728974429075606e-06\n",
      "val score 0.4087027533650144\n",
      "epoch 31\n",
      "loss1 0.5306136280525732, loss2 0.31088686580876357, loss3 0.0011059257358700066, loss4 9.456536322466643e-06, \n",
      "val-loss1 0.5010226368904114 val-loss2 0.28105273842811584 val-loss3 0.022844457998871803 val-loss4 9.52067148318747e-06\n",
      "val score 0.4080690924424289\n",
      "epoch 32\n",
      "loss1 0.5295092923040609, loss2 0.31041119696984765, loss3 0.0010668102483876504, loss4 1.0426406021441425e-05, \n",
      "val-loss1 0.499986857175827 val-loss2 0.2807983458042145 val-loss3 0.028804706409573555 val-loss4 9.007741027744487e-06\n",
      "val score 0.40759115489145187\n",
      "epoch 33\n",
      "loss1 0.5281849539916934, loss2 0.30886262518758995, loss3 0.0010515939548055337, loss4 1.0052365421814949e-05, \n",
      "val-loss1 0.49884554743766785 val-loss2 0.28017860651016235 val-loss3 0.01632852293550968 val-loss4 2.796575472530094e-06\n",
      "val score 0.40604417048394903\n",
      "epoch 34\n",
      "loss1 0.5272286379610309, loss2 0.3107451067398523, loss3 0.0009894034665749757, loss4 1.0228345013100953e-05, \n",
      "val-loss1 0.4977891445159912 val-loss2 0.27970731258392334 val-loss3 0.009436517022550106 val-loss4 3.0944172522140434e-06\n",
      "val score 0.4048658442499686\n",
      "epoch 35\n",
      "loss1 0.5260916538820922, loss2 0.3075802700437662, loss3 0.0008557885406469528, loss4 8.932583367482906e-06, \n",
      "val-loss1 0.4967505633831024 val-loss2 0.27951985597610474 val-loss3 0.01807391084730625 val-loss4 7.037294835754437e-06\n",
      "val score 0.4045334129704997\n",
      "epoch 36\n",
      "loss1 0.5253877737594925, loss2 0.30646111082484706, loss3 0.0009468978351756987, loss4 8.828106628528055e-06, \n",
      "val-loss1 0.4960372745990753 val-loss2 0.2793601453304291 val-loss3 0.03209330141544342 val-loss4 3.4240092645632103e-06\n",
      "val score 0.40470295755667396\n",
      "epoch 37\n",
      "loss1 0.5238354467708646, loss2 0.30658184401406585, loss3 0.000907879137813526, loss4 9.481687860384332e-06, \n",
      "val-loss1 0.49507611989974976 val-loss2 0.27755847573280334 val-loss3 0.011455850675702095 val-loss4 7.777552127663512e-06\n",
      "val score 0.402638160487777\n",
      "epoch 38\n",
      "loss1 0.523244428725643, loss2 0.30638066411928366, loss3 0.0010313423937417653, loss4 1.1329358286962566e-05, \n",
      "val-loss1 0.4943561553955078 val-loss2 0.2775145173072815 val-loss3 0.04961419105529785 val-loss4 1.4378853848029394e-05\n",
      "val score 0.4040336407337691\n",
      "epoch 39\n",
      "loss1 0.5225719709432762, loss2 0.3058489782892111, loss3 0.000979631745082305, loss4 1.1468703209494511e-05, \n",
      "val-loss1 0.4934260845184326 val-loss2 0.2784309387207031 val-loss3 0.023605475202202797 val-loss4 5.345299086911837e-06\n",
      "val score 0.4022649879321079\n",
      "epoch 40\n",
      "loss1 0.521411783367623, loss2 0.3071207967195802, loss3 0.0008912984466620984, loss4 1.23200675365755e-05, \n",
      "val-loss1 0.4926562011241913 val-loss2 0.278055340051651 val-loss3 0.037070393562316895 val-loss4 1.3823944755131379e-05\n",
      "val score 0.40232461967261773\n",
      "epoch 41\n",
      "loss1 0.520732422366397, loss2 0.3052599786119607, loss3 0.0011314557913472193, loss4 1.1871522384138515e-05, \n",
      "val-loss1 0.491755872964859 val-loss2 0.2770878076553345 val-loss3 0.02288367785513401 val-loss4 9.55000905378256e-06\n",
      "val score 0.4007913339996776\n",
      "epoch 42\n",
      "loss1 0.5198378667576622, loss2 0.3043536828219436, loss3 0.000991415493687942, loss4 1.4466829513526656e-05, \n",
      "val-loss1 0.4905947744846344 val-loss2 0.2766554057598114 val-loss3 0.03078879974782467 val-loss4 6.852261776657542e-06\n",
      "val score 0.4002872058916864\n",
      "epoch 43\n",
      "loss1 0.5187801193189985, loss2 0.303906376011499, loss3 0.0011976378514850867, loss4 1.2203756324121087e-05, \n",
      "val-loss1 0.48964738845825195 val-loss2 0.2766689360141754 val-loss3 0.009355232119560242 val-loss4 1.4318745343189221e-05\n",
      "val score 0.3985554366668566\n",
      "epoch 44\n",
      "loss1 0.5180516679778354, loss2 0.30441786633193035, loss3 0.0011088000052832494, loss4 1.2544889687117276e-05, \n",
      "val-loss1 0.4891234040260315 val-loss2 0.27677786350250244 val-loss3 0.0163903646171093 val-loss4 6.592001227545552e-06\n",
      "val score 0.39856180334963937\n",
      "epoch 45\n",
      "loss1 0.5171550462264141, loss2 0.3022619756578489, loss3 0.0010285275510178154, loss4 1.397955955548491e-05, \n",
      "val-loss1 0.48859140276908875 val-loss2 0.2757416367530823 val-loss3 0.0086711086332798 val-loss4 1.1501011613290757e-05\n",
      "val score 0.3975964397712232\n",
      "epoch 46\n",
      "loss1 0.5162108383560908, loss2 0.30297530584662924, loss3 0.0008879759610419069, loss4 1.3588116017734776e-05, \n",
      "val-loss1 0.4875897765159607 val-loss2 0.2756032347679138 val-loss3 0.011866278015077114 val-loss4 6.7795958784699906e-06\n",
      "val score 0.397027143395303\n",
      "epoch 47\n",
      "loss1 0.5157548259687788, loss2 0.30310400273963695, loss3 0.001045075848384028, loss4 1.2918187510752064e-05, \n",
      "val-loss1 0.48697301745414734 val-loss2 0.2758901119232178 val-loss3 0.025288037955760956 val-loss4 7.147548330976861e-06\n",
      "val score 0.3973238938777513\n",
      "epoch 48\n",
      "loss1 0.5150856682817444, loss2 0.3012352114870348, loss3 0.0008986498816169884, loss4 1.2632606337548994e-05, \n",
      "val-loss1 0.4865435063838959 val-loss2 0.27540960907936096 val-loss3 0.01757991500198841 val-loss4 1.4933916645532008e-05\n",
      "val score 0.39654211873053097\n",
      "epoch 49\n",
      "loss1 0.5142850946379072, loss2 0.3014189364345929, loss3 0.0010459154603455415, loss4 1.2565674150841602e-05, \n",
      "val-loss1 0.48574575781822205 val-loss2 0.2747369110584259 val-loss3 0.01932242326438427 val-loss4 7.412687864416512e-06\n",
      "val score 0.39593590448205307\n",
      "epoch 50\n",
      "loss1 0.5136380739339436, loss2 0.3008814458628647, loss3 0.0010542802497982722, loss4 1.360147111083404e-05, \n",
      "val-loss1 0.4852572977542877 val-loss2 0.27484217286109924 val-loss3 0.01767616532742977 val-loss4 3.617440825109952e-06\n",
      "val score 0.39553253213863393\n",
      "epoch 51\n",
      "loss1 0.5133831619306375, loss2 0.30009485917691964, loss3 0.0010097731579759848, loss4 1.5078606498329935e-05, \n",
      "val-loss1 0.4843977689743042 val-loss2 0.2738800346851349 val-loss3 0.017073316499590874 val-loss4 1.6917396351345815e-05\n",
      "val score 0.394708956913837\n",
      "epoch 52\n",
      "loss1 0.5124341451939736, loss2 0.2973314558959189, loss3 0.0010192500113443833, loss4 1.6996432992625042e-05, \n",
      "val-loss1 0.4838855266571045 val-loss2 0.27396926283836365 val-loss3 0.011284515261650085 val-loss4 1.4337582797452342e-05\n",
      "val score 0.39407866386986823\n",
      "epoch 53\n",
      "loss1 0.5117082102153138, loss2 0.2987314649210631, loss3 0.0010143796974865947, loss4 1.4756346382726142e-05, \n",
      "val-loss1 0.48346972465515137 val-loss2 0.2742786109447479 val-loss3 0.017336634919047356 val-loss4 5.097591383673716e-06\n",
      "val score 0.394151616073077\n",
      "epoch 54\n",
      "loss1 0.5113193333603954, loss2 0.2994388009755666, loss3 0.0008884491450028878, loss4 1.2238259335161358e-05, \n",
      "val-loss1 0.4828316271305084 val-loss2 0.2739562392234802 val-loss3 0.031946100294589996 val-loss4 4.487083060666919e-06\n",
      "val score 0.3943709162049344\n",
      "epoch 55\n",
      "loss1 0.5105546451251926, loss2 0.2960125181738657, loss3 0.0009799207607817388, loss4 1.4683335199387822e-05, \n",
      "val-loss1 0.4819988012313843 val-loss2 0.27305570244789124 val-loss3 0.026165127754211426 val-loss4 8.123380212055054e-06\n",
      "val score 0.3933189639082684\n",
      "epoch 56\n",
      "loss1 0.5098505882361463, loss2 0.2977852782675328, loss3 0.000992333114134745, loss4 1.4242867866470141e-05, \n",
      "val-loss1 0.48125308752059937 val-loss2 0.27373069524765015 val-loss3 0.0394851379096508 val-loss4 1.1447250471974257e-05\n",
      "val score 0.39359812957195567\n",
      "epoch 57\n",
      "loss1 0.5091289691342652, loss2 0.30028137496409524, loss3 0.0011515702971413675, loss4 1.5853484646798885e-05, \n",
      "val-loss1 0.4808322787284851 val-loss2 0.2734648883342743 val-loss3 0.008298452012240887 val-loss4 1.042573967424687e-05\n",
      "val score 0.39169101666439016\n",
      "epoch 58\n",
      "loss1 0.5083984127481476, loss2 0.2985806686960104, loss3 0.0011001365443243723, loss4 1.4710874553160645e-05, \n",
      "val-loss1 0.48019248247146606 val-loss2 0.27383849024772644 val-loss3 0.01005174033343792 val-loss4 6.448371550504817e-06\n",
      "val score 0.3914053452148209\n",
      "epoch 59\n",
      "loss1 0.5084390990606701, loss2 0.2973467667821709, loss3 0.000943362706861608, loss4 1.5359218168183043e-05, \n",
      "val-loss1 0.47986310720443726 val-loss2 0.27335312962532043 val-loss3 0.02280205674469471 val-loss4 1.0699771337385755e-05\n",
      "val score 0.3917154387939718\n",
      "[[-1.9626435   3.7373123  -3.9793816  ... -1.3479762  -2.334669\n",
      "  -0.84932774]\n",
      " [-1.7184949   5.25894    -4.257068   ... -0.94024944 -2.3363981\n",
      "  -1.2908818 ]\n",
      " [ 0.530567   -2.5593977   8.076299   ...  2.8237247  -0.21357481\n",
      "  -0.01735118]\n",
      " ...\n",
      " [-1.0636955  -3.2222288   1.7909782  ... -0.02835945  1.6662539\n",
      "   1.1665051 ]\n",
      " [-1.6935961   7.1013064  -2.9269335  ... -2.4243014   0.11512885\n",
      "  -1.2970878 ]\n",
      " [ 0.6869449  -0.61584854 -3.5574436  ... -1.3483506   2.5279188\n",
      "  -0.8919128 ]]\n",
      "(0.546, 0.48)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'To reproduce scMoGCN on other samples, please refer to command lines belows:\\n\\nGEX-ADT:\\npython scmogcn.py --subtask openproblems_bmmc_cite_phase2 --device cuda\\n\\nGEX-ATAC:\\npython scmogcn.py --subtask openproblems_bmmc_multiome_phase2 --device cuda\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scMoGCN_scores=[]\n",
    "import argparse\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from dance.datasets.multimodality import JointEmbeddingNIPSDataset\n",
    "from dance.modules.multi_modality.joint_embedding.scmogcn import ScMoGCNWrapper\n",
    "from dance.transforms.graph.cell_feature_graph import CellFeatureBipartiteGraph\n",
    "from dance.utils import set_seed\n",
    "\n",
    "\n",
    "rndseed = random.randint(0, 2147483647)\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-t\", \"--subtask\", default=datasets[0],\n",
    "                    choices=datasets)\n",
    "parser.add_argument(\"-d\", \"--data_folder\", default=\"../../../../data/joint_embedding\")\n",
    "parser.add_argument(\"-pre\", \"--pretrained_folder\", default=\"./data/joint_embedding/pretrained\")\n",
    "parser.add_argument(\"-csv\", \"--csv_path\", default=\"decoupled_lsi.csv\")\n",
    "parser.add_argument(\"-l\", \"--layers\", default=3, type=int, choices=[3, 4, 5, 6, 7])\n",
    "parser.add_argument(\"-dis\", \"--disable_propagation\", default=0, type=int, choices=[0, 1, 2])\n",
    "parser.add_argument(\"-seed\", \"--rnd_seed\", default=rndseed, type=int)\n",
    "parser.add_argument(\"-cpu\", \"--cpus\", default=1, type=int)\n",
    "parser.add_argument(\"-device\", \"--device\", default=\"cuda\")\n",
    "parser.add_argument(\"-bs\", \"--batch_size\", default=512, type=int)\n",
    "parser.add_argument(\"-nm\", \"--normalize\", default=1, type=int, choices=[0, 1])\n",
    "parser.add_argument(\"--span\", default=0.3, type=float)\n",
    "\n",
    "for dataset in datasets:\n",
    "    args = parser.parse_args(['--subtask',dataset,'--device','cuda','--span','1.0'])\n",
    "\n",
    "    device = args.device\n",
    "    pre_normalize = bool(args.normalize)\n",
    "    torch.set_num_threads(args.cpus)\n",
    "    rndseed = args.rnd_seed\n",
    "    set_seed(rndseed)\n",
    "\n",
    "    dataset = JointEmbeddingNIPSDataset(args.subtask, root=args.data_folder, preprocess=\"feature_selection\", normalize=True,span=args.span)\n",
    "    data = dataset.load_data()\n",
    "    train_size = len(data.get_split_idx(\"train\"))\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    labels = le.fit_transform(data.mod[\"test_sol\"].obs[\"cell_type\"])\n",
    "    data.mod[\"mod1\"].obsm[\"labels\"] = labels\n",
    "    \n",
    "    data = CellFeatureBipartiteGraph(cell_feature_channel=\"X_pca\", mod=\"mod1\")(data)\n",
    "    data = CellFeatureBipartiteGraph(cell_feature_channel=\"X_pca\", mod=\"mod2\")(data)\n",
    "    data.set_config(\n",
    "        feature_mod=[\"mod1\", \"mod2\"],\n",
    "        label_mod=[\"mod1\"],\n",
    "        feature_channel=[\"X_pca\", \"X_pca\"],\n",
    "        label_channel=[\"labels\"],\n",
    "    )\n",
    "    (x_mod1, x_mod2), (cell_type) = data.get_data(return_type=\"torch\")\n",
    "    phase_score =torch.transpose(torch.tensor([[0.0]*(x_mod1.shape[0]),[0]*x_mod1.shape[0]]),0,1)\n",
    "    batch_label=torch.tensor([0.0]*(x_mod1.shape[0]))\n",
    "\n",
    "    model = ScMoGCNWrapper(args, num_celL_types=int(cell_type.max() + 1), num_batches=int(batch_label.max() + 1),\n",
    "                           num_phases=phase_score.shape[1], num_features=x_mod1.shape[1] + x_mod2.shape[1])\n",
    "    model.fit(\n",
    "        g_mod1=data.data[\"mod1\"].uns[\"g\"],\n",
    "        g_mod2=data.data[\"mod2\"].uns[\"g\"],\n",
    "        train_size=train_size,\n",
    "        cell_type=cell_type,\n",
    "        batch_label=batch_label,\n",
    "        phase_score=phase_score,\n",
    "    )\n",
    "    model.load(f\"models/model_joint_embedding_{rndseed}.pth\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        test_id = np.arange(train_size, x_mod1.shape[0])\n",
    "        labels = cell_type.numpy()[test_id]\n",
    "        embeds = model.predict(test_id).cpu().numpy()\n",
    "        print(embeds)\n",
    "        score=model.score(test_id, labels, metric=\"clustering\")\n",
    "        print(score)\n",
    "        scMoGCN_scores.append(score)\n",
    "\"\"\"To reproduce scMoGCN on other samples, please refer to command lines belows:\n",
    "\n",
    "GEX-ADT:\n",
    "python scmogcn.py --subtask openproblems_bmmc_cite_phase2 --device cuda\n",
    "\n",
    "GEX-ATAC:\n",
    "python scmogcn.py --subtask openproblems_bmmc_multiome_phase2 --device cuda\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.536, 0.464), (0.388, 0.275), (0.533, 0.507), (0.546, 0.48)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scMoGCN_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-04 10:00:25,923][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_BRAIN_atac2gex/GSE140203_BRAIN_atac2gex.GSE140203_dataset.output_mod1.h5ad\n",
      "[INFO][2023-10-04 10:00:26,338][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_BRAIN_atac2gex/GSE140203_BRAIN_atac2gex.GSE140203_dataset.output_mod2.h5ad\n",
      "[INFO][2023-10-04 10:00:26,473][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_BRAIN_atac2gex/GSE140203_BRAIN_atac2gex.GSE140203_dataset.output_train_mod1.h5ad\n",
      "[INFO][2023-10-04 10:00:26,866][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_BRAIN_atac2gex/GSE140203_BRAIN_atac2gex.GSE140203_dataset.output_train_mod2.h5ad\n",
      "[INFO][2023-10-04 10:00:26,959][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_BRAIN_atac2gex/GSE140203_BRAIN_atac2gex.GSE140203_dataset.output_solution.h5ad\n",
      "[INFO][2023-10-04 10:00:51,510][dance][_maybe_preprocess] Preprocessing done.\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/mudata/_core/mudata.py:491: UserWarning: Cannot join columns with the same name because var_names are intersecting.\n",
      "  warnings.warn(\n",
      "[INFO][2023-10-04 10:00:51,989][dance][load_data] Raw data loaded:\n",
      "Data object that wraps (.data):\n",
      "MuData object with n_obs × n_vars = 3291 × 685945\n",
      "  uns:\t'dance_config'\n",
      "  5 modalities\n",
      "    mod1:\t3291 x 10000\n",
      "      var:\t'num', 'start', 'end', 'n_counts', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm'\n",
      "      uns:\t'dataset_id', 'hvg'\n",
      "      obsm:\t'X_pca'\n",
      "      layers:\t'counts'\n",
      "    mod2:\t3291 x 10000\n",
      "      var:\t'gene', 'n_counts', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm'\n",
      "      uns:\t'dataset_id', 'hvg'\n",
      "      obsm:\t'X_pca'\n",
      "      layers:\t'counts'\n",
      "    meta1:\t2303 x 324007\n",
      "      var:\t'num', 'start', 'end'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "    meta2:\t2303 x 17931\n",
      "      var:\t'gene'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "    test_sol:\t3291 x 324007\n",
      "      obs:\t'atac.bc', 'cell_type'\n",
      "      var:\t'num', 'start', 'end'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "[INFO][2023-10-04 10:00:51,989][dance][wrapped_func] Took 0:00:26.066660 to load and process data.\n",
      "[INFO][2023-10-04 10:00:52,020][dance][set_config_from_dict] Setting config 'feature_mod' to ['mod1', 'mod2']\n",
      "[INFO][2023-10-04 10:00:52,020][dance][set_config_from_dict] Setting config 'label_mod' to 'mod1'\n",
      "[INFO][2023-10-04 10:00:52,020][dance][set_config_from_dict] Setting config 'feature_channel_type' to ['layers', 'layers']\n",
      "[INFO][2023-10-04 10:00:52,021][dance][set_config_from_dict] Setting config 'feature_channel' to ['counts', 'counts']\n",
      "[INFO][2023-10-04 10:00:52,021][dance][set_config_from_dict] Setting config 'label_channel' to 'labels'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5   4870.607091632938   5760.052151201152   134.73367309570312   3731.04443359375  kl_divergence_l:  1.09037639894252 kl_weight: 0.025 kl_divergence_z: 28.28915023803711\n",
      "10   4890.69387233602   5347.943882437796   135.32171630859375   3283.099853515625  kl_divergence_l:  0.8434103989101192 kl_weight: 0.05 kl_divergence_z: 26.715003967285156\n",
      "20   3700.3808181958057   4625.158626285617   142.5497283935547   3513.345947265625  kl_divergence_l:  0.9631066363136009 kl_weight: 0.1 kl_divergence_z: 26.495540618896484\n",
      "Finish training, total time: 198.2806613445282s epoch: 20 status:  Reached 20 epoch, training complete. \n",
      "[[ 0.16673023  0.06058602 -0.92712873 ... -1.873663    0.33918393\n",
      "   1.0599216 ]\n",
      " [ 2.2512248  -0.8462337  -2.4604926  ...  6.4582996  -0.02524094\n",
      "  -0.11451921]\n",
      " [ 0.30436543  0.5637595   0.01622492 ... -0.60097295  0.86624026\n",
      "  -1.212858  ]\n",
      " ...\n",
      " [ 0.8500484   1.0427794  -0.03551135 ...  1.9562974  -0.69208586\n",
      "  -2.3211868 ]\n",
      " [ 0.97587556  0.5382068  -0.09366035 ... -0.05597509 -0.5220829\n",
      "  -1.6086918 ]\n",
      " [ 0.48194265  0.4817421  -0.16534398 ...  1.3355657  -0.42591467\n",
      "  -0.5171643 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-04 10:04:14,136][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_SKIN_atac2gex/GSE140203_SKIN_atac2gex.GSE140203_dataset.output_mod1.h5ad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMI: 0.412, ARI: 0.260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-04 10:04:16,238][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_SKIN_atac2gex/GSE140203_SKIN_atac2gex.GSE140203_dataset.output_mod2.h5ad\n",
      "[INFO][2023-10-04 10:04:16,582][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_SKIN_atac2gex/GSE140203_SKIN_atac2gex.GSE140203_dataset.output_train_mod1.h5ad\n",
      "[INFO][2023-10-04 10:04:18,099][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_SKIN_atac2gex/GSE140203_SKIN_atac2gex.GSE140203_dataset.output_train_mod2.h5ad\n",
      "[INFO][2023-10-04 10:04:18,347][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/GSE140203_SKIN_atac2gex/GSE140203_SKIN_atac2gex.GSE140203_dataset.output_solution.h5ad\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/anndata/_core/anndata.py:1838: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "[INFO][2023-10-04 10:07:47,896][dance][_maybe_preprocess] Preprocessing done.\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/mudata/_core/mudata.py:322: UserWarning: Duplicated obs_names should not be present in different modalities due to the ambiguity that leads to.\n",
      "  warnings.warn(\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/mudata/_core/mudata.py:491: UserWarning: Cannot join columns with the same name because var_names are intersecting.\n",
      "  warnings.warn(\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/mudata/_core/mudata.py:322: UserWarning: Duplicated obs_names should not be present in different modalities due to the ambiguity that leads to.\n",
      "  warnings.warn(\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/mudata/_core/mudata.py:479: UserWarning: obs_names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  warnings.warn(\n",
      "[INFO][2023-10-04 10:07:53,167][dance][load_data] Raw data loaded:\n",
      "Data object that wraps (.data):\n",
      "MuData object with n_obs × n_vars = 35494 × 730259\n",
      "  uns:\t'dance_config'\n",
      "  5 modalities\n",
      "    mod1:\t34774 x 10000\n",
      "      var:\t'num', 'start', 'end', 'n_counts', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm'\n",
      "      uns:\t'dataset_id', 'hvg'\n",
      "      obsm:\t'X_pca'\n",
      "      layers:\t'counts'\n",
      "    mod2:\t34774 x 10000\n",
      "      var:\t'gene', 'n_counts', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm'\n",
      "      uns:\t'dataset_id', 'hvg'\n",
      "      obsm:\t'X_pca'\n",
      "      layers:\t'counts'\n",
      "    meta1:\t24341 x 344587\n",
      "      var:\t'num', 'start', 'end'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "    meta2:\t24341 x 21085\n",
      "      var:\t'gene'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "    test_sol:\t34774 x 344587\n",
      "      obs:\t'atac.bc', 'cell_type'\n",
      "      var:\t'num', 'start', 'end'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "[INFO][2023-10-04 10:07:53,169][dance][wrapped_func] Took 0:03:39.033134 to load and process data.\n",
      "[INFO][2023-10-04 10:07:53,921][dance][set_config_from_dict] Setting config 'feature_mod' to ['mod1', 'mod2']\n",
      "[INFO][2023-10-04 10:07:53,922][dance][set_config_from_dict] Setting config 'label_mod' to 'mod1'\n",
      "[INFO][2023-10-04 10:07:53,923][dance][set_config_from_dict] Setting config 'feature_channel_type' to ['layers', 'layers']\n",
      "[INFO][2023-10-04 10:07:53,924][dance][set_config_from_dict] Setting config 'feature_channel' to ['counts', 'counts']\n",
      "[INFO][2023-10-04 10:07:53,925][dance][set_config_from_dict] Setting config 'label_channel' to 'labels'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5   1863.0816018127828   6201.330424286834   207.4984130859375   1221.3515625  kl_divergence_l:  3.6345413724494584 kl_weight: 0.025 kl_divergence_z: 28.52562713623047\n",
      "10   1888.6250997608918   2379.479025048003   201.53872680664062   1193.8466796875  kl_divergence_l:  3.583497680371307 kl_weight: 0.05 kl_divergence_z: 11.419819831848145\n",
      "15   1922.2007676485446   2252.770514677865   202.55029296875   1170.1573486328125  kl_divergence_l:  3.7431742611158425 kl_weight: 0.075 kl_divergence_z: 6.449275970458984\n",
      "20   1484.5260860181595   2166.7726841994863   203.54898071289062   1148.37353515625  kl_divergence_l:  3.7746769860005873 kl_weight: 0.1 kl_divergence_z: 3.2357211112976074\n",
      "Finish training, total time: 2005.356766462326s epoch: 20 status:  Reached 20 epoch, training complete. \n",
      "[[-0.28312817  0.3167457   0.2871076  ... -0.5831218  -0.33563468\n",
      "  -1.1981037 ]\n",
      " [ 0.01919515 -0.18245426  0.16589062 ...  0.42177296 -0.21458617\n",
      "  -2.3657603 ]\n",
      " [-0.49299112  1.1364506   0.29133832 ... -0.04715678  0.14281552\n",
      "  -1.5389727 ]\n",
      " ...\n",
      " [-0.8315487   0.7182891  -0.8703231  ...  0.0233661   0.48645532\n",
      "   0.861197  ]\n",
      " [ 0.11278396 -1.1808022   0.69221246 ... -0.4423381  -0.3253584\n",
      "  -0.51711035]\n",
      " [ 0.06516983 -0.2764261  -0.25414315 ...  0.2671092   0.3892475\n",
      "  -0.33766842]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-04 10:41:47,224][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_cite_gex2adt/openproblems_2022_cite_gex2adt.open_dataset.output_mod1.h5ad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMI: 0.398, ARI: 0.285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-04 10:41:50,965][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_cite_gex2adt/openproblems_2022_cite_gex2adt.open_dataset.output_mod2.h5ad\n",
      "[INFO][2023-10-04 10:41:51,102][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_cite_gex2adt/openproblems_2022_cite_gex2adt.open_dataset.output_train_mod1.h5ad\n",
      "[INFO][2023-10-04 10:41:53,726][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_cite_gex2adt/openproblems_2022_cite_gex2adt.open_dataset.output_train_mod2.h5ad\n",
      "[INFO][2023-10-04 10:41:53,833][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_cite_gex2adt/openproblems_2022_cite_gex2adt.open_dataset.output_solution.h5ad\n",
      "/home/zyxing/dance/dance/transforms/preprocess.py:156: RuntimeWarning: divide by zero encountered in divide\n",
      "  tf = X.multiply(1 / X.sum(axis=1))\n",
      "[INFO][2023-10-04 10:46:07,772][dance][_maybe_preprocess] Preprocessing done.\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/mudata/_core/mudata.py:491: UserWarning: Cannot join columns with the same name because var_names are intersecting.\n",
      "  warnings.warn(\n",
      "[INFO][2023-10-04 10:46:07,922][dance][load_data] Raw data loaded:\n",
      "Data object that wraps (.data):\n",
      "MuData object with n_obs × n_vars = 70988 × 53482\n",
      "  uns:\t'dance_config'\n",
      "  5 modalities\n",
      "    mod1:\t70988 x 10000\n",
      "      obs:\t'batch', 'cell_type'\n",
      "      var:\t'feature_types', 'n_counts', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm'\n",
      "      uns:\t'dataset_id', 'hvg'\n",
      "      obsm:\t'X_pca'\n",
      "      layers:\t'counts'\n",
      "    mod2:\t70988 x 140\n",
      "      obs:\t'batch'\n",
      "      var:\t'feature_types', 'n_counts'\n",
      "      uns:\t'dataset_id'\n",
      "      obsm:\t'X_pca'\n",
      "      layers:\t'counts'\n",
      "    meta1:\t49691 x 21601\n",
      "      obs:\t'batch'\n",
      "      var:\t'feature_types'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "    meta2:\t49691 x 140\n",
      "      obs:\t'batch'\n",
      "      var:\t'feature_types'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "    test_sol:\t70988 x 21601\n",
      "      obs:\t'batch', 'cell_type'\n",
      "      var:\t'feature_types'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "[INFO][2023-10-04 10:46:07,923][dance][wrapped_func] Took 0:04:20.699244 to load and process data.\n",
      "[INFO][2023-10-04 10:46:11,960][dance][set_config_from_dict] Setting config 'feature_mod' to ['mod1', 'mod2']\n",
      "[INFO][2023-10-04 10:46:11,963][dance][set_config_from_dict] Setting config 'label_mod' to 'mod1'\n",
      "[INFO][2023-10-04 10:46:11,964][dance][set_config_from_dict] Setting config 'feature_channel_type' to ['layers', 'layers']\n",
      "[INFO][2023-10-04 10:46:11,965][dance][set_config_from_dict] Setting config 'feature_channel' to ['counts', 'counts']\n",
      "[INFO][2023-10-04 10:46:11,966][dance][set_config_from_dict] Setting config 'label_channel' to 'labels'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5   17985.007032570193   16382.881477100365   3793.132080078125   853.6953735351562  kl_divergence_l:  8.454174704874704 kl_weight: 0.025 kl_divergence_z: 48.263954162597656\n",
      "10   16206.075509077205   16262.422772492015   3764.930908203125   855.4279174804688  kl_divergence_l:  8.544236952374451 kl_weight: 0.05 kl_divergence_z: 37.27095031738281\n",
      "15   16635.13916145159   15459.252839351577   3563.09716796875   859.9569702148438  kl_divergence_l:  7.861500253318012 kl_weight: 0.075 kl_divergence_z: 51.291568756103516\n",
      "20   15799.468724735767   15202.643965870297   3500.545166015625   860.4047241210938  kl_divergence_l:  7.981056714463123 kl_weight: 0.1 kl_divergence_z: 21.73849105834961\n",
      "Finish training, total time: 2135.826046228409s epoch: 20 status:  Reached 20 epoch, training complete. \n",
      "[[-1.9540087  -0.6546646  -0.05632153 ... -1.9980044  -1.6573197\n",
      "   0.9333149 ]\n",
      " [-1.6789708  -1.0913044  -0.42879108 ... -2.2321908  -0.51619124\n",
      "   0.05385058]\n",
      " [ 0.50575674 -0.24153113 -1.529554   ... -0.593841    0.4328539\n",
      "  -0.14769718]\n",
      " ...\n",
      " [ 1.7000161   0.3225338  -4.746063   ...  1.8052943   2.4770768\n",
      "   0.56161636]\n",
      " [ 0.03994095  3.061713    0.6179808  ...  1.3026311  -0.7992925\n",
      "   2.7653837 ]\n",
      " [ 0.9533582   2.4820924  -1.884349   ...  1.638442    2.027956\n",
      "  -0.35943907]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-04 11:22:16,198][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_multi_atac2gex/openproblems_2022_multi_atac2gex.open_dataset.output_mod1.h5ad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMI: 0.375, ARI: 0.274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-04 11:22:21,845][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_multi_atac2gex/openproblems_2022_multi_atac2gex.open_dataset.output_mod2.h5ad\n",
      "[INFO][2023-10-04 11:22:25,197][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_multi_atac2gex/openproblems_2022_multi_atac2gex.open_dataset.output_train_mod1.h5ad\n",
      "[INFO][2023-10-04 11:22:28,707][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_multi_atac2gex/openproblems_2022_multi_atac2gex.open_dataset.output_train_mod2.h5ad\n",
      "[INFO][2023-10-04 11:22:31,093][dance][_load_raw_data] Loading /home/zyxing/data/joint_embedding/openproblems_2022_multi_atac2gex/openproblems_2022_multi_atac2gex.open_dataset.output_solution.h5ad\n",
      "[INFO][2023-10-04 11:42:59,779][dance][_maybe_preprocess] Preprocessing done.\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/mudata/_core/mudata.py:491: UserWarning: Cannot join columns with the same name because var_names are intersecting.\n",
      "  warnings.warn(\n",
      "[INFO][2023-10-04 11:43:00,267][dance][load_data] Raw data loaded:\n",
      "Data object that wraps (.data):\n",
      "MuData object with n_obs × n_vars = 105868 × 500740\n",
      "  uns:\t'dance_config'\n",
      "  5 modalities\n",
      "    mod1:\t105868 x 10000\n",
      "      obs:\t'batch', 'cell_type'\n",
      "      var:\t'feature_types', 'n_counts', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm'\n",
      "      uns:\t'dataset_id', 'hvg'\n",
      "      obsm:\t'X_pca'\n",
      "      layers:\t'counts'\n",
      "    mod2:\t105868 x 10000\n",
      "      obs:\t'batch'\n",
      "      var:\t'feature_types', 'n_counts', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm'\n",
      "      uns:\t'dataset_id', 'hvg'\n",
      "      obsm:\t'X_pca'\n",
      "      layers:\t'counts'\n",
      "    meta1:\t74107 x 228941\n",
      "      obs:\t'batch'\n",
      "      var:\t'feature_types'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "    meta2:\t74107 x 22858\n",
      "      obs:\t'batch'\n",
      "      var:\t'feature_types'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "    test_sol:\t105868 x 228941\n",
      "      obs:\t'batch', 'cell_type'\n",
      "      var:\t'feature_types'\n",
      "      uns:\t'dataset_id'\n",
      "      layers:\t'counts'\n",
      "[INFO][2023-10-04 11:43:00,268][dance][wrapped_func] Took 0:20:44.070114 to load and process data.\n",
      "[INFO][2023-10-04 11:43:03,227][dance][set_config_from_dict] Setting config 'feature_mod' to ['mod1', 'mod2']\n",
      "[INFO][2023-10-04 11:43:03,229][dance][set_config_from_dict] Setting config 'label_mod' to 'mod1'\n",
      "[INFO][2023-10-04 11:43:03,230][dance][set_config_from_dict] Setting config 'feature_channel_type' to ['layers', 'layers']\n",
      "[INFO][2023-10-04 11:43:03,231][dance][set_config_from_dict] Setting config 'feature_channel' to ['counts', 'counts']\n",
      "[INFO][2023-10-04 11:43:03,232][dance][set_config_from_dict] Setting config 'label_channel' to 'labels'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5   13839.542842427742   13859.240867715967   1098.2010498046875   8836.97265625  kl_divergence_l:  6.5338216131399145 kl_weight: 0.025 kl_divergence_z: 31.927928924560547\n",
      "10   13178.796699621582   13749.321095138544   1076.4365234375   8864.8779296875  kl_divergence_l:  8.18936132681222 kl_weight: 0.05 kl_divergence_z: 11.160152435302734\n",
      "15   13598.348587159035   13712.04085653718   1070.6529541015625   8813.5673828125  kl_divergence_l:  9.21884509199748 kl_weight: 0.075 kl_divergence_z: 5.951897621154785\n",
      "20   12752.13133829034   13693.182149188237   1066.2730712890625   8823.2724609375  kl_divergence_l:  10.258705066704177 kl_weight: 0.1 kl_divergence_z: 3.848344326019287\n",
      "Finish training, total time: 4140.331627130508s epoch: 20 status:  Reached 20 epoch, training complete. \n",
      "[[ 0.12440279  0.98521894 -0.17474233 ...  0.6150322  -1.0702327\n",
      "   0.24965405]\n",
      " [ 1.4394023  -0.11239281 -1.7417555  ... -0.41631913  1.5900434\n",
      "  -0.6065301 ]\n",
      " [ 0.64373845  1.4043484   0.5709433  ... -0.4568111   0.19301742\n",
      "  -0.40872967]\n",
      " ...\n",
      " [-0.43403068  1.5936542  -0.03290243 ... -0.854367   -1.7201495\n",
      "  -1.4455918 ]\n",
      " [ 0.9985305   0.14139938 -0.18850349 ...  0.17244938 -1.3034205\n",
      "   0.2579293 ]\n",
      " [ 0.53767526  0.17178728 -1.6893276  ...  0.09815516 -1.4470283\n",
      "  -0.90870357]]\n",
      "NMI: 0.406, ARI: 0.348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'To reproduce scMVAE on other samples, please refer to command lines belows:\\n\\nGEX-ADT:\\npython scmvae.py --subtask openproblems_bmmc_cite_phase2 --device cuda\\n\\nGEX-ATAC:\\npython scmvae.py --subtask openproblems_bmmc_multiome_phase2 --device cuda\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scMVAE_scores=[]\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "from sklearn import preprocessing\n",
    "import scanpy as sc\n",
    "from dance.datasets.multimodality import JointEmbeddingNIPSDataset\n",
    "from dance.modules.multi_modality.joint_embedding.scmvae import scMVAE\n",
    "from dance.transforms.preprocess import calculate_log_library_size\n",
    "\n",
    "\n",
    "def parameter_setting():\n",
    "    parser = argparse.ArgumentParser(description=\"Single cell Multi-omics data analysis\")\n",
    "\n",
    "    parser.add_argument(\"--workdir\", \"-wk\", type=str, default=\"./new_test\", help=\"work path\")\n",
    "    parser.add_argument(\"--outdir\", \"-od\", type=str, default=\"./new_test\", help=\"Output path\")\n",
    "\n",
    "    parser.add_argument(\"--lr\", type=float, default=1E-3, help=\"Learning rate\")\n",
    "    parser.add_argument(\"--weight_decay\", type=float, default=1e-6, help=\"weight decay\")\n",
    "    parser.add_argument(\"--eps\", type=float, default=0.01, help=\"eps\")\n",
    "\n",
    "    parser.add_argument(\"--batch_size\", \"-b\", type=int, default=64, help=\"Batch size\")\n",
    "    parser.add_argument(\"--seed\", type=int, default=200, help=\"Random seed for repeat results\")\n",
    "    parser.add_argument(\"--latent\", \"-l\", type=int, default=10, help=\"latent layer dim\")\n",
    "    parser.add_argument(\"--max_epoch\", \"-me\", type=int, default=20, help=\"Max epoches\")\n",
    "    parser.add_argument(\"--max_iteration\", \"-mi\", type=int, default=2000, help=\"Max iteration\")\n",
    "    parser.add_argument(\"--anneal_epoch\", \"-ae\", type=int, default=200, help=\"Anneal epoch\")\n",
    "    parser.add_argument(\"--epoch_per_test\", \"-ept\", type=int, default=5,\n",
    "                        help=\"Epoch per test, must smaller than max iteration.\")\n",
    "    parser.add_argument(\"--max_ARI\", \"-ma\", type=int, default=-200, help=\"initial ARI\")\n",
    "    parser.add_argument(\"-t\", \"--subtask\", default=\"openproblems_bmmc_cite_phase2\")\n",
    "    parser.add_argument(\"-device\", \"--device\", default=\"cuda\")\n",
    "    parser.add_argument(\"--final_rate\", type=float, default=1e-4)\n",
    "    parser.add_argument(\"--scale_factor\", type=float, default=4)\n",
    "    parser.add_argument(\"--span\", default=0.3, type=float)\n",
    "    return parser\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "    parser = parameter_setting()\n",
    "    args = parser.parse_args(['--subtask',dataset,'--device','cpu','--span','1.0'])\n",
    "    assert args.max_iteration > args.epoch_per_test\n",
    "\n",
    "    dataset = JointEmbeddingNIPSDataset(args.subtask, root=\"../../../../data/joint_embedding\", preprocess=\"feature_selection\",span=args.span)\n",
    "    data = dataset.load_data()\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    labels = le.fit_transform(data.mod[\"test_sol\"].obs[\"cell_type\"])\n",
    "    \n",
    "    data.mod[\"mod1\"].obsm[\"labels\"] = labels\n",
    "    data.set_config(feature_mod=[\"mod1\", \"mod2\"], label_mod=\"mod1\", feature_channel_type=[\"layers\", \"layers\"],\n",
    "                    feature_channel=[\"counts\", \"counts\"], label_channel=\"labels\")\n",
    "    # sc.pp.log1p(data.mod[\"mod2\"])\n",
    "    # sc.pp.log1p(data.mod[\"mod1\"])\n",
    "   \n",
    "\n",
    "    (x_train, y_train), _ = data.get_train_data(return_type=\"torch\")\n",
    "    (x_test, y_test), labels = data.get_test_data(return_type=\"torch\")\n",
    "\n",
    "    lib_mean1, lib_var1 = calculate_log_library_size(np.concatenate([x_train.numpy(), x_test.numpy()]))\n",
    "    lib_mean2, lib_var2 = calculate_log_library_size(np.concatenate([y_train.numpy(), y_test.numpy()]))\n",
    "    lib_mean1 = torch.from_numpy(lib_mean1)\n",
    "    lib_var1 = torch.from_numpy(lib_var1)\n",
    "    lib_mean2 = torch.from_numpy(lib_mean2)\n",
    "    lib_var2 = torch.from_numpy(lib_var2)\n",
    "\n",
    "    Nfeature1 = x_train.shape[1]\n",
    "    Nfeature2 = y_train.shape[1]\n",
    "\n",
    "    device = torch.device(args.device)\n",
    "\n",
    "    model = scMVAE(\n",
    "        encoder_1=[Nfeature1, 1024, 128, 128],\n",
    "        hidden_1=128,\n",
    "        Z_DIMS=22,\n",
    "        decoder_share=[22, 128, 256],\n",
    "        share_hidden=128,\n",
    "        decoder_1=[128, 128, 1024],\n",
    "        hidden_2=1024,\n",
    "        encoder_l=[Nfeature1, 128],\n",
    "        hidden3=128,\n",
    "        encoder_2=[Nfeature2, 1024, 128, 128],\n",
    "        hidden_4=128,\n",
    "        encoder_l1=[Nfeature2, 128],\n",
    "        hidden3_1=128,\n",
    "        decoder_2=[128, 128, 1024],\n",
    "        hidden_5=1024,\n",
    "        drop_rate=0.1,\n",
    "        log_variational=True,\n",
    "        Type=\"ZINB\",\n",
    "        device=device,\n",
    "        n_centroids=22,\n",
    "        penality=\"GMM\",\n",
    "        model=1,\n",
    "    )\n",
    "\n",
    "    args.lr = 0.001\n",
    "    args.anneal_epoch = 200\n",
    "\n",
    "    model.to(device)\n",
    "    train_size = len(data.get_split_idx(\"train\"))\n",
    "    train = data_utils.TensorDataset(x_train, lib_mean1[:train_size], lib_var1[:train_size], lib_mean2[:train_size],\n",
    "                                     lib_var2[:train_size], y_train)\n",
    "\n",
    "    valid = data_utils.TensorDataset(x_test, lib_mean1[train_size:], lib_var1[train_size:], lib_mean2[train_size:],\n",
    "                                     lib_var2[train_size:], y_test)\n",
    "\n",
    "    total = data_utils.TensorDataset(torch.cat([x_train, x_test]), torch.cat([y_train, y_test]))\n",
    "\n",
    "    total_loader = data_utils.DataLoader(total, batch_size=args.batch_size, shuffle=False)\n",
    "    model.init_gmm_params(total_loader)\n",
    "    model.fit(args, train, valid, args.final_rate, args.scale_factor, device)\n",
    "\n",
    "    embeds = model.predict(torch.cat([x_train, x_test]), torch.cat([y_train, y_test])).cpu().numpy()\n",
    "    print(embeds)\n",
    "\n",
    "    nmi_score, ari_score = model.score(x_test, y_test, labels)\n",
    "    print(f\"NMI: {nmi_score:.3f}, ARI: {ari_score:.3f}\")\n",
    "    scMVAE_scores.append({\"nmi_score\":nmi_score,\"ari_score\":ari_score})\n",
    "\"\"\"To reproduce scMVAE on other samples, please refer to command lines belows:\n",
    "\n",
    "GEX-ADT:\n",
    "python scmvae.py --subtask openproblems_bmmc_cite_phase2 --device cuda\n",
    "\n",
    "GEX-ATAC:\n",
    "python scmvae.py --subtask openproblems_bmmc_multiome_phase2 --device cuda\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'nmi_score': 0.412, 'ari_score': 0.26},\n",
       " {'nmi_score': 0.398, 'ari_score': 0.285},\n",
       " {'nmi_score': 0.375, 'ari_score': 0.274},\n",
       " {'nmi_score': 0.406, 'ari_score': 0.348}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scMVAE_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
