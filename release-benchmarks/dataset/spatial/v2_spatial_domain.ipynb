{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets=[\"b004\",\"be_ton\",\"mpb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-25 23:52:38,401][dance][_load_raw_data] Loading expression data from /home/zyxing/data/spatial/b004/b004_raw_feature_bc_matrix.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-25 23:52:38,664][dance][_load_raw_data] Loading spatial info from /home/zyxing/data/spatial/b004/tissue_positions_list.txt\n",
      "[INFO][2023-10-25 23:52:38,940][dance][_load_raw_data] Loading label info from /home/zyxing/data/spatial/b004/cluster_labels.csv\n",
      "[INFO][2023-10-25 23:52:39,185][dance][_load_raw_data] Loading image data from /home/zyxing/data/spatial/b004/b004_full_image.tif\n",
      "[INFO][2023-10-25 23:52:39,186][dance][_load_raw_data] image doesn't exist,use louvain\n",
      "[ WARN:0@4703.187] global loadsave.cpp:248 findDecoder imread_('/home/zyxing/data/spatial/b004/b004_full_image.tif'): can't open/read file: check file path/integrity\n",
      "[INFO][2023-10-25 23:52:39,188][dance][_load_raw_data] image doesn't exist,use louvain\n",
      "[INFO][2023-10-25 23:52:39,278][dance][load_data] Raw data loaded:\n",
      "Data object that wraps (.data):\n",
      "AnnData object with n_obs × n_vars = 248285 × 48\n",
      "    obs: 'Unnamed: 0', 'ground_truth', 'label'\n",
      "    uns: 'image', 'dance_config'\n",
      "    obsm: 'spatial', 'spatial_pixel'\n",
      "[INFO][2023-10-25 23:52:39,279][dance.Compose][__call__] Applying composed transformations:\n",
      "Compose(\n",
      "  FilterGenesMatch(prefixes=['ERCC', 'MT-'], suffixes=[]),\n",
      "  AnnDataTransform(func=scanpy.preprocessing._normalization.normalize_total, func_kwargs={'target_sum': 10000.0}),\n",
      "  AnnDataTransform(func=scanpy.preprocessing._simple.scale, func_kwargs={}),\n",
      "  CellPCA(n_components=30),\n",
      "  NeighborGraph(n_neighbors=17, n_pcs=None, knn=True, random_state=0, method='umap', metric='euclidean'),\n",
      "  SetConfig(config_dict={'feature_channel': 'NeighborGraph', 'feature_channel_type': 'obsp', 'label_channel': 'label', 'label_channel_type': 'obs'}),\n",
      ")\n",
      "[INFO][2023-10-25 23:52:39,280][dance.FilterGenesMatch][__call__] 0 number of genes will be removed due to prefix 'ERCC'\n",
      "[INFO][2023-10-25 23:52:39,281][dance.FilterGenesMatch][__call__] 0 number of genes will be removed due to prefix 'MT-'\n",
      "[INFO][2023-10-25 23:52:39,282][dance.FilterGenesMatch][__call__] Removing 0 genes in total\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:197: UserWarning: Some cells have zero counts\n",
      "  warn(UserWarning('Some cells have zero counts'))\n",
      "[INFO][2023-10-25 23:52:39,587][dance.CellPCA][__call__] Start generating cell PCA features (248285, 48) (k=30)\n",
      "[INFO][2023-10-25 23:52:40,444][dance.CellPCA][__call__] Top 10 explained variances: [0.50023502 0.15695003 0.06351391 0.04687454 0.02886694 0.02661571\n",
      " 0.02331984 0.01991766 0.01965098 0.01724397]\n",
      "[INFO][2023-10-25 23:52:40,445][dance.CellPCA][__call__] Total explained variance: 99.49%\n",
      "[INFO][2023-10-25 23:52:40,445][dance.NeighborGraph][__call__] Start computing the kNN connectivity adjacency matrix\n",
      "[INFO][2023-10-25 23:53:13,192][dance.SetConfig][__call__] Updating the dance data object config options:\n",
      "{'feature_channel': 'NeighborGraph',\n",
      " 'feature_channel_type': 'obsp',\n",
      " 'label_channel': 'label',\n",
      " 'label_channel_type': 'obs'}\n",
      "[INFO][2023-10-25 23:53:13,193][dance][set_config_from_dict] Setting config 'feature_channel' to 'NeighborGraph'\n",
      "[INFO][2023-10-25 23:53:13,194][dance][set_config_from_dict] Setting config 'feature_channel_type' to 'obsp'\n",
      "[INFO][2023-10-25 23:53:13,194][dance][set_config_from_dict] Setting config 'label_channel' to 'label'\n",
      "[INFO][2023-10-25 23:53:13,195][dance][set_config_from_dict] Setting config 'label_channel_type' to 'obs'\n",
      "[INFO][2023-10-25 23:53:13,195][dance][load_data] Data transformed:\n",
      "Data object that wraps (.data):\n",
      "AnnData object with n_obs × n_vars = 248285 × 48\n",
      "    obs: 'Unnamed: 0', 'ground_truth', 'label'\n",
      "    var: 'mean', 'std'\n",
      "    uns: 'image', 'dance_config'\n",
      "    obsm: 'spatial', 'spatial_pixel', 'CellPCA'\n",
      "    obsp: 'NeighborGraph'\n",
      "[INFO][2023-10-25 23:53:13,208][dance][wrapped_func] Took 0:00:34.806845 to load and process data.\n",
      "[INFO][2023-10-25 23:53:13,212][dance][fit] Converting adjacency matrix to networkx graph...\n",
      "[INFO][2023-10-25 23:54:50,334][dance][fit] Conversion done. Start fitting...\n",
      "[INFO][2023-10-26 00:15:19,025][dance][fit] Fitting done.\n",
      "[INFO][2023-10-26 00:15:19,134][dance][_load_raw_data] Loading expression data from /home/zyxing/data/spatial/be_ton/be_ton_raw_feature_bc_matrix.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25355328180154496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-26 00:15:19,341][dance][_load_raw_data] Loading spatial info from /home/zyxing/data/spatial/be_ton/tissue_positions_list.txt\n",
      "[INFO][2023-10-26 00:15:19,521][dance][_load_raw_data] Loading label info from /home/zyxing/data/spatial/be_ton/cluster_labels.csv\n",
      "[INFO][2023-10-26 00:15:19,650][dance][_load_raw_data] Loading image data from /home/zyxing/data/spatial/be_ton/be_ton_full_image.tif\n",
      "[INFO][2023-10-26 00:15:19,652][dance][_load_raw_data] image doesn't exist,use louvain\n",
      "[INFO][2023-10-26 00:15:19,652][dance][_load_raw_data] image doesn't exist,use louvain\n",
      "[ WARN:0@6063.652] global loadsave.cpp:248 findDecoder imread_('/home/zyxing/data/spatial/be_ton/be_ton_full_image.tif'): can't open/read file: check file path/integrity\n",
      "[INFO][2023-10-26 00:15:19,747][dance][load_data] Raw data loaded:\n",
      "Data object that wraps (.data):\n",
      "AnnData object with n_obs × n_vars = 219926 × 44\n",
      "    obs: 'Unnamed: 0', 'ground_truth', 'label'\n",
      "    uns: 'image', 'dance_config'\n",
      "    obsm: 'spatial', 'spatial_pixel'\n",
      "[INFO][2023-10-26 00:15:19,747][dance.Compose][__call__] Applying composed transformations:\n",
      "Compose(\n",
      "  FilterGenesMatch(prefixes=['ERCC', 'MT-'], suffixes=[]),\n",
      "  AnnDataTransform(func=scanpy.preprocessing._normalization.normalize_total, func_kwargs={'target_sum': 10000.0}),\n",
      "  AnnDataTransform(func=scanpy.preprocessing._simple.scale, func_kwargs={}),\n",
      "  CellPCA(n_components=30),\n",
      "  NeighborGraph(n_neighbors=17, n_pcs=None, knn=True, random_state=0, method='umap', metric='euclidean'),\n",
      "  SetConfig(config_dict={'feature_channel': 'NeighborGraph', 'feature_channel_type': 'obsp', 'label_channel': 'label', 'label_channel_type': 'obs'}),\n",
      ")\n",
      "[INFO][2023-10-26 00:15:19,749][dance.FilterGenesMatch][__call__] 0 number of genes will be removed due to prefix 'ERCC'\n",
      "[INFO][2023-10-26 00:15:19,749][dance.FilterGenesMatch][__call__] 0 number of genes will be removed due to prefix 'MT-'\n",
      "[INFO][2023-10-26 00:15:19,750][dance.FilterGenesMatch][__call__] Removing 0 genes in total\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:197: UserWarning: Some cells have zero counts\n",
      "  warn(UserWarning('Some cells have zero counts'))\n",
      "[INFO][2023-10-26 00:15:19,954][dance.CellPCA][__call__] Start generating cell PCA features (219926, 44) (k=30)\n",
      "[INFO][2023-10-26 00:15:20,678][dance.CellPCA][__call__] Top 10 explained variances: [0.88907774 0.05306769 0.01536183 0.01025824 0.00925459 0.00735599\n",
      " 0.00385986 0.00265834 0.00188913 0.00136186]\n",
      "[INFO][2023-10-26 00:15:20,679][dance.CellPCA][__call__] Total explained variance: 99.98%\n",
      "[INFO][2023-10-26 00:15:20,679][dance.NeighborGraph][__call__] Start computing the kNN connectivity adjacency matrix\n",
      "[INFO][2023-10-26 00:15:54,508][dance.SetConfig][__call__] Updating the dance data object config options:\n",
      "{'feature_channel': 'NeighborGraph',\n",
      " 'feature_channel_type': 'obsp',\n",
      " 'label_channel': 'label',\n",
      " 'label_channel_type': 'obs'}\n",
      "[INFO][2023-10-26 00:15:54,510][dance][set_config_from_dict] Setting config 'feature_channel' to 'NeighborGraph'\n",
      "[INFO][2023-10-26 00:15:54,511][dance][set_config_from_dict] Setting config 'feature_channel_type' to 'obsp'\n",
      "[INFO][2023-10-26 00:15:54,511][dance][set_config_from_dict] Setting config 'label_channel' to 'label'\n",
      "[INFO][2023-10-26 00:15:54,512][dance][set_config_from_dict] Setting config 'label_channel_type' to 'obs'\n",
      "[INFO][2023-10-26 00:15:54,512][dance][load_data] Data transformed:\n",
      "Data object that wraps (.data):\n",
      "AnnData object with n_obs × n_vars = 219926 × 44\n",
      "    obs: 'Unnamed: 0', 'ground_truth', 'label'\n",
      "    var: 'mean', 'std'\n",
      "    uns: 'image', 'dance_config'\n",
      "    obsm: 'spatial', 'spatial_pixel', 'CellPCA'\n",
      "    obsp: 'NeighborGraph'\n",
      "[INFO][2023-10-26 00:15:54,518][dance][wrapped_func] Took 0:00:35.385055 to load and process data.\n",
      "[INFO][2023-10-26 00:15:54,528][dance][fit] Converting adjacency matrix to networkx graph...\n",
      "[INFO][2023-10-26 00:17:27,073][dance][fit] Conversion done. Start fitting...\n",
      "[INFO][2023-10-26 00:29:59,277][dance][fit] Fitting done.\n",
      "[INFO][2023-10-26 00:29:59,384][dance][_load_raw_data] Loading expression data from /home/zyxing/data/spatial/mpb/mpb_raw_feature_bc_matrix.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12017291301674463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/anndata/_core/anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/anndata/_core/anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "[INFO][2023-10-26 00:30:00,367][dance][_load_raw_data] Loading spatial info from /home/zyxing/data/spatial/mpb/tissue_positions_list.txt\n",
      "[INFO][2023-10-26 00:30:00,379][dance][_load_raw_data] Loading label info from /home/zyxing/data/spatial/mpb/cluster_labels.csv\n",
      "[INFO][2023-10-26 00:30:00,386][dance][_load_raw_data] Loading image data from /home/zyxing/data/spatial/mpb/mpb_full_image.tif\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/anndata/_core/anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/anndata/_core/anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "[INFO][2023-10-26 00:30:00,506][dance][load_data] Raw data loaded:\n",
      "Data object that wraps (.data):\n",
      "AnnData object with n_obs × n_vars = 3353 × 31053\n",
      "    obs: 'Barcode', 'ground_truth', 'label'\n",
      "    var: 'gene_ids', 'feature_types', 'genome'\n",
      "    uns: 'image', 'dance_config'\n",
      "    obsm: 'spatial', 'spatial_pixel'\n",
      "[INFO][2023-10-26 00:30:00,507][dance.Compose][__call__] Applying composed transformations:\n",
      "Compose(\n",
      "  FilterGenesMatch(prefixes=['ERCC', 'MT-'], suffixes=[]),\n",
      "  AnnDataTransform(func=scanpy.preprocessing._normalization.normalize_total, func_kwargs={'target_sum': 10000.0}),\n",
      "  AnnDataTransform(func=scanpy.preprocessing._simple.scale, func_kwargs={}),\n",
      "  CellPCA(n_components=30),\n",
      "  NeighborGraph(n_neighbors=17, n_pcs=None, knn=True, random_state=0, method='umap', metric='euclidean'),\n",
      "  SetConfig(config_dict={'feature_channel': 'NeighborGraph', 'feature_channel_type': 'obsp', 'label_channel': 'label', 'label_channel_type': 'obs'}),\n",
      ")\n",
      "[INFO][2023-10-26 00:30:00,515][dance.FilterGenesMatch][__call__] 0 number of genes will be removed due to prefix 'ERCC'\n",
      "[INFO][2023-10-26 00:30:00,522][dance.FilterGenesMatch][__call__] 0 number of genes will be removed due to prefix 'MT-'\n",
      "[INFO][2023-10-26 00:30:00,523][dance.FilterGenesMatch][__call__] Removing 0 genes in total\n",
      "[INFO][2023-10-26 00:30:01,379][dance.CellPCA][__call__] Start generating cell PCA features (3353, 31053) (k=30)\n",
      "[INFO][2023-10-26 00:30:01,977][dance.CellPCA][__call__] Top 10 explained variances: [0.01772355 0.01214631 0.00534425 0.00487532 0.00377347 0.00313796\n",
      " 0.00251409 0.0024624  0.00239022 0.00237109]\n",
      "[INFO][2023-10-26 00:30:01,978][dance.CellPCA][__call__] Total explained variance: 9.58%\n",
      "[INFO][2023-10-26 00:30:01,979][dance.NeighborGraph][__call__] Start computing the kNN connectivity adjacency matrix\n",
      "[INFO][2023-10-26 00:30:02,353][dance.SetConfig][__call__] Updating the dance data object config options:\n",
      "{'feature_channel': 'NeighborGraph',\n",
      " 'feature_channel_type': 'obsp',\n",
      " 'label_channel': 'label',\n",
      " 'label_channel_type': 'obs'}\n",
      "[INFO][2023-10-26 00:30:02,354][dance][set_config_from_dict] Setting config 'feature_channel' to 'NeighborGraph'\n",
      "[INFO][2023-10-26 00:30:02,355][dance][set_config_from_dict] Setting config 'feature_channel_type' to 'obsp'\n",
      "[INFO][2023-10-26 00:30:02,356][dance][set_config_from_dict] Setting config 'label_channel' to 'label'\n",
      "[INFO][2023-10-26 00:30:02,356][dance][set_config_from_dict] Setting config 'label_channel_type' to 'obs'\n",
      "[INFO][2023-10-26 00:30:02,357][dance][load_data] Data transformed:\n",
      "Data object that wraps (.data):\n",
      "AnnData object with n_obs × n_vars = 3353 × 31053\n",
      "    obs: 'Barcode', 'ground_truth', 'label'\n",
      "    var: 'gene_ids', 'feature_types', 'genome', 'mean', 'std'\n",
      "    uns: 'image', 'dance_config'\n",
      "    obsm: 'spatial', 'spatial_pixel', 'CellPCA'\n",
      "    obsp: 'NeighborGraph'\n",
      "[INFO][2023-10-26 00:30:02,358][dance][wrapped_func] Took 0:00:02.974298 to load and process data.\n",
      "[INFO][2023-10-26 00:30:02,363][dance][fit] Converting adjacency matrix to networkx graph...\n",
      "[INFO][2023-10-26 00:30:03,529][dance][fit] Conversion done. Start fitting...\n",
      "[INFO][2023-10-26 00:30:04,392][dance][fit] Fitting done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48856056584053464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' To reproduce louvain on other samples, please refer to command lines belows:\\nNOTE: you have to run multiple times to get best performance.\\n\\nhuman dorsolateral prefrontal cortex sample 151673:\\npython louvain.py --sample_number=151673 --seed=5\\n# 0.305\\n\\nhuman dorsolateral prefrontal cortex sample 151676:\\npython louvain.py --sample_number=151676 --seed=203\\n# 0.288\\n\\nhuman dorsolateral prefrontal cortex sample 151507:\\npython louvain.py --sample_number=151507 --seed=10\\n# 0.285\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "from dance.datasets.spatial import SpatialLIBDDataset\n",
    "from dance.modules.spatial.spatial_domain.louvain import Louvain\n",
    "from dance.transforms.preprocess import set_seed\n",
    "\n",
    "Louvain_scores=[]\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--cache\", action=\"store_true\", help=\"Cache processed data.\")\n",
    "parser.add_argument(\"--sample_number\", type=str, default=\"151673\",\n",
    "                    help=\"12 human dorsolateral prefrontal cortex datasets for the spatial domain task.\")\n",
    "parser.add_argument(\"--seed\", type=int, default=202, help=\"Random seed.\")\n",
    "parser.add_argument(\"--n_components\", type=int, default=50, help=\"Number of PC components.\")\n",
    "parser.add_argument(\"--neighbors\", type=int, default=17, help=\"Number of neighbors.\")\n",
    "for dataset in datasets:\n",
    "    try:\n",
    "        args = parser.parse_args(['--sample_number',dataset, '--seed','5',\"--n_components\",\"30\"])\n",
    "        set_seed(args.seed)\n",
    "\n",
    "        # Initialize model and get model specific preprocessing pipeline\n",
    "        model = Louvain(resolution=1)\n",
    "        preprocessing_pipeline = model.preprocessing_pipeline(dim=args.n_components, n_neighbors=args.neighbors)\n",
    "\n",
    "        # Load data and perform necessary preprocessing\n",
    "        dataloader = SpatialLIBDDataset(data_id=args.sample_number,data_dir=\"/home/zyxing/data/spatial\")\n",
    "        data = dataloader.load_data(transform=preprocessing_pipeline, cache=args.cache)\n",
    "        adj, y = data.get_data(return_type=\"default\")\n",
    "\n",
    "        # Train and evaluate model\n",
    "        model = Louvain(resolution=1)\n",
    "        score = model.fit_score(adj, y.values.ravel())\n",
    "    except Exception as e:\n",
    "        score=e\n",
    "    finally:\n",
    "        print(score)\n",
    "        Louvain_scores.append(score)\n",
    "\"\"\" To reproduce louvain on other samples, please refer to command lines belows:\n",
    "NOTE: you have to run multiple times to get best performance.\n",
    "\n",
    "human dorsolateral prefrontal cortex sample 151673:\n",
    "python louvain.py --sample_number=151673 --seed=5\n",
    "# 0.305\n",
    "\n",
    "human dorsolateral prefrontal cortex sample 151676:\n",
    "python louvain.py --sample_number=151676 --seed=203\n",
    "# 0.288\n",
    "\n",
    "human dorsolateral prefrontal cortex sample 151507:\n",
    "python louvain.py --sample_number=151507 --seed=10\n",
    "# 0.285\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.25355328180154496, 0.12017291301674463, 0.48856056584053464]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Louvain_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-26 00:30:04,440][dance][set_seed] Setting global random seed to 100\n",
      "[INFO][2023-10-26 00:30:04,441][dance][_load_raw_data] Loading expression data from /home/zyxing/data/spatial/mpb/mpb_raw_feature_bc_matrix.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/anndata/_core/anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/anndata/_core/anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "[INFO][2023-10-26 00:30:05,421][dance][_load_raw_data] Loading spatial info from /home/zyxing/data/spatial/mpb/tissue_positions_list.txt\n",
      "[INFO][2023-10-26 00:30:05,432][dance][_load_raw_data] Loading label info from /home/zyxing/data/spatial/mpb/cluster_labels.csv\n",
      "[INFO][2023-10-26 00:30:05,439][dance][_load_raw_data] Loading image data from /home/zyxing/data/spatial/mpb/mpb_full_image.tif\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/anndata/_core/anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/anndata/_core/anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "[INFO][2023-10-26 00:30:05,566][dance][load_data] Raw data loaded:\n",
      "Data object that wraps (.data):\n",
      "AnnData object with n_obs × n_vars = 3353 × 31053\n",
      "    obs: 'Barcode', 'ground_truth', 'label'\n",
      "    var: 'gene_ids', 'feature_types', 'genome'\n",
      "    uns: 'image', 'dance_config'\n",
      "    obsm: 'spatial', 'spatial_pixel'\n",
      "[INFO][2023-10-26 00:30:05,567][dance.Compose][__call__] Applying composed transformations:\n",
      "Compose(\n",
      "  FilterGenesMatch(prefixes=['ERCC', 'MT-'], suffixes=[]),\n",
      "  AnnDataTransform(func=scanpy.preprocessing._normalization.normalize_total, func_kwargs={'target_sum': 10000.0}),\n",
      "  AnnDataTransform(func=scanpy.preprocessing._simple.log1p, func_kwargs={}),\n",
      "  SpaGCNGraph(alpha=1, beta=49),\n",
      "  SpaGCNGraph2D(),\n",
      "  CellPCA(n_components=50),\n",
      "  SetConfig(config_dict={'feature_channel': ['CellPCA', 'SpaGCNGraph', 'SpaGCNGraph2D'], 'feature_channel_type': ['obsm', 'obsp', 'obsp'], 'label_channel': 'label', 'label_channel_type': 'obs'}),\n",
      ")\n",
      "[INFO][2023-10-26 00:30:05,575][dance.FilterGenesMatch][__call__] 0 number of genes will be removed due to prefix 'ERCC'\n",
      "[INFO][2023-10-26 00:30:05,582][dance.FilterGenesMatch][__call__] 0 number of genes will be removed due to prefix 'MT-'\n",
      "[INFO][2023-10-26 00:30:05,582][dance.FilterGenesMatch][__call__] Removing 0 genes in total\n",
      "[INFO][2023-10-26 00:30:05,740][dance.SpaGCNGraph][__call__] Start calculating the adjacency matrix using the histology image\n",
      "[INFO][2023-10-26 00:30:05,983][dance.SpaGCNGraph][__call__] Variances of c0, c1, c2 = [ 74.88207326 195.8172623  267.26317057]\n",
      "[INFO][2023-10-26 00:30:05,985][dance.SpaGCNGraph][__call__] Varirances of x, y, z = [ 268.13562 1242.5048  1242.5048 ]\n",
      "[INFO][2023-10-26 00:30:06,212][dance.CellPCA][__call__] Start generating cell PCA features (3353, 31053) (k=50)\n",
      "[INFO][2023-10-26 00:30:06,903][dance.CellPCA][__call__] Top 10 explained variances: [0.07938679 0.04168818 0.02032612 0.01341682 0.01138157 0.0065476\n",
      " 0.0063787  0.00529873 0.00338184 0.00314074]\n",
      "[INFO][2023-10-26 00:30:06,904][dance.CellPCA][__call__] Total explained variance: 23.30%\n",
      "[INFO][2023-10-26 00:30:06,933][dance.SetConfig][__call__] Updating the dance data object config options:\n",
      "{'feature_channel': ['CellPCA', 'SpaGCNGraph', 'SpaGCNGraph2D'],\n",
      " 'feature_channel_type': ['obsm', 'obsp', 'obsp'],\n",
      " 'label_channel': 'label',\n",
      " 'label_channel_type': 'obs'}\n",
      "[INFO][2023-10-26 00:30:06,934][dance][set_config_from_dict] Setting config 'feature_channel' to ['CellPCA', 'SpaGCNGraph', 'SpaGCNGraph2D']\n",
      "[INFO][2023-10-26 00:30:06,934][dance][set_config_from_dict] Setting config 'feature_channel_type' to ['obsm', 'obsp', 'obsp']\n",
      "[INFO][2023-10-26 00:30:06,935][dance][set_config_from_dict] Setting config 'label_channel' to 'label'\n",
      "[INFO][2023-10-26 00:30:06,936][dance][set_config_from_dict] Setting config 'label_channel_type' to 'obs'\n",
      "[INFO][2023-10-26 00:30:06,938][dance][load_data] Data transformed:\n",
      "Data object that wraps (.data):\n",
      "AnnData object with n_obs × n_vars = 3353 × 31053\n",
      "    obs: 'Barcode', 'ground_truth', 'label'\n",
      "    var: 'gene_ids', 'feature_types', 'genome'\n",
      "    uns: 'image', 'dance_config', 'log1p'\n",
      "    obsm: 'spatial', 'spatial_pixel', 'CellPCA'\n",
      "    obsp: 'SpaGCNGraph', 'SpaGCNGraph2D'\n",
      "[INFO][2023-10-26 00:30:06,939][dance][wrapped_func] Took 0:00:02.497478 to load and process data.\n",
      "[INFO][2023-10-26 00:30:07,184][dance][search_l] Run 1: l [0.01, 1000], p [0.0, 3342.7987306126756]\n",
      "[INFO][2023-10-26 00:30:07,210][dance][search_l] Run 2: l [0.01, 500.005], p [0.0, 3315.5517578125]\n",
      "[INFO][2023-10-26 00:30:07,236][dance][search_l] Run 3: l [0.01, 250.0075], p [0.0, 3211.62353515625]\n",
      "[INFO][2023-10-26 00:30:07,260][dance][search_l] Run 4: l [0.01, 125.00874999999999], p [0.0, 2862.56396484375]\n",
      "[INFO][2023-10-26 00:30:07,286][dance][search_l] Run 5: l [0.01, 62.509375], p [0.0, 2039.8681640625]\n",
      "[INFO][2023-10-26 00:30:07,311][dance][search_l] Run 6: l [0.01, 31.2596875], p [0.0, 975.9783935546875]\n",
      "[INFO][2023-10-26 00:30:07,338][dance][search_l] Run 7: l [0.01, 15.63484375], p [0.0, 290.52606201171875]\n",
      "[INFO][2023-10-26 00:30:07,387][dance][search_l] Run 8: l [0.01, 7.822421875], p [0.0, 66.0723876953125]\n",
      "[INFO][2023-10-26 00:30:07,443][dance][search_l] Run 9: l [0.01, 3.9162109375], p [0.0, 13.742901802062988]\n",
      "[INFO][2023-10-26 00:30:07,485][dance][search_l] Run 10: l [0.01, 1.9631054687499998], p [0.0, 2.5041720867156982]\n",
      "[INFO][2023-10-26 00:30:07,513][dance][search_l] Run 11: l [0.01, 0.9865527343749999], p [0.0, 0.31365859508514404]\n",
      "[INFO][2023-10-26 00:30:07,539][dance][search_l] Run 12: l [0.49827636718749996, 0.9865527343749999], p [0.005922675132751465, 0.31365859508514404]\n",
      "[INFO][2023-10-26 00:30:07,567][dance][search_l] Run 13: l [0.49827636718749996, 0.74241455078125], p [0.005922675132751465, 0.09121716022491455]\n",
      "[INFO][2023-10-26 00:30:07,593][dance][search_l] Run 14: l [0.620345458984375, 0.74241455078125], p [0.03235971927642822, 0.09121716022491455]\n",
      "[INFO][2023-10-26 00:30:07,620][dance][search_l] Run 15: l [0.620345458984375, 0.6813800048828125], p [0.03235971927642822, 0.05739021301269531]\n",
      "[INFO][2023-10-26 00:30:07,647][dance][search_l] Run 16: l [0.6508627319335938, 0.6813800048828125], p [0.04379630088806152, 0.05739021301269531]\n",
      "[INFO][2023-10-26 00:30:07,675][dance][search_l] recommended l: 0.6661213684082031\n",
      "[INFO][2023-10-26 00:30:07,676][dance][search_set_res] Start at res = 0.4000, step = 0.1000\n",
      "[INFO][2023-10-26 00:30:07,705][dance][fit] Initializing cluster centers with louvain, resolution = 0.4\n",
      "[INFO][2023-10-26 00:30:08,381][dance][fit] Epoch 0\n",
      "[INFO][2023-10-26 00:30:08,406][dance][fit] Epoch 10\n",
      "[INFO][2023-10-26 00:30:08,429][dance][fit] Epoch 20\n",
      "[INFO][2023-10-26 00:30:08,452][dance][fit] Epoch 30\n",
      "[INFO][2023-10-26 00:30:08,476][dance][fit] Epoch 40\n",
      "[INFO][2023-10-26 00:30:08,500][dance][fit] Epoch 50\n",
      "[INFO][2023-10-26 00:30:08,525][dance][fit] Epoch 60\n",
      "[INFO][2023-10-26 00:30:08,532][dance][fit] delta_label 0.0041753653444676405 < tol 0.005\n",
      "[INFO][2023-10-26 00:30:08,533][dance][fit] Reach tolerance threshold. Stopping training.\n",
      "[INFO][2023-10-26 00:30:08,534][dance][fit] Total epoch: 61\n",
      "[INFO][2023-10-26 00:30:08,571][dance][search_set_res] Res = 0.4000, Num of clusters = 13\n",
      "[INFO][2023-10-26 00:30:08,602][dance][fit] Initializing cluster centers with louvain, resolution = 0.30000000000000004\n",
      "[INFO][2023-10-26 00:30:09,362][dance][fit] Epoch 0\n",
      "[INFO][2023-10-26 00:30:09,385][dance][fit] Epoch 10\n",
      "[INFO][2023-10-26 00:30:09,408][dance][fit] Epoch 20\n",
      "[INFO][2023-10-26 00:30:09,431][dance][fit] Epoch 30\n",
      "[INFO][2023-10-26 00:30:09,455][dance][fit] Epoch 40\n",
      "[INFO][2023-10-26 00:30:09,480][dance][fit] Epoch 50\n",
      "[INFO][2023-10-26 00:30:09,506][dance][fit] Epoch 60\n",
      "[INFO][2023-10-26 00:30:09,533][dance][fit] Epoch 70\n",
      "[INFO][2023-10-26 00:30:09,561][dance][fit] Epoch 80\n",
      "[INFO][2023-10-26 00:30:09,589][dance][fit] Epoch 90\n",
      "[INFO][2023-10-26 00:30:09,619][dance][fit] Epoch 100\n",
      "[INFO][2023-10-26 00:30:09,623][dance][fit] delta_label 0.0047718461079630185 < tol 0.005\n",
      "[INFO][2023-10-26 00:30:09,624][dance][fit] Reach tolerance threshold. Stopping training.\n",
      "[INFO][2023-10-26 00:30:09,625][dance][fit] Total epoch: 100\n",
      "[INFO][2023-10-26 00:30:09,667][dance][search_set_res] Res = 3.000e-01, Num of clusters = 11\n",
      "[INFO][2023-10-26 00:30:09,667][dance][search_set_res] Res changed to 0.30000000000000004\n",
      "[INFO][2023-10-26 00:30:09,698][dance][fit] Initializing cluster centers with louvain, resolution = 0.20000000000000004\n",
      "[INFO][2023-10-26 00:30:10,491][dance][fit] Epoch 0\n",
      "[INFO][2023-10-26 00:30:10,515][dance][fit] Epoch 10\n",
      "[INFO][2023-10-26 00:30:10,537][dance][fit] Epoch 20\n",
      "[INFO][2023-10-26 00:30:10,561][dance][fit] Epoch 30\n",
      "[INFO][2023-10-26 00:30:10,585][dance][fit] Epoch 40\n",
      "[INFO][2023-10-26 00:30:10,603][dance][fit] delta_label 0.0038771249627199524 < tol 0.005\n",
      "[INFO][2023-10-26 00:30:10,604][dance][fit] Reach tolerance threshold. Stopping training.\n",
      "[INFO][2023-10-26 00:30:10,604][dance][fit] Total epoch: 46\n",
      "[INFO][2023-10-26 00:30:10,638][dance][search_set_res] Res = 2.000e-01, Num of clusters = 9\n",
      "[INFO][2023-10-26 00:30:10,639][dance][search_set_res] Res changed to 0.20000000000000004\n",
      "[INFO][2023-10-26 00:30:10,669][dance][fit] Initializing cluster centers with louvain, resolution = 0.10000000000000003\n",
      "[INFO][2023-10-26 00:30:11,324][dance][fit] Epoch 0\n",
      "[INFO][2023-10-26 00:30:11,348][dance][fit] Epoch 10\n",
      "[INFO][2023-10-26 00:30:11,370][dance][fit] Epoch 20\n",
      "[INFO][2023-10-26 00:30:11,395][dance][fit] Epoch 30\n",
      "[INFO][2023-10-26 00:30:11,418][dance][fit] Epoch 40\n",
      "[INFO][2023-10-26 00:30:11,442][dance][fit] Epoch 50\n",
      "[INFO][2023-10-26 00:30:11,465][dance][fit] Epoch 60\n",
      "[INFO][2023-10-26 00:30:11,489][dance][fit] Epoch 70\n",
      "[INFO][2023-10-26 00:30:11,512][dance][fit] Epoch 80\n",
      "[INFO][2023-10-26 00:30:11,535][dance][fit] Epoch 90\n",
      "[INFO][2023-10-26 00:30:11,557][dance][fit] Epoch 100\n",
      "[INFO][2023-10-26 00:30:11,580][dance][fit] Epoch 110\n",
      "[INFO][2023-10-26 00:30:11,603][dance][fit] Epoch 120\n",
      "[INFO][2023-10-26 00:30:11,627][dance][fit] Epoch 130\n",
      "[INFO][2023-10-26 00:30:11,649][dance][fit] Epoch 140\n",
      "[INFO][2023-10-26 00:30:11,672][dance][fit] Epoch 150\n",
      "[INFO][2023-10-26 00:30:11,695][dance][fit] Epoch 160\n",
      "[INFO][2023-10-26 00:30:11,699][dance][fit] delta_label 0.0047718461079630185 < tol 0.005\n",
      "[INFO][2023-10-26 00:30:11,700][dance][fit] Reach tolerance threshold. Stopping training.\n",
      "[INFO][2023-10-26 00:30:11,700][dance][fit] Total epoch: 160\n",
      "[INFO][2023-10-26 00:30:11,744][dance][search_set_res] Res = 1.000e-01, Num of clusters = 6\n",
      "[INFO][2023-10-26 00:30:11,745][dance][search_set_res] Step changed to 0.0500\n",
      "[INFO][2023-10-26 00:30:11,776][dance][fit] Initializing cluster centers with louvain, resolution = 0.15000000000000002\n",
      "[INFO][2023-10-26 00:30:12,569][dance][fit] Epoch 0\n",
      "[INFO][2023-10-26 00:30:12,593][dance][fit] Epoch 10\n",
      "[INFO][2023-10-26 00:30:12,616][dance][fit] Epoch 20\n",
      "[INFO][2023-10-26 00:30:12,640][dance][fit] Epoch 30\n",
      "[INFO][2023-10-26 00:30:12,662][dance][fit] Epoch 40\n",
      "[INFO][2023-10-26 00:30:12,686][dance][fit] Epoch 50\n",
      "[INFO][2023-10-26 00:30:12,711][dance][fit] Epoch 60\n",
      "[INFO][2023-10-26 00:30:12,732][dance][fit] Epoch 70\n",
      "[INFO][2023-10-26 00:30:12,747][dance][fit] delta_label 0.003578884580972264 < tol 0.005\n",
      "[INFO][2023-10-26 00:30:12,748][dance][fit] Reach tolerance threshold. Stopping training.\n",
      "[INFO][2023-10-26 00:30:12,749][dance][fit] Total epoch: 76\n",
      "[INFO][2023-10-26 00:30:12,804][dance][search_set_res] Res = 1.500e-01, Num of clusters = 8\n",
      "[INFO][2023-10-26 00:30:12,805][dance][search_set_res] Res changed to 0.15000000000000002\n",
      "[INFO][2023-10-26 00:30:12,836][dance][fit] Initializing cluster centers with louvain, resolution = 0.10000000000000002\n",
      "[INFO][2023-10-26 00:30:13,550][dance][fit] Epoch 0\n",
      "[INFO][2023-10-26 00:30:13,569][dance][fit] Epoch 10\n",
      "[INFO][2023-10-26 00:30:13,586][dance][fit] Epoch 20\n",
      "[INFO][2023-10-26 00:30:13,607][dance][fit] Epoch 30\n",
      "[INFO][2023-10-26 00:30:13,628][dance][fit] Epoch 40\n",
      "[INFO][2023-10-26 00:30:13,650][dance][fit] Epoch 50\n",
      "[INFO][2023-10-26 00:30:13,673][dance][fit] Epoch 60\n",
      "[INFO][2023-10-26 00:30:13,698][dance][fit] Epoch 70\n",
      "[INFO][2023-10-26 00:30:13,724][dance][fit] Epoch 80\n",
      "[INFO][2023-10-26 00:30:13,752][dance][fit] Epoch 90\n",
      "[INFO][2023-10-26 00:30:13,780][dance][fit] Epoch 100\n",
      "[INFO][2023-10-26 00:30:13,809][dance][fit] Epoch 110\n",
      "[INFO][2023-10-26 00:30:13,839][dance][fit] Epoch 120\n",
      "[INFO][2023-10-26 00:30:13,865][dance][fit] Epoch 130\n",
      "[INFO][2023-10-26 00:30:13,893][dance][fit] Epoch 140\n",
      "[INFO][2023-10-26 00:30:13,919][dance][fit] Epoch 150\n",
      "[INFO][2023-10-26 00:30:13,945][dance][fit] Epoch 160\n",
      "[INFO][2023-10-26 00:30:13,972][dance][fit] Epoch 170\n",
      "[INFO][2023-10-26 00:30:13,999][dance][fit] Epoch 180\n",
      "[INFO][2023-10-26 00:30:14,025][dance][fit] Epoch 190\n",
      "[INFO][2023-10-26 00:30:14,089][dance][search_set_res] Res = 1.000e-01, Num of clusters = 6\n",
      "[INFO][2023-10-26 00:30:14,089][dance][search_set_res] Step changed to 0.0250\n",
      "[INFO][2023-10-26 00:30:14,121][dance][fit] Initializing cluster centers with louvain, resolution = 0.12500000000000003\n",
      "[INFO][2023-10-26 00:30:14,871][dance][fit] Epoch 0\n",
      "[INFO][2023-10-26 00:30:14,895][dance][fit] Epoch 10\n",
      "[INFO][2023-10-26 00:30:14,918][dance][fit] Epoch 20\n",
      "[INFO][2023-10-26 00:30:14,941][dance][fit] Epoch 30\n",
      "[INFO][2023-10-26 00:30:14,966][dance][fit] Epoch 40\n",
      "[INFO][2023-10-26 00:30:14,970][dance][fit] delta_label 0.003578884580972264 < tol 0.005\n",
      "[INFO][2023-10-26 00:30:14,970][dance][fit] Reach tolerance threshold. Stopping training.\n",
      "[INFO][2023-10-26 00:30:14,971][dance][fit] Total epoch: 40\n",
      "[INFO][2023-10-26 00:30:15,006][dance][search_set_res] Res = 1.250e-01, Num of clusters = 7\n",
      "[INFO][2023-10-26 00:30:15,007][dance][search_set_res] recommended res = 0.1250\n",
      "[INFO][2023-10-26 00:30:15,037][dance][fit] Initializing cluster centers with louvain, resolution = 0.12500000000000003\n",
      "[INFO][2023-10-26 00:30:15,859][dance][fit] Epoch 0\n",
      "[INFO][2023-10-26 00:30:15,883][dance][fit] Epoch 10\n",
      "[INFO][2023-10-26 00:30:15,904][dance][fit] Epoch 20\n",
      "[INFO][2023-10-26 00:30:15,926][dance][fit] Epoch 30\n",
      "[INFO][2023-10-26 00:30:15,950][dance][fit] Epoch 40\n",
      "[INFO][2023-10-26 00:30:15,972][dance][fit] Epoch 50\n",
      "[INFO][2023-10-26 00:30:15,993][dance][fit] Epoch 60\n",
      "[INFO][2023-10-26 00:30:16,018][dance][fit] Epoch 70\n",
      "[INFO][2023-10-26 00:30:16,043][dance][fit] Epoch 80\n",
      "[INFO][2023-10-26 00:30:16,071][dance][fit] Epoch 90\n",
      "[INFO][2023-10-26 00:30:16,096][dance][fit] Epoch 100\n",
      "[INFO][2023-10-26 00:30:16,124][dance][fit] Epoch 110\n",
      "[INFO][2023-10-26 00:30:16,155][dance][fit] Epoch 120\n",
      "[INFO][2023-10-26 00:30:16,185][dance][fit] Epoch 130\n",
      "[INFO][2023-10-26 00:30:16,217][dance][fit] Epoch 140\n",
      "[INFO][2023-10-26 00:30:16,250][dance][fit] Epoch 150\n",
      "[INFO][2023-10-26 00:30:16,283][dance][fit] Epoch 160\n",
      "[INFO][2023-10-26 00:30:16,315][dance][fit] Epoch 170\n",
      "[INFO][2023-10-26 00:30:16,349][dance][fit] Epoch 180\n",
      "[INFO][2023-10-26 00:30:16,381][dance][fit] Epoch 190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI: 0.4882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' To reproduce SpaGCN on other samples, please refer to command lines belows:\\n\\nhuman dorsolateral prefrontal cortex sample 151673:\\npython spagcn.py --sample_number=151673 --lr=0.1\\n\\nhuman dorsolateral prefrontal cortex sample 151676:\\npython spagcn.py --sample_number=151676  --lr=0.02\\n\\nhuman dorsolateral prefrontal cortex sample 151507:\\npython spagcn.py --sample_number=151507  --lr=0.009\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "from dance.datasets.spatial import SpatialLIBDDataset\n",
    "from dance.modules.spatial.spatial_domain.spagcn import SpaGCN, refine\n",
    "from dance.utils import set_seed\n",
    "\n",
    "SpaGCN_scores=[]\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--cache\", action=\"store_true\", help=\"Cache processed data.\")\n",
    "parser.add_argument(\"--sample_number\", type=str, default=\"151673\",\n",
    "                    help=\"12 human dorsolateral prefrontal cortex datasets for the spatial domain task.\")\n",
    "parser.add_argument(\"--beta\", type=int, default=49, help=\"\")\n",
    "parser.add_argument(\"--alpha\", type=int, default=1, help=\"\")\n",
    "parser.add_argument(\"--p\", type=float, default=0.05,\n",
    "                    help=\"percentage of total expression contributed by neighborhoods.\")\n",
    "parser.add_argument(\"--l\", type=float, default=0.5, help=\"the parameter to control percentage p.\")\n",
    "parser.add_argument(\"--start\", type=float, default=0.01, help=\"starting value for searching l.\")\n",
    "parser.add_argument(\"--end\", type=float, default=1000, help=\"ending value for searching l.\")\n",
    "parser.add_argument(\"--tol\", type=float, default=5e-3, help=\"tolerant value for searching l.\")\n",
    "parser.add_argument(\"--max_run\", type=int, default=200, help=\"max runs.\")\n",
    "parser.add_argument(\"--epochs\", type=int, default=200, help=\"Number of epochs.\")\n",
    "parser.add_argument(\"--n_clusters\", type=int, default=7, help=\"the number of clusters\")\n",
    "parser.add_argument(\"--step\", type=float, default=0.1, help=\"\")\n",
    "parser.add_argument(\"--lr\", type=float, default=0.05, help=\"learning rate\")\n",
    "parser.add_argument(\"--random_state\", type=int, default=100, help=\"\")\n",
    "args = parser.parse_args(['--sample_number',\"mpb\",'--lr','0.1'])\n",
    "set_seed(args.random_state)\n",
    "\n",
    "# Initialize model and get model specific preprocessing pipeline\n",
    "model = SpaGCN()\n",
    "preprocessing_pipeline = model.preprocessing_pipeline(alpha=args.alpha, beta=args.beta)\n",
    "\n",
    "# Load data and perform necessary preprocessing\n",
    "dataloader = SpatialLIBDDataset(data_id=args.sample_number,data_dir=\"/home/zyxing/data/spatial\")\n",
    "data = dataloader.load_data(transform=preprocessing_pipeline, cache=args.cache)\n",
    "(x, adj, adj_2d), y = data.get_train_data()\n",
    "\n",
    "# Train and evaluate model\n",
    "l = model.search_l(args.p, adj, start=args.start, end=args.end, tol=args.tol, max_run=args.max_run)\n",
    "model.set_l(l)\n",
    "res = model.search_set_res((x, adj), l=l, target_num=args.n_clusters, start=0.4, step=args.step, tol=args.tol,\n",
    "                        lr=args.lr, epochs=args.epochs, max_run=args.max_run)\n",
    "\n",
    "pred = model.fit_predict((x, adj), init_spa=True, init=\"louvain\", tol=args.tol, lr=args.lr, epochs=args.epochs,\n",
    "                        res=res)\n",
    "score = model.default_score_func(y, pred)\n",
    "print(f\"ARI: {score:.4f}\")\n",
    "\n",
    "refined_pred = refine(sample_id=data.data.obs_names.tolist(), pred=pred.tolist(), dis=adj_2d, shape=\"hexagon\")\n",
    "score_refined = model.default_score_func(y, refined_pred)\n",
    "\"\"\" To reproduce SpaGCN on other samples, please refer to command lines belows:\n",
    "\n",
    "human dorsolateral prefrontal cortex sample 151673:\n",
    "python spagcn.py --sample_number=151673 --lr=0.1\n",
    "\n",
    "human dorsolateral prefrontal cortex sample 151676:\n",
    "python spagcn.py --sample_number=151676  --lr=0.02\n",
    "\n",
    "human dorsolateral prefrontal cortex sample 151507:\n",
    "python spagcn.py --sample_number=151507  --lr=0.009\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-26 00:30:19,818][dance][_load_raw_data] Loading expression data from /home/zyxing/data/spatial/mpb/mpb_raw_feature_bc_matrix.h5\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/anndata/_core/anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/anndata/_core/anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "[INFO][2023-10-26 00:30:20,838][dance][_load_raw_data] Loading spatial info from /home/zyxing/data/spatial/mpb/tissue_positions_list.txt\n",
      "[INFO][2023-10-26 00:30:20,852][dance][_load_raw_data] Loading label info from /home/zyxing/data/spatial/mpb/cluster_labels.csv\n",
      "[INFO][2023-10-26 00:30:20,860][dance][_load_raw_data] Loading image data from /home/zyxing/data/spatial/mpb/mpb_full_image.tif\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/anndata/_core/anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/anndata/_core/anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "[INFO][2023-10-26 00:30:21,026][dance][load_data] Raw data loaded:\n",
      "Data object that wraps (.data):\n",
      "AnnData object with n_obs × n_vars = 3353 × 31053\n",
      "    obs: 'Barcode', 'ground_truth', 'label'\n",
      "    var: 'gene_ids', 'feature_types', 'genome'\n",
      "    uns: 'image', 'dance_config'\n",
      "    obsm: 'spatial', 'spatial_pixel'\n",
      "[INFO][2023-10-26 00:30:21,027][dance.Compose][__call__] Applying composed transformations:\n",
      "Compose(\n",
      "  AnnDataTransform(func=scanpy.preprocessing._highly_variable_genes.highly_variable_genes, func_kwargs={'flavor': 'seurat_v3', 'n_top_genes': 3000, 'subset': True}),\n",
      "  AnnDataTransform(func=scanpy.preprocessing._normalization.normalize_total, func_kwargs={'target_sum': 10000.0}),\n",
      "  AnnDataTransform(func=scanpy.preprocessing._simple.log1p, func_kwargs={}),\n",
      "  StagateGraph(model_name='radius', radius=150, n_neighbors=5),\n",
      "  SetConfig(config_dict={'feature_channel': 'StagateGraph', 'feature_channel_type': 'obsp', 'label_channel': 'label', 'label_channel_type': 'obs'}),\n",
      ")\n",
      "[INFO][2023-10-26 00:30:21,793][dance.SetConfig][__call__] Updating the dance data object config options:\n",
      "{'feature_channel': 'StagateGraph',\n",
      " 'feature_channel_type': 'obsp',\n",
      " 'label_channel': 'label',\n",
      " 'label_channel_type': 'obs'}\n",
      "[INFO][2023-10-26 00:30:21,794][dance][set_config_from_dict] Setting config 'feature_channel' to 'StagateGraph'\n",
      "[INFO][2023-10-26 00:30:21,795][dance][set_config_from_dict] Setting config 'feature_channel_type' to 'obsp'\n",
      "[INFO][2023-10-26 00:30:21,796][dance][set_config_from_dict] Setting config 'label_channel' to 'label'\n",
      "[INFO][2023-10-26 00:30:21,797][dance][set_config_from_dict] Setting config 'label_channel_type' to 'obs'\n",
      "[INFO][2023-10-26 00:30:21,798][dance][load_data] Data transformed:\n",
      "Data object that wraps (.data):\n",
      "AnnData object with n_obs × n_vars = 3353 × 3000\n",
      "    obs: 'Barcode', 'ground_truth', 'label'\n",
      "    var: 'gene_ids', 'feature_types', 'genome', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm'\n",
      "    uns: 'image', 'dance_config', 'hvg', 'log1p'\n",
      "    obsm: 'spatial', 'spatial_pixel'\n",
      "    obsp: 'StagateGraph'\n",
      "[INFO][2023-10-26 00:30:21,799][dance][wrapped_func] Took 0:00:01.980599 to load and process data.\n",
      "[INFO][2023-10-26 00:30:21,853][dance][_pretrain] Pre-training started\n",
      "[WARNING][2023-10-26 00:30:21,854][dance][_pretrain] `pretrain_path` is not set, pre-trained model will not be saved.\n",
      "100%|██████████| 1000/1000 [00:40<00:00, 24.60it/s]\n",
      "[INFO][2023-10-26 00:31:02,540][dance][_pretrain] Pre-training finished (took 40.69 seconds)\n",
      "[INFO][2023-10-26 00:31:02,541][dance][fit] Fitting Gaussian Mixture model for cluster assignments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI: 0.3814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' To reproduce Stagate on other samples, please refer to command lines belows:\\nNOTE: since the stagate method is unstable, you have to run at least 5 times to get\\n      best performance. (same with original Stagate paper)\\n\\nhuman dorsolateral prefrontal cortex sample 151673:\\npython stagate.py --sample_number=151673 --seed=16\\n\\nhuman dorsolateral prefrontal cortex sample 151676:\\npython stagate.py --sample_number=151676 --seed=2030\\n\\nhuman dorsolateral prefrontal cortex sample 151507:\\npython stagate.py --sample_number=151507 --seed=2021\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from dance.datasets.spatial import SpatialLIBDDataset\n",
    "from dance.modules.spatial.spatial_domain.stagate import Stagate\n",
    "from dance.transforms.preprocess import set_seed\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--cache\", action=\"store_true\", help=\"Cache processed data.\")\n",
    "parser.add_argument(\"--sample_number\", type=str, default=\"151673\",\n",
    "                    help=\"12 human dorsolateral prefrontal cortex datasets for the spatial domain task.\")\n",
    "parser.add_argument(\"--hidden_dims\", type=list, default=[512, 32], help=\"hidden dimensions\")\n",
    "parser.add_argument(\"--rad_cutoff\", type=int, default=150, help=\"\")\n",
    "parser.add_argument(\"--seed\", type=int, default=3, help=\"\")\n",
    "parser.add_argument(\"--epochs\", type=int, default=1000, help=\"epochs\")\n",
    "parser.add_argument(\"--high_variable_genes\", type=int, default=3000, help=\"\")\n",
    "args = parser.parse_args(['--sample_number','mpb','--seed','16'])\n",
    "set_seed(args.seed)\n",
    "\n",
    "# Initialize model and get model specific preprocessing pipeline\n",
    "model = Stagate([args.high_variable_genes] + args.hidden_dims)\n",
    "preprocessing_pipeline = model.preprocessing_pipeline(n_top_hvgs=args.high_variable_genes, radius=args.rad_cutoff)\n",
    "\n",
    "# Load data and perform necessary preprocessing\n",
    "dataloader = SpatialLIBDDataset(data_id=args.sample_number,data_dir=\"/home/zyxing/data/spatial\")\n",
    "data = dataloader.load_data(transform=preprocessing_pipeline, cache=args.cache)\n",
    "adj, y = data.get_data(return_type=\"default\")\n",
    "x = data.data.X.A\n",
    "edge_list_array = np.vstack(np.nonzero(adj))\n",
    "\n",
    "# Train and evaluate model\n",
    "model = Stagate([args.high_variable_genes] + args.hidden_dims)\n",
    "score = model.fit_score((x, edge_list_array), y, epochs=args.epochs, random_state=args.seed)\n",
    "print(f\"ARI: {score:.4f}\")\n",
    "\"\"\" To reproduce Stagate on other samples, please refer to command lines belows:\n",
    "NOTE: since the stagate method is unstable, you have to run at least 5 times to get\n",
    "      best performance. (same with original Stagate paper)\n",
    "\n",
    "human dorsolateral prefrontal cortex sample 151673:\n",
    "python stagate.py --sample_number=151673 --seed=16\n",
    "\n",
    "human dorsolateral prefrontal cortex sample 151676:\n",
    "python stagate.py --sample_number=151676 --seed=2030\n",
    "\n",
    "human dorsolateral prefrontal cortex sample 151507:\n",
    "python stagate.py --sample_number=151507 --seed=2021\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[INFO][2023-10-26 00:31:04,278][dance][_load_raw_data] Loading expression data from /home/zyxing/data/spatial/mpb/mpb_raw_feature_bc_matrix.h5\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/anndata/_core/anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/anndata/_core/anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "[INFO][2023-10-26 00:31:05,244][dance][_load_raw_data] Loading spatial info from /home/zyxing/data/spatial/mpb/tissue_positions_list.txt\n",
      "[INFO][2023-10-26 00:31:05,257][dance][_load_raw_data] Loading label info from /home/zyxing/data/spatial/mpb/cluster_labels.csv\n",
      "[INFO][2023-10-26 00:31:05,264][dance][_load_raw_data] Loading image data from /home/zyxing/data/spatial/mpb/mpb_full_image.tif\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/anndata/_core/anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/anndata/_core/anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "[INFO][2023-10-26 00:31:05,427][dance][load_data] Raw data loaded:\n",
      "Data object that wraps (.data):\n",
      "AnnData object with n_obs × n_vars = 3353 × 31053\n",
      "    obs: 'Barcode', 'ground_truth', 'label'\n",
      "    var: 'gene_ids', 'feature_types', 'genome'\n",
      "    uns: 'image', 'dance_config'\n",
      "    obsm: 'spatial', 'spatial_pixel'\n",
      "[INFO][2023-10-26 00:31:05,428][dance.Compose][__call__] Applying composed transformations:\n",
      "Compose(\n",
      "  AnnDataTransform(func=scanpy.preprocessing._simple.filter_genes, func_kwargs={'min_cells': 1}),\n",
      "  AnnDataTransform(func=scanpy.preprocessing._normalization.normalize_total, func_kwargs={'target_sum': 10000.0}),\n",
      "  AnnDataTransform(func=scanpy.preprocessing._simple.log1p, func_kwargs={}),\n",
      "  MorphologyFeature(model_name='resnet50', n_components=50, crop_size=10, target_size=230),\n",
      "  CellPCA(n_components=10),\n",
      "  SMEGraph(),\n",
      "  SMEFeature(),\n",
      "  NeighborGraph(n_neighbors=10, n_pcs=10, knn=True, random_state=0, method='umap', metric='euclidean'),\n",
      "  SetConfig(config_dict={'feature_channel': 'NeighborGraph', 'feature_channel_type': 'obsp', 'label_channel': 'label', 'label_channel_type': 'obs'}),\n",
      ")\n",
      "Extracting feature: 100%|██████████ [ time left: 00:00 ]\n",
      "[INFO][2023-10-26 00:33:13,078][dance.CellPCA][__call__] Start generating cell PCA features (3353, 20524) (k=10)\n",
      "[INFO][2023-10-26 00:33:13,432][dance.CellPCA][__call__] Top 10 explained variances: [0.07938678 0.0416882  0.02032615 0.01341683 0.01138158 0.0065476\n",
      " 0.00637869 0.00529873 0.00338184 0.00314074]\n",
      "[INFO][2023-10-26 00:33:13,433][dance.CellPCA][__call__] Total explained variance: 19.09%\n",
      "Adjusting data: 100%|██████████ [ time left: 00:00 ]\n",
      "[INFO][2023-10-26 00:33:16,383][dance.NeighborGraph][__call__] Start computing the kNN connectivity adjacency matrix\n",
      "[INFO][2023-10-26 00:33:16,689][dance.SetConfig][__call__] Updating the dance data object config options:\n",
      "{'feature_channel': 'NeighborGraph',\n",
      " 'feature_channel_type': 'obsp',\n",
      " 'label_channel': 'label',\n",
      " 'label_channel_type': 'obs'}\n",
      "[INFO][2023-10-26 00:33:16,690][dance][set_config_from_dict] Setting config 'feature_channel' to 'NeighborGraph'\n",
      "[INFO][2023-10-26 00:33:16,691][dance][set_config_from_dict] Setting config 'feature_channel_type' to 'obsp'\n",
      "[INFO][2023-10-26 00:33:16,692][dance][set_config_from_dict] Setting config 'label_channel' to 'label'\n",
      "[INFO][2023-10-26 00:33:16,693][dance][set_config_from_dict] Setting config 'label_channel_type' to 'obs'\n",
      "[INFO][2023-10-26 00:33:16,694][dance][load_data] Data transformed:\n",
      "Data object that wraps (.data):\n",
      "AnnData object with n_obs × n_vars = 3353 × 20524\n",
      "    obs: 'Barcode', 'ground_truth', 'label'\n",
      "    var: 'gene_ids', 'feature_types', 'genome', 'n_cells'\n",
      "    uns: 'image', 'dance_config', 'log1p'\n",
      "    obsm: 'spatial', 'spatial_pixel', 'MorphologyFeature', 'CellPCA', 'SMEFeature'\n",
      "    obsp: 'SMEGraph', 'NeighborGraph'\n",
      "[INFO][2023-10-26 00:33:16,694][dance][wrapped_func] Took 0:02:12.416176 to load and process data.\n",
      "[INFO][2023-10-26 00:33:16,698][dance][fit] Converting adjacency matrix to networkx graph...\n",
      "[INFO][2023-10-26 00:33:17,277][dance][fit] Conversion done. Start fitting...\n",
      "[INFO][2023-10-26 00:33:17,819][dance][fit] Fitting done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI: 0.5191\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' To reproduce stlearn on other samples, please refer to command lines belows:\\nNOTE: since the stlearn method is unstable, you have to run multiple times to get\\n      best performance.\\n\\nhuman dorsolateral prefrontal cortex sample 151673:\\npython stlearn.py --n_clusters=20 --sample_number=151673 --seed=93\\n\\nhuman dorsolateral prefrontal cortex sample 151676:\\npython stlearn.py --n_clusters=20 --sample_number=151676 --seed=11\\n\\nhuman dorsolateral prefrontal cortex sample 151507:\\npython stlearn.py --n_clusters=20 --sample_number=151507 --seed=0\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "from dance.datasets.spatial import SpatialLIBDDataset\n",
    "from dance.modules.spatial.spatial_domain.stlearn import StKmeans, StLouvain\n",
    "from dance.transforms.preprocess import set_seed\n",
    "\n",
    "MODES = [\"louvain\", \"kmeans\"]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--cache\", action=\"store_true\", help=\"Cache processed data.\")\n",
    "    parser.add_argument(\"--sample_number\", type=str, default=\"151673\",\n",
    "                        help=\"12 human dorsolateral prefrontal cortex datasets for the spatial domain task.\")\n",
    "    parser.add_argument(\"--mode\", type=str, default=\"louvain\", choices=MODES)\n",
    "    parser.add_argument(\"--n_clusters\", type=int, default=17, help=\"the number of clusters\")\n",
    "    parser.add_argument(\"--seed\", type=int, default=2)\n",
    "    parser.add_argument(\"--n_components\", type=int, default=50, help=\"the number of components in PCA\")\n",
    "    parser.add_argument(\"--device\", type=str, default=\"cuda\", help=\"device for resnet extract feature\")\n",
    "    args = parser.parse_args(['--n_clusters','20','--sample_number','mpb','--seed','93'])\n",
    "    set_seed(args.seed)\n",
    "\n",
    "    # Initialize model and get model specific preprocessing pipeline\n",
    "    if args.mode == \"kmeans\":\n",
    "        model = StKmeans(n_clusters=args.n_clusters)\n",
    "    elif args.mode == \"louvain\":\n",
    "        model = StLouvain(resolution=0.6)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown mode {args.mode!r}, available options are {MODES}\")\n",
    "    preprocessing_pipeline = model.preprocessing_pipeline()\n",
    "\n",
    "    # Load data and perform necessary preprocessing\n",
    "    dataloader = SpatialLIBDDataset(data_id=args.sample_number,data_dir=\"/home/zyxing/data/spatial\")\n",
    "    data = dataloader.load_data(transform=preprocessing_pipeline, cache=args.cache)\n",
    "    x, y = data.get_data(return_type=\"default\")\n",
    "\n",
    "    # Train and evaluate model\n",
    "    score = model.fit_score(x, y.values.ravel())\n",
    "    print(f\"ARI: {score:.4f}\")\n",
    "\"\"\" To reproduce stlearn on other samples, please refer to command lines belows:\n",
    "NOTE: since the stlearn method is unstable, you have to run multiple times to get\n",
    "      best performance.\n",
    "\n",
    "human dorsolateral prefrontal cortex sample 151673:\n",
    "python stlearn.py --n_clusters=20 --sample_number=151673 --seed=93\n",
    "\n",
    "human dorsolateral prefrontal cortex sample 151676:\n",
    "python stlearn.py --n_clusters=20 --sample_number=151676 --seed=11\n",
    "\n",
    "human dorsolateral prefrontal cortex sample 151507:\n",
    "python stlearn.py --n_clusters=20 --sample_number=151507 --seed=0\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets=[\"sub_pancreatic_cancer\",\"sub_human_breast_cancer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-26 00:33:17,857][dance][_load_raw_data] Loading expression data from /home/zyxing/data/spatial/sub_pancreatic_cancer/sub_pancreatic_cancer_raw_feature_bc_matrix.h5\n",
      "[INFO][2023-10-26 00:33:17,874][dance][_load_raw_data] Loading spatial info from /home/zyxing/data/spatial/sub_pancreatic_cancer/tissue_positions_list.txt\n",
      "[INFO][2023-10-26 00:33:17,879][dance][_load_raw_data] Loading label info from /home/zyxing/data/spatial/sub_pancreatic_cancer/cluster_labels.csv\n",
      "[INFO][2023-10-26 00:33:17,885][dance][_load_raw_data] Loading image data from /home/zyxing/data/spatial/sub_pancreatic_cancer/sub_pancreatic_cancer_full_image.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-26 00:33:30,198][dance][load_data] Raw data loaded:\n",
      "Data object that wraps (.data):\n",
      "AnnData object with n_obs × n_vars = 2000 × 474\n",
      "    obs: '0', 'ground_truth', 'label'\n",
      "    var: 'gene_ids', 'feature_types', 'genome'\n",
      "    uns: 'image', 'dance_config'\n",
      "    obsm: 'spatial', 'spatial_pixel'\n",
      "[INFO][2023-10-26 00:33:30,200][dance.Compose][__call__] Applying composed transformations:\n",
      "Compose(\n",
      "  FilterGenesMatch(prefixes=['ERCC', 'MT-'], suffixes=[]),\n",
      "  AnnDataTransform(func=scanpy.preprocessing._normalization.normalize_total, func_kwargs={'target_sum': 10000.0}),\n",
      "  AnnDataTransform(func=scanpy.preprocessing._simple.scale, func_kwargs={}),\n",
      "  CellPCA(n_components=30),\n",
      "  NeighborGraph(n_neighbors=17, n_pcs=None, knn=True, random_state=0, method='umap', metric='euclidean'),\n",
      "  SetConfig(config_dict={'feature_channel': 'NeighborGraph', 'feature_channel_type': 'obsp', 'label_channel': 'label', 'label_channel_type': 'obs'}),\n",
      ")\n",
      "[INFO][2023-10-26 00:33:30,201][dance.FilterGenesMatch][__call__] 0 number of genes will be removed due to prefix 'ERCC'\n",
      "[INFO][2023-10-26 00:33:30,202][dance.FilterGenesMatch][__call__] 0 number of genes will be removed due to prefix 'MT-'\n",
      "[INFO][2023-10-26 00:33:30,203][dance.FilterGenesMatch][__call__] Removing 0 genes in total\n",
      "[INFO][2023-10-26 00:33:31,304][dance.CellPCA][__call__] Start generating cell PCA features (2000, 474) (k=30)\n",
      "[INFO][2023-10-26 00:33:31,318][dance.CellPCA][__call__] Top 10 explained variances: [0.02503958 0.01309882 0.0108925  0.00955402 0.00739734 0.00657433\n",
      " 0.00590837 0.00572336 0.00551816 0.00549484]\n",
      "[INFO][2023-10-26 00:33:31,319][dance.CellPCA][__call__] Total explained variance: 18.64%\n",
      "[INFO][2023-10-26 00:33:31,319][dance.NeighborGraph][__call__] Start computing the kNN connectivity adjacency matrix\n",
      "[INFO][2023-10-26 00:33:32,528][dance.SetConfig][__call__] Updating the dance data object config options:\n",
      "{'feature_channel': 'NeighborGraph',\n",
      " 'feature_channel_type': 'obsp',\n",
      " 'label_channel': 'label',\n",
      " 'label_channel_type': 'obs'}\n",
      "[INFO][2023-10-26 00:33:32,529][dance][set_config_from_dict] Setting config 'feature_channel' to 'NeighborGraph'\n",
      "[INFO][2023-10-26 00:33:32,529][dance][set_config_from_dict] Setting config 'feature_channel_type' to 'obsp'\n",
      "[INFO][2023-10-26 00:33:32,530][dance][set_config_from_dict] Setting config 'label_channel' to 'label'\n",
      "[INFO][2023-10-26 00:33:32,530][dance][set_config_from_dict] Setting config 'label_channel_type' to 'obs'\n",
      "[INFO][2023-10-26 00:33:32,531][dance][load_data] Data transformed:\n",
      "Data object that wraps (.data):\n",
      "AnnData object with n_obs × n_vars = 2000 × 474\n",
      "    obs: '0', 'ground_truth', 'label'\n",
      "    var: 'gene_ids', 'feature_types', 'genome', 'mean', 'std'\n",
      "    uns: 'image', 'dance_config'\n",
      "    obsm: 'spatial', 'spatial_pixel', 'CellPCA'\n",
      "    obsp: 'NeighborGraph'\n",
      "[INFO][2023-10-26 00:33:32,531][dance][wrapped_func] Took 0:00:14.674188 to load and process data.\n",
      "[INFO][2023-10-26 00:33:32,534][dance][fit] Converting adjacency matrix to networkx graph...\n",
      "[INFO][2023-10-26 00:33:33,368][dance][fit] Conversion done. Start fitting...\n",
      "[INFO][2023-10-26 00:33:34,322][dance][fit] Fitting done.\n",
      "[INFO][2023-10-26 00:33:34,326][dance][_load_raw_data] Loading expression data from /home/zyxing/data/spatial/sub_human_breast_cancer/sub_human_breast_cancer_raw_feature_bc_matrix.h5\n",
      "[INFO][2023-10-26 00:33:34,337][dance][_load_raw_data] Loading spatial info from /home/zyxing/data/spatial/sub_human_breast_cancer/tissue_positions_list.txt\n",
      "[INFO][2023-10-26 00:33:34,344][dance][_load_raw_data] Loading label info from /home/zyxing/data/spatial/sub_human_breast_cancer/cluster_labels.csv\n",
      "[INFO][2023-10-26 00:33:34,351][dance][_load_raw_data] Loading image data from /home/zyxing/data/spatial/sub_human_breast_cancer/sub_human_breast_cancer_full_image.tif\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4245974721439729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-26 00:33:46,541][dance][load_data] Raw data loaded:\n",
      "Data object that wraps (.data):\n",
      "AnnData object with n_obs × n_vars = 2000 × 313\n",
      "    obs: '0', 'ground_truth', 'label'\n",
      "    uns: 'image', 'dance_config'\n",
      "    obsm: 'spatial', 'spatial_pixel'\n",
      "[INFO][2023-10-26 00:33:46,543][dance.Compose][__call__] Applying composed transformations:\n",
      "Compose(\n",
      "  FilterGenesMatch(prefixes=['ERCC', 'MT-'], suffixes=[]),\n",
      "  AnnDataTransform(func=scanpy.preprocessing._normalization.normalize_total, func_kwargs={'target_sum': 10000.0}),\n",
      "  AnnDataTransform(func=scanpy.preprocessing._simple.scale, func_kwargs={}),\n",
      "  CellPCA(n_components=30),\n",
      "  NeighborGraph(n_neighbors=17, n_pcs=None, knn=True, random_state=0, method='umap', metric='euclidean'),\n",
      "  SetConfig(config_dict={'feature_channel': 'NeighborGraph', 'feature_channel_type': 'obsp', 'label_channel': 'label', 'label_channel_type': 'obs'}),\n",
      ")\n",
      "[INFO][2023-10-26 00:33:46,544][dance.FilterGenesMatch][__call__] 0 number of genes will be removed due to prefix 'ERCC'\n",
      "[INFO][2023-10-26 00:33:46,544][dance.FilterGenesMatch][__call__] 0 number of genes will be removed due to prefix 'MT-'\n",
      "[INFO][2023-10-26 00:33:46,545][dance.FilterGenesMatch][__call__] Removing 0 genes in total\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:197: UserWarning: Some cells have zero counts\n",
      "  warn(UserWarning('Some cells have zero counts'))\n",
      "[INFO][2023-10-26 00:33:48,040][dance.CellPCA][__call__] Start generating cell PCA features (2000, 313) (k=30)\n",
      "[INFO][2023-10-26 00:33:48,055][dance.CellPCA][__call__] Top 10 explained variances: [0.05675166 0.0298374  0.02052803 0.01735525 0.01562706 0.01113057\n",
      " 0.0099794  0.00946123 0.00907395 0.00890572]\n",
      "[INFO][2023-10-26 00:33:48,056][dance.CellPCA][__call__] Total explained variance: 32.84%\n",
      "[INFO][2023-10-26 00:33:48,056][dance.NeighborGraph][__call__] Start computing the kNN connectivity adjacency matrix\n",
      "[INFO][2023-10-26 00:33:49,758][dance.SetConfig][__call__] Updating the dance data object config options:\n",
      "{'feature_channel': 'NeighborGraph',\n",
      " 'feature_channel_type': 'obsp',\n",
      " 'label_channel': 'label',\n",
      " 'label_channel_type': 'obs'}\n",
      "[INFO][2023-10-26 00:33:49,759][dance][set_config_from_dict] Setting config 'feature_channel' to 'NeighborGraph'\n",
      "[INFO][2023-10-26 00:33:49,760][dance][set_config_from_dict] Setting config 'feature_channel_type' to 'obsp'\n",
      "[INFO][2023-10-26 00:33:49,761][dance][set_config_from_dict] Setting config 'label_channel' to 'label'\n",
      "[INFO][2023-10-26 00:33:49,762][dance][set_config_from_dict] Setting config 'label_channel_type' to 'obs'\n",
      "[INFO][2023-10-26 00:33:49,764][dance][load_data] Data transformed:\n",
      "Data object that wraps (.data):\n",
      "AnnData object with n_obs × n_vars = 2000 × 313\n",
      "    obs: '0', 'ground_truth', 'label'\n",
      "    var: 'mean', 'std'\n",
      "    uns: 'image', 'dance_config'\n",
      "    obsm: 'spatial', 'spatial_pixel', 'CellPCA'\n",
      "    obsp: 'NeighborGraph'\n",
      "[INFO][2023-10-26 00:33:49,765][dance][wrapped_func] Took 0:00:15.439954 to load and process data.\n",
      "[INFO][2023-10-26 00:33:49,777][dance][fit] Converting adjacency matrix to networkx graph...\n",
      "[INFO][2023-10-26 00:33:50,650][dance][fit] Conversion done. Start fitting...\n",
      "[INFO][2023-10-26 00:33:51,486][dance][fit] Fitting done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5051484277373146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' To reproduce louvain on other samples, please refer to command lines belows:\\nNOTE: you have to run multiple times to get best performance.\\n\\nhuman dorsolateral prefrontal cortex sample 151673:\\npython louvain.py --sample_number=151673 --seed=5\\n# 0.305\\n\\nhuman dorsolateral prefrontal cortex sample 151676:\\npython louvain.py --sample_number=151676 --seed=203\\n# 0.288\\n\\nhuman dorsolateral prefrontal cortex sample 151507:\\npython louvain.py --sample_number=151507 --seed=10\\n# 0.285\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "from dance.datasets.spatial import SpatialLIBDDataset\n",
    "from dance.modules.spatial.spatial_domain.louvain import Louvain\n",
    "from dance.transforms.preprocess import set_seed\n",
    "\n",
    "Louvain_scores=[]\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--cache\", action=\"store_true\", help=\"Cache processed data.\")\n",
    "parser.add_argument(\"--sample_number\", type=str, default=\"151673\",\n",
    "                    help=\"12 human dorsolateral prefrontal cortex datasets for the spatial domain task.\")\n",
    "parser.add_argument(\"--seed\", type=int, default=202, help=\"Random seed.\")\n",
    "parser.add_argument(\"--n_components\", type=int, default=50, help=\"Number of PC components.\")\n",
    "parser.add_argument(\"--neighbors\", type=int, default=17, help=\"Number of neighbors.\")\n",
    "for dataset in datasets:\n",
    "    try:\n",
    "        args = parser.parse_args(['--sample_number',dataset, '--seed','5',\"--n_components\",\"30\"])\n",
    "        set_seed(args.seed)\n",
    "\n",
    "        # Initialize model and get model specific preprocessing pipeline\n",
    "        model = Louvain(resolution=1)\n",
    "        preprocessing_pipeline = model.preprocessing_pipeline(dim=args.n_components, n_neighbors=args.neighbors)\n",
    "\n",
    "        # Load data and perform necessary preprocessing\n",
    "        dataloader = SpatialLIBDDataset(data_id=args.sample_number,data_dir=\"/home/zyxing/data/spatial\")\n",
    "        data = dataloader.load_data(transform=preprocessing_pipeline, cache=args.cache)\n",
    "        adj, y = data.get_data(return_type=\"default\")\n",
    "\n",
    "        # Train and evaluate model\n",
    "        model = Louvain(resolution=1)\n",
    "        score = model.fit_score(adj, y.values.ravel())\n",
    "    except Exception as e:\n",
    "        score=e\n",
    "    finally:\n",
    "        print(score)\n",
    "        Louvain_scores.append(score)\n",
    "\"\"\" To reproduce louvain on other samples, please refer to command lines belows:\n",
    "NOTE: you have to run multiple times to get best performance.\n",
    "\n",
    "human dorsolateral prefrontal cortex sample 151673:\n",
    "python louvain.py --sample_number=151673 --seed=5\n",
    "# 0.305\n",
    "\n",
    "human dorsolateral prefrontal cortex sample 151676:\n",
    "python louvain.py --sample_number=151676 --seed=203\n",
    "# 0.288\n",
    "\n",
    "human dorsolateral prefrontal cortex sample 151507:\n",
    "python louvain.py --sample_number=151507 --seed=10\n",
    "# 0.285\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4245974721439729, 0.5051484277373146]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Louvain_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-26 00:33:51,526][dance][set_seed] Setting global random seed to 100\n",
      "[INFO][2023-10-26 00:33:51,529][dance][_load_raw_data] Loading expression data from /home/zyxing/data/spatial/sub_pancreatic_cancer/sub_pancreatic_cancer_raw_feature_bc_matrix.h5\n",
      "[INFO][2023-10-26 00:33:51,552][dance][_load_raw_data] Loading spatial info from /home/zyxing/data/spatial/sub_pancreatic_cancer/tissue_positions_list.txt\n",
      "[INFO][2023-10-26 00:33:51,561][dance][_load_raw_data] Loading label info from /home/zyxing/data/spatial/sub_pancreatic_cancer/cluster_labels.csv\n",
      "[INFO][2023-10-26 00:33:51,569][dance][_load_raw_data] Loading image data from /home/zyxing/data/spatial/sub_pancreatic_cancer/sub_pancreatic_cancer_full_image.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-26 00:34:00,579][dance][load_data] Raw data loaded:\n",
      "Data object that wraps (.data):\n",
      "AnnData object with n_obs × n_vars = 2000 × 474\n",
      "    obs: '0', 'ground_truth', 'label'\n",
      "    var: 'gene_ids', 'feature_types', 'genome'\n",
      "    uns: 'image', 'dance_config'\n",
      "    obsm: 'spatial', 'spatial_pixel'\n",
      "[INFO][2023-10-26 00:34:00,580][dance.Compose][__call__] Applying composed transformations:\n",
      "Compose(\n",
      "  FilterGenesMatch(prefixes=['ERCC', 'MT-'], suffixes=[]),\n",
      "  AnnDataTransform(func=scanpy.preprocessing._normalization.normalize_total, func_kwargs={'target_sum': 10000.0}),\n",
      "  AnnDataTransform(func=scanpy.preprocessing._simple.log1p, func_kwargs={}),\n",
      "  SpaGCNGraph(alpha=500, beta=500),\n",
      "  SpaGCNGraph2D(),\n",
      "  CellPCA(n_components=50),\n",
      "  SetConfig(config_dict={'feature_channel': ['CellPCA', 'SpaGCNGraph', 'SpaGCNGraph2D'], 'feature_channel_type': ['obsm', 'obsp', 'obsp'], 'label_channel': 'label', 'label_channel_type': 'obs'}),\n",
      ")\n",
      "[INFO][2023-10-26 00:34:00,582][dance.FilterGenesMatch][__call__] 0 number of genes will be removed due to prefix 'ERCC'\n",
      "[INFO][2023-10-26 00:34:00,582][dance.FilterGenesMatch][__call__] 0 number of genes will be removed due to prefix 'MT-'\n",
      "[INFO][2023-10-26 00:34:00,583][dance.FilterGenesMatch][__call__] Removing 0 genes in total\n",
      "[INFO][2023-10-26 00:34:01,694][dance.SpaGCNGraph][__call__] Start calculating the adjacency matrix using the histology image\n",
      "[INFO][2023-10-26 00:34:10,445][dance.SpaGCNGraph][__call__] Variances of c0, c1, c2 = [29347.91111284 29347.91111284 29347.91111284]\n",
      "[INFO][2023-10-26 00:34:10,447][dance.SpaGCNGraph][__call__] Varirances of x, y, z = [4.5727125e+04 3.7172295e+06 9.2930743e+11]\n",
      "[INFO][2023-10-26 00:34:10,453][dance.CellPCA][__call__] Start generating cell PCA features (2000, 474) (k=50)\n",
      "[INFO][2023-10-26 00:34:10,478][dance.CellPCA][__call__] Top 10 explained variances: [0.09418727 0.04080046 0.02711154 0.01931883 0.01478043 0.01045991\n",
      " 0.00933927 0.00883399 0.0084794  0.00797781]\n",
      "[INFO][2023-10-26 00:34:10,479][dance.CellPCA][__call__] Total explained variance: 48.92%\n",
      "[INFO][2023-10-26 00:34:10,479][dance.SetConfig][__call__] Updating the dance data object config options:\n",
      "{'feature_channel': ['CellPCA', 'SpaGCNGraph', 'SpaGCNGraph2D'],\n",
      " 'feature_channel_type': ['obsm', 'obsp', 'obsp'],\n",
      " 'label_channel': 'label',\n",
      " 'label_channel_type': 'obs'}\n",
      "[INFO][2023-10-26 00:34:10,480][dance][set_config_from_dict] Setting config 'feature_channel' to ['CellPCA', 'SpaGCNGraph', 'SpaGCNGraph2D']\n",
      "[INFO][2023-10-26 00:34:10,480][dance][set_config_from_dict] Setting config 'feature_channel_type' to ['obsm', 'obsp', 'obsp']\n",
      "[INFO][2023-10-26 00:34:10,481][dance][set_config_from_dict] Setting config 'label_channel' to 'label'\n",
      "[INFO][2023-10-26 00:34:10,481][dance][set_config_from_dict] Setting config 'label_channel_type' to 'obs'\n",
      "[INFO][2023-10-26 00:34:10,482][dance][load_data] Data transformed:\n",
      "Data object that wraps (.data):\n",
      "AnnData object with n_obs × n_vars = 2000 × 474\n",
      "    obs: '0', 'ground_truth', 'label'\n",
      "    var: 'gene_ids', 'feature_types', 'genome'\n",
      "    uns: 'image', 'dance_config', 'log1p'\n",
      "    obsm: 'spatial', 'spatial_pixel', 'CellPCA'\n",
      "    obsp: 'SpaGCNGraph', 'SpaGCNGraph2D'\n",
      "[INFO][2023-10-26 00:34:10,482][dance][wrapped_func] Took 0:00:18.953981 to load and process data.\n",
      "[INFO][2023-10-26 00:34:10,592][dance][search_l] Run 1: l [0.01, 1000], p [0.0, 0.9907824111854271]\n",
      "[INFO][2023-10-26 00:34:10,602][dance][search_l] Run 2: l [0.01, 500.005], p [0.0, 0.34092676639556885]\n",
      "[INFO][2023-10-26 00:34:10,611][dance][search_l] Run 3: l [0.01, 250.0075], p [0.0, 0.10906744003295898]\n",
      "[INFO][2023-10-26 00:34:10,619][dance][search_l] Run 4: l [125.00874999999999, 250.0075], p [0.038611531257629395, 0.10906744003295898]\n",
      "[INFO][2023-10-26 00:34:10,628][dance][search_l] Run 5: l [125.00874999999999, 187.508125], p [0.038611531257629395, 0.06985199451446533]\n",
      "[INFO][2023-10-26 00:34:10,636][dance][search_l] recommended l: 156.2584375\n",
      "[INFO][2023-10-26 00:34:10,637][dance][search_set_res] Start at res = 0.4000, step = 0.1000\n",
      "[INFO][2023-10-26 00:34:10,646][dance][fit] Initializing cluster centers with louvain, resolution = 0.4\n",
      "[INFO][2023-10-26 00:34:11,193][dance][fit] Epoch 0\n",
      "[INFO][2023-10-26 00:34:11,218][dance][fit] Epoch 10\n",
      "[INFO][2023-10-26 00:34:11,240][dance][fit] Epoch 20\n",
      "[INFO][2023-10-26 00:34:11,263][dance][fit] Epoch 30\n",
      "[INFO][2023-10-26 00:34:11,287][dance][fit] Epoch 40\n",
      "[INFO][2023-10-26 00:34:11,312][dance][fit] Epoch 50\n",
      "[INFO][2023-10-26 00:34:11,338][dance][fit] Epoch 60\n",
      "[INFO][2023-10-26 00:34:11,369][dance][fit] Epoch 70\n",
      "[INFO][2023-10-26 00:34:11,399][dance][fit] Epoch 80\n",
      "[INFO][2023-10-26 00:34:11,428][dance][fit] Epoch 90\n",
      "[INFO][2023-10-26 00:34:11,458][dance][fit] Epoch 100\n",
      "[INFO][2023-10-26 00:34:11,488][dance][fit] Epoch 110\n",
      "[INFO][2023-10-26 00:34:11,519][dance][fit] Epoch 120\n",
      "[INFO][2023-10-26 00:34:11,551][dance][fit] Epoch 130\n",
      "[INFO][2023-10-26 00:34:11,583][dance][fit] Epoch 140\n",
      "[INFO][2023-10-26 00:34:11,616][dance][fit] Epoch 150\n",
      "[INFO][2023-10-26 00:34:11,649][dance][fit] Epoch 160\n",
      "[INFO][2023-10-26 00:34:11,681][dance][fit] Epoch 170\n",
      "[INFO][2023-10-26 00:34:11,715][dance][fit] Epoch 180\n",
      "[INFO][2023-10-26 00:34:11,747][dance][fit] Epoch 190\n",
      "[INFO][2023-10-26 00:34:11,799][dance][search_set_res] Res = 0.4000, Num of clusters = 4\n",
      "[INFO][2023-10-26 00:34:11,812][dance][fit] Initializing cluster centers with louvain, resolution = 0.5\n",
      "[INFO][2023-10-26 00:34:12,385][dance][fit] Epoch 0\n",
      "[INFO][2023-10-26 00:34:12,409][dance][fit] Epoch 10\n",
      "[INFO][2023-10-26 00:34:12,430][dance][fit] Epoch 20\n",
      "[INFO][2023-10-26 00:34:12,454][dance][fit] Epoch 30\n",
      "[INFO][2023-10-26 00:34:12,477][dance][fit] Epoch 40\n",
      "[INFO][2023-10-26 00:34:12,502][dance][fit] Epoch 50\n",
      "[INFO][2023-10-26 00:34:12,528][dance][fit] Epoch 60\n",
      "[INFO][2023-10-26 00:34:12,557][dance][fit] Epoch 70\n",
      "[INFO][2023-10-26 00:34:12,588][dance][fit] Epoch 80\n",
      "[INFO][2023-10-26 00:34:12,618][dance][fit] Epoch 90\n",
      "[INFO][2023-10-26 00:34:12,648][dance][fit] Epoch 100\n",
      "[INFO][2023-10-26 00:34:12,679][dance][fit] Epoch 110\n",
      "[INFO][2023-10-26 00:34:12,711][dance][fit] Epoch 120\n",
      "[INFO][2023-10-26 00:34:12,744][dance][fit] Epoch 130\n",
      "[INFO][2023-10-26 00:34:12,776][dance][fit] Epoch 140\n",
      "[INFO][2023-10-26 00:34:12,812][dance][fit] Epoch 150\n",
      "[INFO][2023-10-26 00:34:12,848][dance][fit] Epoch 160\n",
      "[INFO][2023-10-26 00:34:12,884][dance][fit] Epoch 170\n",
      "[INFO][2023-10-26 00:34:12,921][dance][fit] Epoch 180\n",
      "[INFO][2023-10-26 00:34:12,957][dance][fit] Epoch 190\n",
      "[INFO][2023-10-26 00:34:13,015][dance][search_set_res] Res = 5.000e-01, Num of clusters = 4\n",
      "[INFO][2023-10-26 00:34:13,017][dance][search_set_res] Res changed to 0.5\n",
      "[INFO][2023-10-26 00:34:13,028][dance][fit] Initializing cluster centers with louvain, resolution = 0.6\n",
      "[INFO][2023-10-26 00:34:13,559][dance][fit] Epoch 0\n",
      "[INFO][2023-10-26 00:34:13,583][dance][fit] Epoch 10\n",
      "[INFO][2023-10-26 00:34:13,606][dance][fit] Epoch 20\n",
      "[INFO][2023-10-26 00:34:13,633][dance][fit] Epoch 30\n",
      "[INFO][2023-10-26 00:34:13,655][dance][fit] Epoch 40\n",
      "[INFO][2023-10-26 00:34:13,681][dance][fit] Epoch 50\n",
      "[INFO][2023-10-26 00:34:13,707][dance][fit] Epoch 60\n",
      "[INFO][2023-10-26 00:34:13,734][dance][fit] Epoch 70\n",
      "[INFO][2023-10-26 00:34:13,761][dance][fit] Epoch 80\n",
      "[INFO][2023-10-26 00:34:13,791][dance][fit] Epoch 90\n",
      "[INFO][2023-10-26 00:34:13,818][dance][fit] Epoch 100\n",
      "[INFO][2023-10-26 00:34:13,850][dance][fit] Epoch 110\n",
      "[INFO][2023-10-26 00:34:13,881][dance][fit] Epoch 120\n",
      "[INFO][2023-10-26 00:34:13,913][dance][fit] Epoch 130\n",
      "[INFO][2023-10-26 00:34:13,946][dance][fit] Epoch 140\n",
      "[INFO][2023-10-26 00:34:13,979][dance][fit] Epoch 150\n",
      "[INFO][2023-10-26 00:34:14,013][dance][fit] Epoch 160\n",
      "[INFO][2023-10-26 00:34:14,047][dance][fit] Epoch 170\n",
      "[INFO][2023-10-26 00:34:14,082][dance][fit] Epoch 180\n",
      "[INFO][2023-10-26 00:34:14,116][dance][fit] Epoch 190\n",
      "[INFO][2023-10-26 00:34:14,171][dance][search_set_res] Res = 6.000e-01, Num of clusters = 6\n",
      "[INFO][2023-10-26 00:34:14,172][dance][search_set_res] Res changed to 0.6\n",
      "[INFO][2023-10-26 00:34:14,182][dance][fit] Initializing cluster centers with louvain, resolution = 0.7\n",
      "[INFO][2023-10-26 00:34:14,849][dance][fit] Epoch 0\n",
      "[INFO][2023-10-26 00:34:14,874][dance][fit] Epoch 10\n",
      "[INFO][2023-10-26 00:34:14,893][dance][fit] Epoch 20\n",
      "[INFO][2023-10-26 00:34:14,912][dance][fit] Epoch 30\n",
      "[INFO][2023-10-26 00:34:14,931][dance][fit] Epoch 40\n",
      "[INFO][2023-10-26 00:34:14,951][dance][fit] Epoch 50\n",
      "[INFO][2023-10-26 00:34:14,971][dance][fit] Epoch 60\n",
      "[INFO][2023-10-26 00:34:14,991][dance][fit] Epoch 70\n",
      "[INFO][2023-10-26 00:34:15,011][dance][fit] Epoch 80\n",
      "[INFO][2023-10-26 00:34:15,033][dance][fit] Epoch 90\n",
      "[INFO][2023-10-26 00:34:15,055][dance][fit] Epoch 100\n",
      "[INFO][2023-10-26 00:34:15,078][dance][fit] Epoch 110\n",
      "[INFO][2023-10-26 00:34:15,104][dance][fit] Epoch 120\n",
      "[INFO][2023-10-26 00:34:15,131][dance][fit] Epoch 130\n",
      "[INFO][2023-10-26 00:34:15,160][dance][fit] Epoch 140\n",
      "[INFO][2023-10-26 00:34:15,190][dance][fit] Epoch 150\n",
      "[INFO][2023-10-26 00:34:15,220][dance][fit] Epoch 160\n",
      "[INFO][2023-10-26 00:34:15,248][dance][fit] Epoch 170\n",
      "[INFO][2023-10-26 00:34:15,280][dance][fit] Epoch 180\n",
      "[INFO][2023-10-26 00:34:15,311][dance][fit] Epoch 190\n",
      "[INFO][2023-10-26 00:34:15,360][dance][search_set_res] Res = 7.000e-01, Num of clusters = 5\n",
      "[INFO][2023-10-26 00:34:15,361][dance][search_set_res] Res changed to 0.7\n",
      "[INFO][2023-10-26 00:34:15,371][dance][fit] Initializing cluster centers with louvain, resolution = 0.7999999999999999\n",
      "[INFO][2023-10-26 00:34:16,094][dance][fit] Epoch 0\n",
      "[INFO][2023-10-26 00:34:16,118][dance][fit] Epoch 10\n",
      "[INFO][2023-10-26 00:34:16,141][dance][fit] Epoch 20\n",
      "[INFO][2023-10-26 00:34:16,165][dance][fit] Epoch 30\n",
      "[INFO][2023-10-26 00:34:16,189][dance][fit] Epoch 40\n",
      "[INFO][2023-10-26 00:34:16,213][dance][fit] Epoch 50\n",
      "[INFO][2023-10-26 00:34:16,240][dance][fit] Epoch 60\n",
      "[INFO][2023-10-26 00:34:16,268][dance][fit] Epoch 70\n",
      "[INFO][2023-10-26 00:34:16,296][dance][fit] Epoch 80\n",
      "[INFO][2023-10-26 00:34:16,326][dance][fit] Epoch 90\n",
      "[INFO][2023-10-26 00:34:16,356][dance][fit] Epoch 100\n",
      "[INFO][2023-10-26 00:34:16,390][dance][fit] Epoch 110\n",
      "[INFO][2023-10-26 00:34:16,424][dance][fit] Epoch 120\n",
      "[INFO][2023-10-26 00:34:16,460][dance][fit] Epoch 130\n",
      "[INFO][2023-10-26 00:34:16,495][dance][fit] Epoch 140\n",
      "[INFO][2023-10-26 00:34:16,530][dance][fit] Epoch 150\n",
      "[INFO][2023-10-26 00:34:16,565][dance][fit] Epoch 160\n",
      "[INFO][2023-10-26 00:34:16,600][dance][fit] Epoch 170\n",
      "[INFO][2023-10-26 00:34:16,635][dance][fit] Epoch 180\n",
      "[INFO][2023-10-26 00:34:16,669][dance][fit] Epoch 190\n",
      "[INFO][2023-10-26 00:34:16,727][dance][search_set_res] Res = 8.000e-01, Num of clusters = 6\n",
      "[INFO][2023-10-26 00:34:16,728][dance][search_set_res] Res changed to 0.7999999999999999\n",
      "[INFO][2023-10-26 00:34:16,739][dance][fit] Initializing cluster centers with louvain, resolution = 0.8999999999999999\n",
      "[INFO][2023-10-26 00:34:17,428][dance][fit] Epoch 0\n",
      "[INFO][2023-10-26 00:34:17,453][dance][fit] Epoch 10\n",
      "[INFO][2023-10-26 00:34:17,478][dance][fit] Epoch 20\n",
      "[INFO][2023-10-26 00:34:17,504][dance][fit] Epoch 30\n",
      "[INFO][2023-10-26 00:34:17,527][dance][fit] Epoch 40\n",
      "[INFO][2023-10-26 00:34:17,551][dance][fit] Epoch 50\n",
      "[INFO][2023-10-26 00:34:17,575][dance][fit] Epoch 60\n",
      "[INFO][2023-10-26 00:34:17,602][dance][fit] Epoch 70\n",
      "[INFO][2023-10-26 00:34:17,627][dance][fit] Epoch 80\n",
      "[INFO][2023-10-26 00:34:17,654][dance][fit] Epoch 90\n",
      "[INFO][2023-10-26 00:34:17,682][dance][fit] Epoch 100\n",
      "[INFO][2023-10-26 00:34:17,710][dance][fit] Epoch 110\n",
      "[INFO][2023-10-26 00:34:17,741][dance][fit] Epoch 120\n",
      "[INFO][2023-10-26 00:34:17,770][dance][fit] Epoch 130\n",
      "[INFO][2023-10-26 00:34:17,800][dance][fit] Epoch 140\n",
      "[INFO][2023-10-26 00:34:17,832][dance][fit] Epoch 150\n",
      "[INFO][2023-10-26 00:34:17,864][dance][fit] Epoch 160\n",
      "[INFO][2023-10-26 00:34:17,896][dance][fit] Epoch 170\n",
      "[INFO][2023-10-26 00:34:17,929][dance][fit] Epoch 180\n",
      "[INFO][2023-10-26 00:34:17,961][dance][fit] Epoch 190\n",
      "[INFO][2023-10-26 00:34:18,010][dance][search_set_res] Res = 9.000e-01, Num of clusters = 6\n",
      "[INFO][2023-10-26 00:34:18,012][dance][search_set_res] Res changed to 0.8999999999999999\n",
      "[INFO][2023-10-26 00:34:18,021][dance][fit] Initializing cluster centers with louvain, resolution = 0.9999999999999999\n",
      "[INFO][2023-10-26 00:34:18,623][dance][fit] Epoch 0\n",
      "[INFO][2023-10-26 00:34:18,649][dance][fit] Epoch 10\n",
      "[INFO][2023-10-26 00:34:18,672][dance][fit] Epoch 20\n",
      "[INFO][2023-10-26 00:34:18,696][dance][fit] Epoch 30\n",
      "[INFO][2023-10-26 00:34:18,718][dance][fit] Epoch 40\n",
      "[INFO][2023-10-26 00:34:18,746][dance][fit] Epoch 50\n",
      "[INFO][2023-10-26 00:34:18,770][dance][fit] Epoch 60\n",
      "[INFO][2023-10-26 00:34:18,797][dance][fit] Epoch 70\n",
      "[INFO][2023-10-26 00:34:18,821][dance][fit] Epoch 80\n",
      "[INFO][2023-10-26 00:34:18,850][dance][fit] Epoch 90\n",
      "[INFO][2023-10-26 00:34:18,877][dance][fit] Epoch 100\n",
      "[INFO][2023-10-26 00:34:18,903][dance][fit] Epoch 110\n",
      "[INFO][2023-10-26 00:34:18,932][dance][fit] Epoch 120\n",
      "[INFO][2023-10-26 00:34:18,961][dance][fit] Epoch 130\n",
      "[INFO][2023-10-26 00:34:18,992][dance][fit] Epoch 140\n",
      "[INFO][2023-10-26 00:34:19,024][dance][fit] Epoch 150\n",
      "[INFO][2023-10-26 00:34:19,057][dance][fit] Epoch 160\n",
      "[INFO][2023-10-26 00:34:19,090][dance][fit] Epoch 170\n",
      "[INFO][2023-10-26 00:34:19,123][dance][fit] Epoch 180\n",
      "[INFO][2023-10-26 00:34:19,157][dance][fit] Epoch 190\n",
      "[INFO][2023-10-26 00:34:19,208][dance][search_set_res] Res = 1.000e+00, Num of clusters = 7\n",
      "[INFO][2023-10-26 00:34:19,215][dance][search_set_res] recommended res = 1.0000\n",
      "[INFO][2023-10-26 00:34:19,226][dance][fit] Initializing cluster centers with louvain, resolution = 0.9999999999999999\n",
      "[INFO][2023-10-26 00:34:19,875][dance][fit] Epoch 0\n",
      "[INFO][2023-10-26 00:34:19,899][dance][fit] Epoch 10\n",
      "[INFO][2023-10-26 00:34:19,917][dance][fit] Epoch 20\n",
      "[INFO][2023-10-26 00:34:19,935][dance][fit] Epoch 30\n",
      "[INFO][2023-10-26 00:34:19,951][dance][fit] Epoch 40\n",
      "[INFO][2023-10-26 00:34:19,969][dance][fit] Epoch 50\n",
      "[INFO][2023-10-26 00:34:19,987][dance][fit] Epoch 60\n",
      "[INFO][2023-10-26 00:34:20,004][dance][fit] Epoch 70\n",
      "[INFO][2023-10-26 00:34:20,023][dance][fit] Epoch 80\n",
      "[INFO][2023-10-26 00:34:20,042][dance][fit] Epoch 90\n",
      "[INFO][2023-10-26 00:34:20,062][dance][fit] Epoch 100\n",
      "[INFO][2023-10-26 00:34:20,082][dance][fit] Epoch 110\n",
      "[INFO][2023-10-26 00:34:20,104][dance][fit] Epoch 120\n",
      "[INFO][2023-10-26 00:34:20,128][dance][fit] Epoch 130\n",
      "[INFO][2023-10-26 00:34:20,153][dance][fit] Epoch 140\n",
      "[INFO][2023-10-26 00:34:20,180][dance][fit] Epoch 150\n",
      "[INFO][2023-10-26 00:34:20,209][dance][fit] Epoch 160\n",
      "[INFO][2023-10-26 00:34:20,239][dance][fit] Epoch 170\n",
      "[INFO][2023-10-26 00:34:20,269][dance][fit] Epoch 180\n",
      "[INFO][2023-10-26 00:34:20,300][dance][fit] Epoch 190\n",
      "[INFO][2023-10-26 00:34:21,901][dance][set_seed] Setting global random seed to 100\n",
      "[INFO][2023-10-26 00:34:21,904][dance][_load_raw_data] Loading expression data from /home/zyxing/data/spatial/sub_human_breast_cancer/sub_human_breast_cancer_raw_feature_bc_matrix.h5\n",
      "[INFO][2023-10-26 00:34:21,919][dance][_load_raw_data] Loading spatial info from /home/zyxing/data/spatial/sub_human_breast_cancer/tissue_positions_list.txt\n",
      "[INFO][2023-10-26 00:34:21,927][dance][_load_raw_data] Loading label info from /home/zyxing/data/spatial/sub_human_breast_cancer/cluster_labels.csv\n",
      "[INFO][2023-10-26 00:34:21,934][dance][_load_raw_data] Loading image data from /home/zyxing/data/spatial/sub_human_breast_cancer/sub_human_breast_cancer_full_image.tif\n",
      "[INFO][2023-10-26 00:34:34,399][dance][load_data] Raw data loaded:\n",
      "Data object that wraps (.data):\n",
      "AnnData object with n_obs × n_vars = 2000 × 313\n",
      "    obs: '0', 'ground_truth', 'label'\n",
      "    uns: 'image', 'dance_config'\n",
      "    obsm: 'spatial', 'spatial_pixel'\n",
      "[INFO][2023-10-26 00:34:34,401][dance.Compose][__call__] Applying composed transformations:\n",
      "Compose(\n",
      "  FilterGenesMatch(prefixes=['ERCC', 'MT-'], suffixes=[]),\n",
      "  AnnDataTransform(func=scanpy.preprocessing._normalization.normalize_total, func_kwargs={'target_sum': 10000.0}),\n",
      "  AnnDataTransform(func=scanpy.preprocessing._simple.log1p, func_kwargs={}),\n",
      "  SpaGCNGraph(alpha=500, beta=500),\n",
      "  SpaGCNGraph2D(),\n",
      "  CellPCA(n_components=50),\n",
      "  SetConfig(config_dict={'feature_channel': ['CellPCA', 'SpaGCNGraph', 'SpaGCNGraph2D'], 'feature_channel_type': ['obsm', 'obsp', 'obsp'], 'label_channel': 'label', 'label_channel_type': 'obs'}),\n",
      ")\n",
      "[INFO][2023-10-26 00:34:34,402][dance.FilterGenesMatch][__call__] 0 number of genes will be removed due to prefix 'ERCC'\n",
      "[INFO][2023-10-26 00:34:34,403][dance.FilterGenesMatch][__call__] 0 number of genes will be removed due to prefix 'MT-'\n",
      "[INFO][2023-10-26 00:34:34,403][dance.FilterGenesMatch][__call__] Removing 0 genes in total\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:197: UserWarning: Some cells have zero counts\n",
      "  warn(UserWarning('Some cells have zero counts'))\n",
      "[INFO][2023-10-26 00:34:35,939][dance.SpaGCNGraph][__call__] Start calculating the adjacency matrix using the histology image\n",
      "[INFO][2023-10-26 00:34:43,980][dance.SpaGCNGraph][__call__] Variances of c0, c1, c2 = [15513.50276623 15513.50276623 15513.50276623]\n",
      "[INFO][2023-10-26 00:34:43,983][dance.SpaGCNGraph][__call__] Varirances of x, y, z = [1.0344000e+06 1.2252313e+05 2.5860001e+11]\n",
      "[INFO][2023-10-26 00:34:43,991][dance.CellPCA][__call__] Start generating cell PCA features (2000, 313) (k=50)\n",
      "[INFO][2023-10-26 00:34:44,012][dance.CellPCA][__call__] Top 10 explained variances: [0.16653208 0.04777749 0.03602955 0.0227042  0.0225984  0.0160103\n",
      " 0.01251658 0.01085443 0.01011125 0.00885056]\n",
      "[INFO][2023-10-26 00:34:44,012][dance.CellPCA][__call__] Total explained variance: 58.06%\n",
      "[INFO][2023-10-26 00:34:44,013][dance.SetConfig][__call__] Updating the dance data object config options:\n",
      "{'feature_channel': ['CellPCA', 'SpaGCNGraph', 'SpaGCNGraph2D'],\n",
      " 'feature_channel_type': ['obsm', 'obsp', 'obsp'],\n",
      " 'label_channel': 'label',\n",
      " 'label_channel_type': 'obs'}\n",
      "[INFO][2023-10-26 00:34:44,013][dance][set_config_from_dict] Setting config 'feature_channel' to ['CellPCA', 'SpaGCNGraph', 'SpaGCNGraph2D']\n",
      "[INFO][2023-10-26 00:34:44,014][dance][set_config_from_dict] Setting config 'feature_channel_type' to ['obsm', 'obsp', 'obsp']\n",
      "[INFO][2023-10-26 00:34:44,014][dance][set_config_from_dict] Setting config 'label_channel' to 'label'\n",
      "[INFO][2023-10-26 00:34:44,014][dance][set_config_from_dict] Setting config 'label_channel_type' to 'obs'\n",
      "[INFO][2023-10-26 00:34:44,015][dance][load_data] Data transformed:\n",
      "Data object that wraps (.data):\n",
      "AnnData object with n_obs × n_vars = 2000 × 313\n",
      "    obs: '0', 'ground_truth', 'label'\n",
      "    uns: 'image', 'dance_config', 'log1p'\n",
      "    obsm: 'spatial', 'spatial_pixel', 'CellPCA'\n",
      "    obsp: 'SpaGCNGraph', 'SpaGCNGraph2D'\n",
      "[INFO][2023-10-26 00:34:44,015][dance][wrapped_func] Took 0:00:22.111914 to load and process data.\n",
      "[INFO][2023-10-26 00:34:44,140][dance][search_l] Run 1: l [0.01, 1000], p [0.0, 1.3976740009822097]\n",
      "[INFO][2023-10-26 00:34:44,150][dance][search_l] Run 2: l [0.01, 500.005], p [0.0, 0.3722454309463501]\n",
      "[INFO][2023-10-26 00:34:44,160][dance][search_l] Run 3: l [0.01, 250.0075], p [0.0, 0.10846114158630371]\n",
      "[INFO][2023-10-26 00:34:44,170][dance][search_l] Run 4: l [125.00874999999999, 250.0075], p [0.038364291191101074, 0.10846114158630371]\n",
      "[INFO][2023-10-26 00:34:44,181][dance][search_l] Run 5: l [125.00874999999999, 187.508125], p [0.038364291191101074, 0.06994962692260742]\n",
      "[INFO][2023-10-26 00:34:44,191][dance][search_l] recommended l: 156.2584375\n",
      "[INFO][2023-10-26 00:34:44,192][dance][search_set_res] Start at res = 0.4000, step = 0.1000\n",
      "[INFO][2023-10-26 00:34:44,201][dance][fit] Initializing cluster centers with louvain, resolution = 0.4\n",
      "[INFO][2023-10-26 00:34:44,818][dance][fit] Epoch 0\n",
      "[INFO][2023-10-26 00:34:44,843][dance][fit] Epoch 10\n",
      "[INFO][2023-10-26 00:34:44,866][dance][fit] Epoch 20\n",
      "[INFO][2023-10-26 00:34:44,891][dance][fit] Epoch 30\n",
      "[INFO][2023-10-26 00:34:44,918][dance][fit] Epoch 40\n",
      "[INFO][2023-10-26 00:34:44,944][dance][fit] Epoch 50\n",
      "[INFO][2023-10-26 00:34:44,972][dance][fit] Epoch 60\n",
      "[INFO][2023-10-26 00:34:45,000][dance][fit] Epoch 70\n",
      "[INFO][2023-10-26 00:34:45,029][dance][fit] Epoch 80\n",
      "[INFO][2023-10-26 00:34:45,060][dance][fit] Epoch 90\n",
      "[INFO][2023-10-26 00:34:45,090][dance][fit] Epoch 100\n",
      "[INFO][2023-10-26 00:34:45,121][dance][fit] Epoch 110\n",
      "[INFO][2023-10-26 00:34:45,153][dance][fit] Epoch 120\n",
      "[INFO][2023-10-26 00:34:45,184][dance][fit] Epoch 130\n",
      "[INFO][2023-10-26 00:34:45,217][dance][fit] Epoch 140\n",
      "[INFO][2023-10-26 00:34:45,250][dance][fit] Epoch 150\n",
      "[INFO][2023-10-26 00:34:45,283][dance][fit] Epoch 160\n",
      "[INFO][2023-10-26 00:34:45,316][dance][fit] Epoch 170\n",
      "[INFO][2023-10-26 00:34:45,350][dance][fit] Epoch 180\n",
      "[INFO][2023-10-26 00:34:45,384][dance][fit] Epoch 190\n",
      "[INFO][2023-10-26 00:34:45,437][dance][search_set_res] Res = 0.4000, Num of clusters = 5\n",
      "[INFO][2023-10-26 00:34:45,449][dance][fit] Initializing cluster centers with louvain, resolution = 0.5\n",
      "[INFO][2023-10-26 00:34:45,958][dance][fit] Epoch 0\n",
      "[INFO][2023-10-26 00:34:45,982][dance][fit] Epoch 10\n",
      "[INFO][2023-10-26 00:34:46,004][dance][fit] Epoch 20\n",
      "[INFO][2023-10-26 00:34:46,027][dance][fit] Epoch 30\n",
      "[INFO][2023-10-26 00:34:46,050][dance][fit] Epoch 40\n",
      "[INFO][2023-10-26 00:34:46,075][dance][fit] Epoch 50\n",
      "[INFO][2023-10-26 00:34:46,102][dance][fit] Epoch 60\n",
      "[INFO][2023-10-26 00:34:46,129][dance][fit] Epoch 70\n",
      "[INFO][2023-10-26 00:34:46,157][dance][fit] Epoch 80\n",
      "[INFO][2023-10-26 00:34:46,186][dance][fit] Epoch 90\n",
      "[INFO][2023-10-26 00:34:46,216][dance][fit] Epoch 100\n",
      "[INFO][2023-10-26 00:34:46,246][dance][fit] Epoch 110\n",
      "[INFO][2023-10-26 00:34:46,277][dance][fit] Epoch 120\n",
      "[INFO][2023-10-26 00:34:46,308][dance][fit] Epoch 130\n",
      "[INFO][2023-10-26 00:34:46,341][dance][fit] Epoch 140\n",
      "[INFO][2023-10-26 00:34:46,373][dance][fit] Epoch 150\n",
      "[INFO][2023-10-26 00:34:46,407][dance][fit] Epoch 160\n",
      "[INFO][2023-10-26 00:34:46,441][dance][fit] Epoch 170\n",
      "[INFO][2023-10-26 00:34:46,476][dance][fit] Epoch 180\n",
      "[INFO][2023-10-26 00:34:46,510][dance][fit] Epoch 190\n",
      "[INFO][2023-10-26 00:34:46,562][dance][search_set_res] Res = 5.000e-01, Num of clusters = 5\n",
      "[INFO][2023-10-26 00:34:46,563][dance][search_set_res] Res changed to 0.5\n",
      "[INFO][2023-10-26 00:34:46,576][dance][fit] Initializing cluster centers with louvain, resolution = 0.6\n",
      "[INFO][2023-10-26 00:34:47,022][dance][fit] Epoch 0\n",
      "[INFO][2023-10-26 00:34:47,047][dance][fit] Epoch 10\n",
      "[INFO][2023-10-26 00:34:47,069][dance][fit] Epoch 20\n",
      "[INFO][2023-10-26 00:34:47,093][dance][fit] Epoch 30\n",
      "[INFO][2023-10-26 00:34:47,117][dance][fit] Epoch 40\n",
      "[INFO][2023-10-26 00:34:47,141][dance][fit] Epoch 50\n",
      "[INFO][2023-10-26 00:34:47,167][dance][fit] Epoch 60\n",
      "[INFO][2023-10-26 00:34:47,195][dance][fit] Epoch 70\n",
      "[INFO][2023-10-26 00:34:47,222][dance][fit] Epoch 80\n",
      "[INFO][2023-10-26 00:34:47,252][dance][fit] Epoch 90\n",
      "[INFO][2023-10-26 00:34:47,281][dance][fit] Epoch 100\n",
      "[INFO][2023-10-26 00:34:47,310][dance][fit] Epoch 110\n",
      "[INFO][2023-10-26 00:34:47,342][dance][fit] Epoch 120\n",
      "[INFO][2023-10-26 00:34:47,373][dance][fit] Epoch 130\n",
      "[INFO][2023-10-26 00:34:47,405][dance][fit] Epoch 140\n",
      "[INFO][2023-10-26 00:34:47,437][dance][fit] Epoch 150\n",
      "[INFO][2023-10-26 00:34:47,469][dance][fit] Epoch 160\n",
      "[INFO][2023-10-26 00:34:47,502][dance][fit] Epoch 170\n",
      "[INFO][2023-10-26 00:34:47,534][dance][fit] Epoch 180\n",
      "[INFO][2023-10-26 00:34:47,567][dance][fit] Epoch 190\n",
      "[INFO][2023-10-26 00:34:47,619][dance][search_set_res] Res = 6.000e-01, Num of clusters = 7\n",
      "[INFO][2023-10-26 00:34:47,620][dance][search_set_res] recommended res = 0.6000\n",
      "[INFO][2023-10-26 00:34:47,632][dance][fit] Initializing cluster centers with louvain, resolution = 0.6\n",
      "[INFO][2023-10-26 00:34:48,130][dance][fit] Epoch 0\n",
      "[INFO][2023-10-26 00:34:48,150][dance][fit] Epoch 10\n",
      "[INFO][2023-10-26 00:34:48,169][dance][fit] Epoch 20\n",
      "[INFO][2023-10-26 00:34:48,189][dance][fit] Epoch 30\n",
      "[INFO][2023-10-26 00:34:48,211][dance][fit] Epoch 40\n",
      "[INFO][2023-10-26 00:34:48,235][dance][fit] Epoch 50\n",
      "[INFO][2023-10-26 00:34:48,261][dance][fit] Epoch 60\n",
      "[INFO][2023-10-26 00:34:48,287][dance][fit] Epoch 70\n",
      "[INFO][2023-10-26 00:34:48,314][dance][fit] Epoch 80\n",
      "[INFO][2023-10-26 00:34:48,342][dance][fit] Epoch 90\n",
      "[INFO][2023-10-26 00:34:48,371][dance][fit] Epoch 100\n",
      "[INFO][2023-10-26 00:34:48,401][dance][fit] Epoch 110\n",
      "[INFO][2023-10-26 00:34:48,432][dance][fit] Epoch 120\n",
      "[INFO][2023-10-26 00:34:48,464][dance][fit] Epoch 130\n",
      "[INFO][2023-10-26 00:34:48,495][dance][fit] Epoch 140\n",
      "[INFO][2023-10-26 00:34:48,528][dance][fit] Epoch 150\n",
      "[INFO][2023-10-26 00:34:48,560][dance][fit] Epoch 160\n",
      "[INFO][2023-10-26 00:34:48,593][dance][fit] Epoch 170\n",
      "[INFO][2023-10-26 00:34:48,627][dance][fit] Epoch 180\n",
      "[INFO][2023-10-26 00:34:48,662][dance][fit] Epoch 190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' To reproduce SpaGCN on other samples, please refer to command lines belows:\\n\\n    human dorsolateral prefrontal cortex sample 151673:\\n    python spagcn.py --sample_number=151673 --lr=0.1\\n\\n    human dorsolateral prefrontal cortex sample 151676:\\n    python spagcn.py --sample_number=151676  --lr=0.02\\n\\n    human dorsolateral prefrontal cortex sample 151507:\\n    python spagcn.py --sample_number=151507  --lr=0.009\\n    '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "from dance.datasets.spatial import SpatialLIBDDataset\n",
    "from dance.modules.spatial.spatial_domain.spagcn import SpaGCN, refine\n",
    "from dance.utils import set_seed\n",
    "\n",
    "SpaGCN_scores=[]\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--cache\", action=\"store_true\", help=\"Cache processed data.\")\n",
    "parser.add_argument(\"--sample_number\", type=str, default=\"151673\",\n",
    "                    help=\"12 human dorsolateral prefrontal cortex datasets for the spatial domain task.\")\n",
    "parser.add_argument(\"--beta\", type=int, default=500, help=\"\")\n",
    "parser.add_argument(\"--alpha\", type=int, default=500, help=\"\")\n",
    "parser.add_argument(\"--p\", type=float, default=0.05,\n",
    "                    help=\"percentage of total expression contributed by neighborhoods.\")\n",
    "parser.add_argument(\"--l\", type=float, default=0.5, help=\"the parameter to control percentage p.\")\n",
    "parser.add_argument(\"--start\", type=float, default=0.01, help=\"starting value for searching l.\")\n",
    "parser.add_argument(\"--end\", type=float, default=1000, help=\"ending value for searching l.\")\n",
    "parser.add_argument(\"--tol\", type=float, default=5e-3, help=\"tolerant value for searching l.\")\n",
    "parser.add_argument(\"--max_run\", type=int, default=200, help=\"max runs.\")\n",
    "parser.add_argument(\"--epochs\", type=int, default=200, help=\"Number of epochs.\")\n",
    "parser.add_argument(\"--n_clusters\", type=int, default=7, help=\"the number of clusters\")\n",
    "parser.add_argument(\"--step\", type=float, default=0.1, help=\"\")\n",
    "parser.add_argument(\"--lr\", type=float, default=0.05, help=\"learning rate\")\n",
    "parser.add_argument(\"--random_state\", type=int, default=100, help=\"\")\n",
    "for dataset in datasets:\n",
    "        args = parser.parse_args(['--sample_number',dataset,'--lr','0.1'])\n",
    "        set_seed(args.random_state)\n",
    "\n",
    "        # Initialize model and get model specific preprocessing pipeline\n",
    "        model = SpaGCN()\n",
    "        preprocessing_pipeline = model.preprocessing_pipeline(alpha=args.alpha, beta=args.beta)\n",
    "\n",
    "        # Load data and perform necessary preprocessing\n",
    "        dataloader = SpatialLIBDDataset(data_id=args.sample_number,data_dir=\"/home/zyxing/data/spatial\")\n",
    "        data = dataloader.load_data(transform=preprocessing_pipeline, cache=args.cache)\n",
    "        (x, adj, adj_2d), y = data.get_train_data()\n",
    "\n",
    "        # Train and evaluate model\n",
    "        l = model.search_l(args.p, adj, start=args.start, end=args.end, tol=args.tol, max_run=args.max_run)\n",
    "        model.set_l(l)\n",
    "        res = model.search_set_res((x, adj), l=l, target_num=args.n_clusters, start=0.4, step=args.step, tol=args.tol,\n",
    "                                lr=args.lr, epochs=args.epochs, max_run=args.max_run)\n",
    "\n",
    "        pred = model.fit_predict((x, adj), init_spa=True, init=\"louvain\", tol=args.tol, lr=args.lr, epochs=args.epochs,\n",
    "                                res=res,device=\"cuda\")\n",
    "        score = model.default_score_func(y, pred)\n",
    "        SpaGCN_scores.append(score)\n",
    "\n",
    "        refined_pred = refine(sample_id=data.data.obs_names.tolist(), pred=pred.tolist(), dis=adj_2d, shape=\"hexagon\")\n",
    "        score_refined = model.default_score_func(y, refined_pred)\n",
    "\"\"\" To reproduce SpaGCN on other samples, please refer to command lines belows:\n",
    "\n",
    "    human dorsolateral prefrontal cortex sample 151673:\n",
    "    python spagcn.py --sample_number=151673 --lr=0.1\n",
    "\n",
    "    human dorsolateral prefrontal cortex sample 151676:\n",
    "    python spagcn.py --sample_number=151676  --lr=0.02\n",
    "\n",
    "    human dorsolateral prefrontal cortex sample 151507:\n",
    "    python spagcn.py --sample_number=151507  --lr=0.009\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.27378139574017296, 0.559193437234145]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SpaGCN_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-26 00:34:50,943][dance][_load_raw_data] Loading expression data from /home/zyxing/data/spatial/sub_pancreatic_cancer/sub_pancreatic_cancer_raw_feature_bc_matrix.h5\n",
      "[INFO][2023-10-26 00:34:50,965][dance][_load_raw_data] Loading spatial info from /home/zyxing/data/spatial/sub_pancreatic_cancer/tissue_positions_list.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-10-26 00:34:50,973][dance][_load_raw_data] Loading label info from /home/zyxing/data/spatial/sub_pancreatic_cancer/cluster_labels.csv\n",
      "[INFO][2023-10-26 00:34:50,981][dance][_load_raw_data] Loading image data from /home/zyxing/data/spatial/sub_pancreatic_cancer/sub_pancreatic_cancer_full_image.tif\n",
      "[INFO][2023-10-26 00:35:00,354][dance][load_data] Raw data loaded:\n",
      "Data object that wraps (.data):\n",
      "AnnData object with n_obs × n_vars = 2000 × 474\n",
      "    obs: '0', 'ground_truth', 'label'\n",
      "    var: 'gene_ids', 'feature_types', 'genome'\n",
      "    uns: 'image', 'dance_config'\n",
      "    obsm: 'spatial', 'spatial_pixel'\n",
      "[INFO][2023-10-26 00:35:00,356][dance.Compose][__call__] Applying composed transformations:\n",
      "Compose(\n",
      "  AnnDataTransform(func=scanpy.preprocessing._highly_variable_genes.highly_variable_genes, func_kwargs={'flavor': 'seurat_v3', 'n_top_genes': 313, 'subset': True}),\n",
      "  AnnDataTransform(func=scanpy.preprocessing._normalization.normalize_total, func_kwargs={'target_sum': 10000.0}),\n",
      "  AnnDataTransform(func=scanpy.preprocessing._simple.log1p, func_kwargs={}),\n",
      "  StagateGraph(model_name='radius', radius=150, n_neighbors=5),\n",
      "  SetConfig(config_dict={'feature_channel': 'StagateGraph', 'feature_channel_type': 'obsp', 'label_channel': 'label', 'label_channel_type': 'obs'}),\n",
      ")\n",
      "[INFO][2023-10-26 00:35:01,501][dance.SetConfig][__call__] Updating the dance data object config options:\n",
      "{'feature_channel': 'StagateGraph',\n",
      " 'feature_channel_type': 'obsp',\n",
      " 'label_channel': 'label',\n",
      " 'label_channel_type': 'obs'}\n",
      "[INFO][2023-10-26 00:35:01,502][dance][set_config_from_dict] Setting config 'feature_channel' to 'StagateGraph'\n",
      "[INFO][2023-10-26 00:35:01,503][dance][set_config_from_dict] Setting config 'feature_channel_type' to 'obsp'\n",
      "[INFO][2023-10-26 00:35:01,503][dance][set_config_from_dict] Setting config 'label_channel' to 'label'\n",
      "[INFO][2023-10-26 00:35:01,504][dance][set_config_from_dict] Setting config 'label_channel_type' to 'obs'\n",
      "[INFO][2023-10-26 00:35:01,505][dance][load_data] Data transformed:\n",
      "Data object that wraps (.data):\n",
      "AnnData object with n_obs × n_vars = 2000 × 313\n",
      "    obs: '0', 'ground_truth', 'label'\n",
      "    var: 'gene_ids', 'feature_types', 'genome', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm'\n",
      "    uns: 'image', 'dance_config', 'hvg', 'log1p'\n",
      "    obsm: 'spatial', 'spatial_pixel'\n",
      "    obsp: 'StagateGraph'\n",
      "[INFO][2023-10-26 00:35:01,506][dance][wrapped_func] Took 0:00:10.562621 to load and process data.\n",
      "[INFO][2023-10-26 00:35:02,959][dance][_pretrain] Pre-training started\n",
      "[WARNING][2023-10-26 00:35:02,960][dance][_pretrain] `pretrain_path` is not set, pre-trained model will not be saved.\n",
      "100%|██████████| 1000/1000 [00:08<00:00, 114.91it/s]\n",
      "[INFO][2023-10-26 00:35:11,671][dance][_pretrain] Pre-training finished (took 8.71 seconds)\n",
      "[INFO][2023-10-26 00:35:11,672][dance][fit] Fitting Gaussian Mixture model for cluster assignments.\n",
      "[INFO][2023-10-26 00:35:12,742][dance][_load_raw_data] Loading expression data from /home/zyxing/data/spatial/sub_human_breast_cancer/sub_human_breast_cancer_raw_feature_bc_matrix.h5\n",
      "[INFO][2023-10-26 00:35:12,753][dance][_load_raw_data] Loading spatial info from /home/zyxing/data/spatial/sub_human_breast_cancer/tissue_positions_list.txt\n",
      "[INFO][2023-10-26 00:35:12,758][dance][_load_raw_data] Loading label info from /home/zyxing/data/spatial/sub_human_breast_cancer/cluster_labels.csv\n",
      "[INFO][2023-10-26 00:35:12,763][dance][_load_raw_data] Loading image data from /home/zyxing/data/spatial/sub_human_breast_cancer/sub_human_breast_cancer_full_image.tif\n",
      "[INFO][2023-10-26 00:35:25,455][dance][load_data] Raw data loaded:\n",
      "Data object that wraps (.data):\n",
      "AnnData object with n_obs × n_vars = 2000 × 313\n",
      "    obs: '0', 'ground_truth', 'label'\n",
      "    uns: 'image', 'dance_config'\n",
      "    obsm: 'spatial', 'spatial_pixel'\n",
      "[INFO][2023-10-26 00:35:25,457][dance.Compose][__call__] Applying composed transformations:\n",
      "Compose(\n",
      "  AnnDataTransform(func=scanpy.preprocessing._highly_variable_genes.highly_variable_genes, func_kwargs={'flavor': 'seurat_v3', 'n_top_genes': 313, 'subset': True}),\n",
      "  AnnDataTransform(func=scanpy.preprocessing._normalization.normalize_total, func_kwargs={'target_sum': 10000.0}),\n",
      "  AnnDataTransform(func=scanpy.preprocessing._simple.log1p, func_kwargs={}),\n",
      "  StagateGraph(model_name='radius', radius=150, n_neighbors=5),\n",
      "  SetConfig(config_dict={'feature_channel': 'StagateGraph', 'feature_channel_type': 'obsp', 'label_channel': 'label', 'label_channel_type': 'obs'}),\n",
      ")\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:197: UserWarning: Some cells have zero counts\n",
      "  warn(UserWarning('Some cells have zero counts'))\n",
      "[INFO][2023-10-26 00:35:27,059][dance.SetConfig][__call__] Updating the dance data object config options:\n",
      "{'feature_channel': 'StagateGraph',\n",
      " 'feature_channel_type': 'obsp',\n",
      " 'label_channel': 'label',\n",
      " 'label_channel_type': 'obs'}\n",
      "[INFO][2023-10-26 00:35:27,060][dance][set_config_from_dict] Setting config 'feature_channel' to 'StagateGraph'\n",
      "[INFO][2023-10-26 00:35:27,061][dance][set_config_from_dict] Setting config 'feature_channel_type' to 'obsp'\n",
      "[INFO][2023-10-26 00:35:27,062][dance][set_config_from_dict] Setting config 'label_channel' to 'label'\n",
      "[INFO][2023-10-26 00:35:27,062][dance][set_config_from_dict] Setting config 'label_channel_type' to 'obs'\n",
      "[INFO][2023-10-26 00:35:27,063][dance][load_data] Data transformed:\n",
      "Data object that wraps (.data):\n",
      "AnnData object with n_obs × n_vars = 2000 × 313\n",
      "    obs: '0', 'ground_truth', 'label'\n",
      "    var: 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm'\n",
      "    uns: 'image', 'dance_config', 'hvg', 'log1p'\n",
      "    obsm: 'spatial', 'spatial_pixel'\n",
      "    obsp: 'StagateGraph'\n",
      "[INFO][2023-10-26 00:35:27,064][dance][wrapped_func] Took 0:00:14.321950 to load and process data.\n",
      "[INFO][2023-10-26 00:35:27,087][dance][_pretrain] Pre-training started\n",
      "[WARNING][2023-10-26 00:35:27,088][dance][_pretrain] `pretrain_path` is not set, pre-trained model will not be saved.\n",
      "100%|██████████| 1000/1000 [00:06<00:00, 143.34it/s]\n",
      "[INFO][2023-10-26 00:35:34,072][dance][_pretrain] Pre-training finished (took 6.98 seconds)\n",
      "[INFO][2023-10-26 00:35:34,073][dance][fit] Fitting Gaussian Mixture model for cluster assignments.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from dance.datasets.spatial import SpatialLIBDDataset\n",
    "from dance.modules.spatial.spatial_domain.stagate import Stagate\n",
    "from dance.transforms.preprocess import set_seed\n",
    "Stagate_scores=[]\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--cache\", action=\"store_true\", help=\"Cache processed data.\")\n",
    "parser.add_argument(\"--sample_number\", type=str, default=\"151673\",\n",
    "                    help=\"12 human dorsolateral prefrontal cortex datasets for the spatial domain task.\")\n",
    "parser.add_argument(\"--hidden_dims\", type=list, default=[512, 32], help=\"hidden dimensions\")\n",
    "parser.add_argument(\"--rad_cutoff\", type=int, default=150, help=\"\")\n",
    "parser.add_argument(\"--seed\", type=int, default=3, help=\"\")\n",
    "parser.add_argument(\"--epochs\", type=int, default=1000, help=\"epochs\")\n",
    "parser.add_argument(\"--high_variable_genes\", type=int, default=313, help=\"\")\n",
    "for dataset in datasets:\n",
    "      args = parser.parse_args(['--sample_number',dataset,'--seed','16'])\n",
    "      set_seed(args.seed)\n",
    "\n",
    "      # Initialize model and get model specific preprocessing pipeline\n",
    "      model = Stagate([args.high_variable_genes] + args.hidden_dims)\n",
    "      preprocessing_pipeline = model.preprocessing_pipeline(n_top_hvgs=args.high_variable_genes, radius=args.rad_cutoff)\n",
    "\n",
    "      # Load data and perform necessary preprocessing\n",
    "      dataloader = SpatialLIBDDataset(data_id=args.sample_number,data_dir=\"/home/zyxing/data/spatial\")\n",
    "      data = dataloader.load_data(transform=preprocessing_pipeline, cache=args.cache)\n",
    "      adj, y = data.get_data(return_type=\"default\")\n",
    "      x = data.data.X.A\n",
    "      edge_list_array = np.vstack(np.nonzero(adj))\n",
    "\n",
    "      # Train and evaluate model\n",
    "      model = Stagate([args.high_variable_genes] + args.hidden_dims,device=\"cuda:2\")\n",
    "      score = model.fit_score((x, edge_list_array), y, epochs=args.epochs, random_state=args.seed)\n",
    "      Stagate_scores.append(score)\n",
    "      \"\"\" To reproduce Stagate on other samples, please refer to command lines belows:\n",
    "      NOTE: since the stagate method is unstable, you have to run at least 5 times to get\n",
    "            best performance. (same with original Stagate paper)\n",
    "\n",
    "      human dorsolateral prefrontal cortex sample 151673:\n",
    "      python stagate.py --sample_number=151673 --seed=16\n",
    "\n",
    "      human dorsolateral prefrontal cortex sample 151676:\n",
    "      python stagate.py --sample_number=151676 --seed=2030\n",
    "\n",
    "      human dorsolateral prefrontal cortex sample 151507:\n",
    "      python stagate.py --sample_number=151507 --seed=2021\n",
    "      \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.17421365641942377, 0.3703528419733546]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stagate_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[INFO][2023-10-26 00:35:35,992][dance][_load_raw_data] Loading expression data from /home/zyxing/data/spatial/sub_pancreatic_cancer/sub_pancreatic_cancer_raw_feature_bc_matrix.h5\n",
      "[INFO][2023-10-26 00:35:36,011][dance][_load_raw_data] Loading spatial info from /home/zyxing/data/spatial/sub_pancreatic_cancer/tissue_positions_list.txt\n",
      "[INFO][2023-10-26 00:35:36,017][dance][_load_raw_data] Loading label info from /home/zyxing/data/spatial/sub_pancreatic_cancer/cluster_labels.csv\n",
      "[INFO][2023-10-26 00:35:36,025][dance][_load_raw_data] Loading image data from /home/zyxing/data/spatial/sub_pancreatic_cancer/sub_pancreatic_cancer_full_image.tif\n",
      "[INFO][2023-10-26 00:35:45,041][dance][load_data] Raw data loaded:\n",
      "Data object that wraps (.data):\n",
      "AnnData object with n_obs × n_vars = 2000 × 474\n",
      "    obs: '0', 'ground_truth', 'label'\n",
      "    var: 'gene_ids', 'feature_types', 'genome'\n",
      "    uns: 'image', 'dance_config'\n",
      "    obsm: 'spatial', 'spatial_pixel'\n",
      "[INFO][2023-10-26 00:35:45,043][dance.Compose][__call__] Applying composed transformations:\n",
      "Compose(\n",
      "  AnnDataTransform(func=scanpy.preprocessing._simple.filter_genes, func_kwargs={'min_cells': 1}),\n",
      "  AnnDataTransform(func=scanpy.preprocessing._normalization.normalize_total, func_kwargs={'target_sum': 10000.0}),\n",
      "  AnnDataTransform(func=scanpy.preprocessing._simple.log1p, func_kwargs={}),\n",
      "  MorphologyFeature(model_name='resnet50', n_components=50, crop_size=10, target_size=299),\n",
      "  CellPCA(n_components=10),\n",
      "  SMEGraph(),\n",
      "  SMEFeature(),\n",
      "  NeighborGraph(n_neighbors=10, n_pcs=10, knn=True, random_state=0, method='umap', metric='euclidean'),\n",
      "  SetConfig(config_dict={'feature_channel': 'NeighborGraph', 'feature_channel_type': 'obsp', 'label_channel': 'label', 'label_channel_type': 'obs'}),\n",
      ")\n",
      "Extracting feature: 100%|██████████ [ time left: 00:00 ]\n",
      "[INFO][2023-10-26 00:37:11,341][dance.CellPCA][__call__] Start generating cell PCA features (2000, 472) (k=10)\n",
      "[INFO][2023-10-26 00:37:11,349][dance.CellPCA][__call__] Top 10 explained variances: [0.09418733 0.04080046 0.02711152 0.01931888 0.01478058 0.01045597\n",
      " 0.00928103 0.00874563 0.00836625 0.00788726]\n",
      "[INFO][2023-10-26 00:37:11,350][dance.CellPCA][__call__] Total explained variance: 24.09%\n",
      "Adjusting data: 100%|██████████ [ time left: 00:00 ]\n",
      "[INFO][2023-10-26 00:37:11,566][dance.NeighborGraph][__call__] Start computing the kNN connectivity adjacency matrix\n",
      "[INFO][2023-10-26 00:37:12,817][dance.SetConfig][__call__] Updating the dance data object config options:\n",
      "{'feature_channel': 'NeighborGraph',\n",
      " 'feature_channel_type': 'obsp',\n",
      " 'label_channel': 'label',\n",
      " 'label_channel_type': 'obs'}\n",
      "[INFO][2023-10-26 00:37:12,818][dance][set_config_from_dict] Setting config 'feature_channel' to 'NeighborGraph'\n",
      "[INFO][2023-10-26 00:37:12,818][dance][set_config_from_dict] Setting config 'feature_channel_type' to 'obsp'\n",
      "[INFO][2023-10-26 00:37:12,819][dance][set_config_from_dict] Setting config 'label_channel' to 'label'\n",
      "[INFO][2023-10-26 00:37:12,819][dance][set_config_from_dict] Setting config 'label_channel_type' to 'obs'\n",
      "[INFO][2023-10-26 00:37:12,819][dance][load_data] Data transformed:\n",
      "Data object that wraps (.data):\n",
      "AnnData object with n_obs × n_vars = 2000 × 472\n",
      "    obs: '0', 'ground_truth', 'label'\n",
      "    var: 'gene_ids', 'feature_types', 'genome', 'n_cells'\n",
      "    uns: 'image', 'dance_config', 'log1p'\n",
      "    obsm: 'spatial', 'spatial_pixel', 'MorphologyFeature', 'CellPCA', 'SMEFeature'\n",
      "    obsp: 'SMEGraph', 'NeighborGraph'\n",
      "[INFO][2023-10-26 00:37:12,820][dance][wrapped_func] Took 0:01:36.828249 to load and process data.\n",
      "[INFO][2023-10-26 00:37:12,832][dance][fit] Converting adjacency matrix to networkx graph...\n",
      "[INFO][2023-10-26 00:37:13,237][dance][fit] Conversion done. Start fitting...\n",
      "[INFO][2023-10-26 00:37:13,590][dance][fit] Fitting done.\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[INFO][2023-10-26 00:37:13,888][dance][_load_raw_data] Loading expression data from /home/zyxing/data/spatial/sub_human_breast_cancer/sub_human_breast_cancer_raw_feature_bc_matrix.h5\n",
      "[INFO][2023-10-26 00:37:13,902][dance][_load_raw_data] Loading spatial info from /home/zyxing/data/spatial/sub_human_breast_cancer/tissue_positions_list.txt\n",
      "[INFO][2023-10-26 00:37:13,907][dance][_load_raw_data] Loading label info from /home/zyxing/data/spatial/sub_human_breast_cancer/cluster_labels.csv\n",
      "[INFO][2023-10-26 00:37:13,912][dance][_load_raw_data] Loading image data from /home/zyxing/data/spatial/sub_human_breast_cancer/sub_human_breast_cancer_full_image.tif\n",
      "[INFO][2023-10-26 00:37:26,019][dance][load_data] Raw data loaded:\n",
      "Data object that wraps (.data):\n",
      "AnnData object with n_obs × n_vars = 2000 × 313\n",
      "    obs: '0', 'ground_truth', 'label'\n",
      "    uns: 'image', 'dance_config'\n",
      "    obsm: 'spatial', 'spatial_pixel'\n",
      "[INFO][2023-10-26 00:37:26,021][dance.Compose][__call__] Applying composed transformations:\n",
      "Compose(\n",
      "  AnnDataTransform(func=scanpy.preprocessing._simple.filter_genes, func_kwargs={'min_cells': 1}),\n",
      "  AnnDataTransform(func=scanpy.preprocessing._normalization.normalize_total, func_kwargs={'target_sum': 10000.0}),\n",
      "  AnnDataTransform(func=scanpy.preprocessing._simple.log1p, func_kwargs={}),\n",
      "  MorphologyFeature(model_name='resnet50', n_components=50, crop_size=10, target_size=299),\n",
      "  CellPCA(n_components=10),\n",
      "  SMEGraph(),\n",
      "  SMEFeature(),\n",
      "  NeighborGraph(n_neighbors=10, n_pcs=10, knn=True, random_state=0, method='umap', metric='euclidean'),\n",
      "  SetConfig(config_dict={'feature_channel': 'NeighborGraph', 'feature_channel_type': 'obsp', 'label_channel': 'label', 'label_channel_type': 'obs'}),\n",
      ")\n",
      "/home/zyxing/anaconda3/envs/dance/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:197: UserWarning: Some cells have zero counts\n",
      "  warn(UserWarning('Some cells have zero counts'))\n",
      "Extracting feature: 100%|██████████ [ time left: 00:00 ]\n",
      "[INFO][2023-10-26 00:38:50,321][dance.CellPCA][__call__] Start generating cell PCA features (2000, 313) (k=10)\n",
      "[INFO][2023-10-26 00:38:50,329][dance.CellPCA][__call__] Top 10 explained variances: [0.16653213 0.04777743 0.03602952 0.02270422 0.0225984  0.01601036\n",
      " 0.01251625 0.01085163 0.01011013 0.00883927]\n",
      "[INFO][2023-10-26 00:38:50,329][dance.CellPCA][__call__] Total explained variance: 35.40%\n",
      "Adjusting data: 100%|██████████ [ time left: 00:00 ]\n",
      "[INFO][2023-10-26 00:38:50,588][dance.NeighborGraph][__call__] Start computing the kNN connectivity adjacency matrix\n",
      "[INFO][2023-10-26 00:38:52,233][dance.SetConfig][__call__] Updating the dance data object config options:\n",
      "{'feature_channel': 'NeighborGraph',\n",
      " 'feature_channel_type': 'obsp',\n",
      " 'label_channel': 'label',\n",
      " 'label_channel_type': 'obs'}\n",
      "[INFO][2023-10-26 00:38:52,234][dance][set_config_from_dict] Setting config 'feature_channel' to 'NeighborGraph'\n",
      "[INFO][2023-10-26 00:38:52,235][dance][set_config_from_dict] Setting config 'feature_channel_type' to 'obsp'\n",
      "[INFO][2023-10-26 00:38:52,235][dance][set_config_from_dict] Setting config 'label_channel' to 'label'\n",
      "[INFO][2023-10-26 00:38:52,235][dance][set_config_from_dict] Setting config 'label_channel_type' to 'obs'\n",
      "[INFO][2023-10-26 00:38:52,236][dance][load_data] Data transformed:\n",
      "Data object that wraps (.data):\n",
      "AnnData object with n_obs × n_vars = 2000 × 313\n",
      "    obs: '0', 'ground_truth', 'label'\n",
      "    var: 'n_cells'\n",
      "    uns: 'image', 'dance_config', 'log1p'\n",
      "    obsm: 'spatial', 'spatial_pixel', 'MorphologyFeature', 'CellPCA', 'SMEFeature'\n",
      "    obsp: 'SMEGraph', 'NeighborGraph'\n",
      "[INFO][2023-10-26 00:38:52,236][dance][wrapped_func] Took 0:01:38.349013 to load and process data.\n",
      "[INFO][2023-10-26 00:38:52,247][dance][fit] Converting adjacency matrix to networkx graph...\n",
      "[INFO][2023-10-26 00:38:52,665][dance][fit] Conversion done. Start fitting...\n",
      "[INFO][2023-10-26 00:38:52,998][dance][fit] Fitting done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' To reproduce stlearn on other samples, please refer to command lines belows:\\nNOTE: since the stlearn method is unstable, you have to run multiple times to get\\n      best performance.\\n\\nhuman dorsolateral prefrontal cortex sample 151673:\\npython stlearn.py --n_clusters=20 --sample_number=151673 --seed=93\\n\\nhuman dorsolateral prefrontal cortex sample 151676:\\npython stlearn.py --n_clusters=20 --sample_number=151676 --seed=11\\n\\nhuman dorsolateral prefrontal cortex sample 151507:\\npython stlearn.py --n_clusters=20 --sample_number=151507 --seed=0\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "from dance.datasets.spatial import SpatialLIBDDataset\n",
    "from dance.modules.spatial.spatial_domain.stlearn import StKmeans, StLouvain\n",
    "from dance.transforms.preprocess import set_seed\n",
    "\n",
    "MODES = [\"louvain\", \"kmeans\"]\n",
    "\n",
    "St_ModesScores=[]\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--cache\", action=\"store_true\", help=\"Cache processed data.\")\n",
    "parser.add_argument(\"--sample_number\", type=str, default=\"151673\",\n",
    "                    help=\"12 human dorsolateral prefrontal cortex datasets for the spatial domain task.\")\n",
    "parser.add_argument(\"--mode\", type=str, default=\"louvain\", choices=MODES)\n",
    "parser.add_argument(\"--n_clusters\", type=int, default=17, help=\"the number of clusters\")\n",
    "parser.add_argument(\"--seed\", type=int, default=2)\n",
    "parser.add_argument(\"--n_components\", type=int, default=50, help=\"the number of components in PCA\")\n",
    "parser.add_argument(\"--device\", type=str, default=\"cuda\", help=\"device for resnet extract feature\")\n",
    "for dataset in datasets:\n",
    "    args = parser.parse_args(['--n_clusters','20','--sample_number',dataset,'--seed','93'])\n",
    "    set_seed(args.seed)\n",
    "\n",
    "    # Initialize model and get model specific preprocessing pipeline\n",
    "    if args.mode == \"kmeans\":\n",
    "        model = StKmeans(n_clusters=args.n_clusters)\n",
    "    elif args.mode == \"louvain\":\n",
    "        model = StLouvain(resolution=0.6)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown mode {args.mode!r}, available options are {MODES}\")\n",
    "    preprocessing_pipeline = model.preprocessing_pipeline(crop_size=10,target_size=299)\n",
    "\n",
    "    # Load data and perform necessary preprocessing\n",
    "    dataloader = SpatialLIBDDataset(data_id=args.sample_number,data_dir=\"/home/zyxing/data/spatial\")\n",
    "    data = dataloader.load_data(transform=preprocessing_pipeline, cache=args.cache)\n",
    "    x, y = data.get_data(return_type=\"default\")\n",
    "\n",
    "    # Train and evaluate model\n",
    "    score = model.fit_score(x, y.values.ravel())\n",
    "    St_ModesScores.append(score)\n",
    "\"\"\" To reproduce stlearn on other samples, please refer to command lines belows:\n",
    "NOTE: since the stlearn method is unstable, you have to run multiple times to get\n",
    "      best performance.\n",
    "\n",
    "human dorsolateral prefrontal cortex sample 151673:\n",
    "python stlearn.py --n_clusters=20 --sample_number=151673 --seed=93\n",
    "\n",
    "human dorsolateral prefrontal cortex sample 151676:\n",
    "python stlearn.py --n_clusters=20 --sample_number=151676 --seed=11\n",
    "\n",
    "human dorsolateral prefrontal cortex sample 151507:\n",
    "python stlearn.py --n_clusters=20 --sample_number=151507 --seed=0\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.21686632960908456, 0.24452581195775105]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "St_ModesScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
